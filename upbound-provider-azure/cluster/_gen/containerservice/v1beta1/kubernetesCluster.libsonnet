{
  local d = (import 'doc-util/main.libsonnet'),
  '#':: d.pkg(name='kubernetesCluster', url='', help='"KubernetesCluster is the Schema for the KubernetesClusters API. Manages a managed Kubernetes Cluster (also known as AKS / Azure Kubernetes Service)"'),
  '#metadata':: d.obj(help='"ObjectMeta is metadata that all persisted resources must have, which includes all objects users must create."'),
  metadata: {
    '#withAnnotations':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotations(annotations): { metadata+: { annotations: annotations } },
    '#withAnnotationsMixin':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotationsMixin(annotations): { metadata+: { annotations+: annotations } },
    '#withClusterName':: d.fn(help='"The name of the cluster which the object belongs to. This is used to distinguish resources with same name and namespace in different clusters. This field is not set anywhere right now and apiserver is going to ignore it if set in create or update request."', args=[d.arg(name='clusterName', type=d.T.string)]),
    withClusterName(clusterName): { metadata+: { clusterName: clusterName } },
    '#withCreationTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='creationTimestamp', type=d.T.string)]),
    withCreationTimestamp(creationTimestamp): { metadata+: { creationTimestamp: creationTimestamp } },
    '#withDeletionGracePeriodSeconds':: d.fn(help='"Number of seconds allowed for this object to gracefully terminate before it will be removed from the system. Only set when deletionTimestamp is also set. May only be shortened. Read-only."', args=[d.arg(name='deletionGracePeriodSeconds', type=d.T.integer)]),
    withDeletionGracePeriodSeconds(deletionGracePeriodSeconds): { metadata+: { deletionGracePeriodSeconds: deletionGracePeriodSeconds } },
    '#withDeletionTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='deletionTimestamp', type=d.T.string)]),
    withDeletionTimestamp(deletionTimestamp): { metadata+: { deletionTimestamp: deletionTimestamp } },
    '#withFinalizers':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizers(finalizers): { metadata+: { finalizers: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withFinalizersMixin':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizersMixin(finalizers): { metadata+: { finalizers+: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withGenerateName':: d.fn(help='"GenerateName is an optional prefix, used by the server, to generate a unique name ONLY IF the Name field has not been provided. If this field is used, the name returned to the client will be different than the name passed. This value will also be combined with a unique suffix. The provided value has the same validation rules as the Name field, and may be truncated by the length of the suffix required to make the value unique on the server.\\n\\nIf this field is specified and the generated name exists, the server will NOT return a 409 - instead, it will either return 201 Created or 500 with Reason ServerTimeout indicating a unique name could not be found in the time allotted, and the client should retry (optionally after the time indicated in the Retry-After header).\\n\\nApplied only if Name is not specified. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency"', args=[d.arg(name='generateName', type=d.T.string)]),
    withGenerateName(generateName): { metadata+: { generateName: generateName } },
    '#withGeneration':: d.fn(help='"A sequence number representing a specific generation of the desired state. Populated by the system. Read-only."', args=[d.arg(name='generation', type=d.T.integer)]),
    withGeneration(generation): { metadata+: { generation: generation } },
    '#withLabels':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"', args=[d.arg(name='labels', type=d.T.object)]),
    withLabels(labels): { metadata+: { labels: labels } },
    '#withLabelsMixin':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
    withLabelsMixin(labels): { metadata+: { labels+: labels } },
    '#withName':: d.fn(help='"Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names"', args=[d.arg(name='name', type=d.T.string)]),
    withName(name): { metadata+: { name: name } },
    '#withNamespace':: d.fn(help='"Namespace defines the space within which each name must be unique. An empty namespace is equivalent to the \\"default\\" namespace, but \\"default\\" is the canonical representation. Not all objects are required to be scoped to a namespace - the value of this field for those objects will be empty.\\n\\nMust be a DNS_LABEL. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/namespaces"', args=[d.arg(name='namespace', type=d.T.string)]),
    withNamespace(namespace): { metadata+: { namespace: namespace } },
    '#withOwnerReferences':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferences(ownerReferences): { metadata+: { ownerReferences: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withOwnerReferencesMixin':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferencesMixin(ownerReferences): { metadata+: { ownerReferences+: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withResourceVersion':: d.fn(help='"An opaque value that represents the internal version of this object that can be used by clients to determine when objects have changed. May be used for optimistic concurrency, change detection, and the watch operation on a resource or set of resources. Clients must treat these values as opaque and passed unmodified back to the server. They may only be valid for a particular resource or set of resources.\\n\\nPopulated by the system. Read-only. Value must be treated as opaque by clients and . More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency"', args=[d.arg(name='resourceVersion', type=d.T.string)]),
    withResourceVersion(resourceVersion): { metadata+: { resourceVersion: resourceVersion } },
    '#withSelfLink':: d.fn(help='"SelfLink is a URL representing this object. Populated by the system. Read-only.\\n\\nDEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release."', args=[d.arg(name='selfLink', type=d.T.string)]),
    withSelfLink(selfLink): { metadata+: { selfLink: selfLink } },
    '#withUid':: d.fn(help='"UID is the unique in time and space value for this object. It is typically generated by the server on successful creation of a resource and is not allowed to change on PUT operations.\\n\\nPopulated by the system. Read-only. More info: http://kubernetes.io/docs/user-guide/identifiers#uids"', args=[d.arg(name='uid', type=d.T.string)]),
    withUid(uid): { metadata+: { uid: uid } },
  },
  '#new':: d.fn(help='new returns an instance of KubernetesCluster', args=[d.arg(name='name', type=d.T.string)]),
  new(name): {
    apiVersion: 'containerservice.azure.upbound.io/v1beta1',
    kind: 'KubernetesCluster',
  } + self.metadata.withName(name=name) + self.metadata.withAnnotations(annotations={
    'tanka.dev/namespaced': 'false',
  }),
  '#spec':: d.obj(help='"KubernetesClusterSpec defines the desired state of KubernetesCluster"'),
  spec: {
    '#forProvider':: d.obj(help=''),
    forProvider: {
      '#aciConnectorLinux':: d.obj(help='"A aci_connector_linux block as defined below. For more details, please visit Create and configure an AKS cluster to use virtual nodes."'),
      aciConnectorLinux: {
        '#subnetNameRef':: d.obj(help='"Reference to a Subnet in network to populate subnetName."'),
        subnetNameRef: {
          '#policy':: d.obj(help='"Policies for referencing."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { subnetNameRef+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { subnetNameRef+: { policy+: { resolve: resolve } } },
          },
          '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { subnetNameRef+: { name: name } },
        },
        '#subnetNameSelector':: d.obj(help='"Selector for a Subnet in network to populate subnetName."'),
        subnetNameSelector: {
          '#policy':: d.obj(help='"Policies for selection."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { subnetNameSelector+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { subnetNameSelector+: { policy+: { resolve: resolve } } },
          },
          '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference\\nas the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
          withMatchControllerRef(matchControllerRef): { subnetNameSelector+: { matchControllerRef: matchControllerRef } },
          '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabels(matchLabels): { subnetNameSelector+: { matchLabels: matchLabels } },
          '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabelsMixin(matchLabels): { subnetNameSelector+: { matchLabels+: matchLabels } },
        },
        '#withSubnetName':: d.fn(help='"The subnet name for the virtual nodes to run."', args=[d.arg(name='subnetName', type=d.T.string)]),
        withSubnetName(subnetName): { subnetName: subnetName },
      },
      '#apiServerAccessProfile':: d.obj(help='"An api_server_access_profile block as defined below."'),
      apiServerAccessProfile: {
        '#subnetIdRef':: d.obj(help='"Reference to a Subnet in network to populate subnetId."'),
        subnetIdRef: {
          '#policy':: d.obj(help='"Policies for referencing."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { subnetIdRef+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { subnetIdRef+: { policy+: { resolve: resolve } } },
          },
          '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { subnetIdRef+: { name: name } },
        },
        '#subnetIdSelector':: d.obj(help='"Selector for a Subnet in network to populate subnetId."'),
        subnetIdSelector: {
          '#policy':: d.obj(help='"Policies for selection."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { subnetIdSelector+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { subnetIdSelector+: { policy+: { resolve: resolve } } },
          },
          '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference\\nas the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
          withMatchControllerRef(matchControllerRef): { subnetIdSelector+: { matchControllerRef: matchControllerRef } },
          '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabels(matchLabels): { subnetIdSelector+: { matchLabels: matchLabels } },
          '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabelsMixin(matchLabels): { subnetIdSelector+: { matchLabels+: matchLabels } },
        },
        '#withAuthorizedIpRanges':: d.fn(help='"Set of authorized IP ranges to allow access to API server, e.g. [\\"198.51.100.0/24\\"]."', args=[d.arg(name='authorizedIpRanges', type=d.T.array)]),
        withAuthorizedIpRanges(authorizedIpRanges): { authorizedIpRanges: if std.isArray(v=authorizedIpRanges) then authorizedIpRanges else [authorizedIpRanges] },
        '#withAuthorizedIpRangesMixin':: d.fn(help='"Set of authorized IP ranges to allow access to API server, e.g. [\\"198.51.100.0/24\\"]."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='authorizedIpRanges', type=d.T.array)]),
        withAuthorizedIpRangesMixin(authorizedIpRanges): { authorizedIpRanges+: if std.isArray(v=authorizedIpRanges) then authorizedIpRanges else [authorizedIpRanges] },
        '#withSubnetId':: d.fn(help='"The ID of the Subnet where the API server endpoint is delegated to."', args=[d.arg(name='subnetId', type=d.T.string)]),
        withSubnetId(subnetId): { subnetId: subnetId },
        '#withVirtualNetworkIntegrationEnabled':: d.fn(help='"Whether to enable virtual network integration for the API Server. Defaults to false."', args=[d.arg(name='virtualNetworkIntegrationEnabled', type=d.T.boolean)]),
        withVirtualNetworkIntegrationEnabled(virtualNetworkIntegrationEnabled): { virtualNetworkIntegrationEnabled: virtualNetworkIntegrationEnabled },
      },
      '#autoScalerProfile':: d.obj(help='"A auto_scaler_profile block as defined below."'),
      autoScalerProfile: {
        '#withBalanceSimilarNodeGroups':: d.fn(help='"Detect similar node groups and balance the number of nodes between them. Defaults to false."', args=[d.arg(name='balanceSimilarNodeGroups', type=d.T.boolean)]),
        withBalanceSimilarNodeGroups(balanceSimilarNodeGroups): { balanceSimilarNodeGroups: balanceSimilarNodeGroups },
        '#withDaemonsetEvictionForEmptyNodesEnabled':: d.fn(help='"Whether DaemonSet pods will be gracefully terminated from empty nodes. Defaults to false."', args=[d.arg(name='daemonsetEvictionForEmptyNodesEnabled', type=d.T.boolean)]),
        withDaemonsetEvictionForEmptyNodesEnabled(daemonsetEvictionForEmptyNodesEnabled): { daemonsetEvictionForEmptyNodesEnabled: daemonsetEvictionForEmptyNodesEnabled },
        '#withDaemonsetEvictionForOccupiedNodesEnabled':: d.fn(help='"Whether DaemonSet pods will be gracefully terminated from non-empty nodes. Defaults to true."', args=[d.arg(name='daemonsetEvictionForOccupiedNodesEnabled', type=d.T.boolean)]),
        withDaemonsetEvictionForOccupiedNodesEnabled(daemonsetEvictionForOccupiedNodesEnabled): { daemonsetEvictionForOccupiedNodesEnabled: daemonsetEvictionForOccupiedNodesEnabled },
        '#withEmptyBulkDeleteMax':: d.fn(help='"Maximum number of empty nodes that can be deleted at the same time. Defaults to 10."', args=[d.arg(name='emptyBulkDeleteMax', type=d.T.string)]),
        withEmptyBulkDeleteMax(emptyBulkDeleteMax): { emptyBulkDeleteMax: emptyBulkDeleteMax },
        '#withExpander':: d.fn(help='"Expander to use. Possible values are least-waste, priority, most-pods and random. Defaults to random."', args=[d.arg(name='expander', type=d.T.string)]),
        withExpander(expander): { expander: expander },
        '#withIgnoreDaemonsetsUtilizationEnabled':: d.fn(help='"Whether DaemonSet pods will be ignored when calculating resource utilization for scale down. Defaults to false."', args=[d.arg(name='ignoreDaemonsetsUtilizationEnabled', type=d.T.boolean)]),
        withIgnoreDaemonsetsUtilizationEnabled(ignoreDaemonsetsUtilizationEnabled): { ignoreDaemonsetsUtilizationEnabled: ignoreDaemonsetsUtilizationEnabled },
        '#withMaxGracefulTerminationSec':: d.fn(help='"Maximum number of seconds the cluster autoscaler waits for pod termination when trying to scale down a node. Defaults to 600."', args=[d.arg(name='maxGracefulTerminationSec', type=d.T.string)]),
        withMaxGracefulTerminationSec(maxGracefulTerminationSec): { maxGracefulTerminationSec: maxGracefulTerminationSec },
        '#withMaxNodeProvisioningTime':: d.fn(help='"Maximum time the autoscaler waits for a node to be provisioned. Defaults to 15m."', args=[d.arg(name='maxNodeProvisioningTime', type=d.T.string)]),
        withMaxNodeProvisioningTime(maxNodeProvisioningTime): { maxNodeProvisioningTime: maxNodeProvisioningTime },
        '#withMaxUnreadyNodes':: d.fn(help='"Maximum Number of allowed unready nodes. Defaults to 3."', args=[d.arg(name='maxUnreadyNodes', type=d.T.number)]),
        withMaxUnreadyNodes(maxUnreadyNodes): { maxUnreadyNodes: maxUnreadyNodes },
        '#withMaxUnreadyPercentage':: d.fn(help='"Maximum percentage of unready nodes the cluster autoscaler will stop if the percentage is exceeded. Defaults to 45."', args=[d.arg(name='maxUnreadyPercentage', type=d.T.number)]),
        withMaxUnreadyPercentage(maxUnreadyPercentage): { maxUnreadyPercentage: maxUnreadyPercentage },
        '#withNewPodScaleUpDelay':: d.fn(help="\"For scenarios like burst/batch scale where you don't want CA to act before the kubernetes scheduler could schedule all the pods, you can tell CA to ignore unscheduled pods before they're a certain age. Defaults to 10s.\"", args=[d.arg(name='newPodScaleUpDelay', type=d.T.string)]),
        withNewPodScaleUpDelay(newPodScaleUpDelay): { newPodScaleUpDelay: newPodScaleUpDelay },
        '#withScaleDownDelayAfterAdd':: d.fn(help='"How long after the scale up of AKS nodes the scale down evaluation resumes. Defaults to 10m."', args=[d.arg(name='scaleDownDelayAfterAdd', type=d.T.string)]),
        withScaleDownDelayAfterAdd(scaleDownDelayAfterAdd): { scaleDownDelayAfterAdd: scaleDownDelayAfterAdd },
        '#withScaleDownDelayAfterDelete':: d.fn(help='"How long after node deletion that scale down evaluation resumes. Defaults to the value used for scan_interval."', args=[d.arg(name='scaleDownDelayAfterDelete', type=d.T.string)]),
        withScaleDownDelayAfterDelete(scaleDownDelayAfterDelete): { scaleDownDelayAfterDelete: scaleDownDelayAfterDelete },
        '#withScaleDownDelayAfterFailure':: d.fn(help='"How long after scale down failure that scale down evaluation resumes. Defaults to 3m."', args=[d.arg(name='scaleDownDelayAfterFailure', type=d.T.string)]),
        withScaleDownDelayAfterFailure(scaleDownDelayAfterFailure): { scaleDownDelayAfterFailure: scaleDownDelayAfterFailure },
        '#withScaleDownUnneeded':: d.fn(help='"How long a node should be unneeded before it is eligible for scale down. Defaults to 10m."', args=[d.arg(name='scaleDownUnneeded', type=d.T.string)]),
        withScaleDownUnneeded(scaleDownUnneeded): { scaleDownUnneeded: scaleDownUnneeded },
        '#withScaleDownUnready':: d.fn(help='"How long an unready node should be unneeded before it is eligible for scale down. Defaults to 20m."', args=[d.arg(name='scaleDownUnready', type=d.T.string)]),
        withScaleDownUnready(scaleDownUnready): { scaleDownUnready: scaleDownUnready },
        '#withScaleDownUtilizationThreshold':: d.fn(help='"Node utilization level, defined as sum of requested resources divided by capacity, below which a node can be considered for scale down. Defaults to 0.5."', args=[d.arg(name='scaleDownUtilizationThreshold', type=d.T.string)]),
        withScaleDownUtilizationThreshold(scaleDownUtilizationThreshold): { scaleDownUtilizationThreshold: scaleDownUtilizationThreshold },
        '#withScanInterval':: d.fn(help='"How often the AKS Cluster should be re-evaluated for scale up/down. Defaults to 10s."', args=[d.arg(name='scanInterval', type=d.T.string)]),
        withScanInterval(scanInterval): { scanInterval: scanInterval },
        '#withSkipNodesWithLocalStorage':: d.fn(help='"If true cluster autoscaler will never delete nodes with pods with local storage, for example, EmptyDir or HostPath. Defaults to false."', args=[d.arg(name='skipNodesWithLocalStorage', type=d.T.boolean)]),
        withSkipNodesWithLocalStorage(skipNodesWithLocalStorage): { skipNodesWithLocalStorage: skipNodesWithLocalStorage },
        '#withSkipNodesWithSystemPods':: d.fn(help='"If true cluster autoscaler will never delete nodes with pods from kube-system (except for DaemonSet or mirror pods). Defaults to true."', args=[d.arg(name='skipNodesWithSystemPods', type=d.T.boolean)]),
        withSkipNodesWithSystemPods(skipNodesWithSystemPods): { skipNodesWithSystemPods: skipNodesWithSystemPods },
      },
      '#azureActiveDirectoryRoleBasedAccessControl':: d.obj(help='"A azure_active_directory_role_based_access_control block as defined below."'),
      azureActiveDirectoryRoleBasedAccessControl: {
        '#withAdminGroupObjectIds':: d.fn(help='"A list of Object IDs of Azure Active Directory Groups which should have Admin Role on the Cluster."', args=[d.arg(name='adminGroupObjectIds', type=d.T.array)]),
        withAdminGroupObjectIds(adminGroupObjectIds): { adminGroupObjectIds: if std.isArray(v=adminGroupObjectIds) then adminGroupObjectIds else [adminGroupObjectIds] },
        '#withAdminGroupObjectIdsMixin':: d.fn(help='"A list of Object IDs of Azure Active Directory Groups which should have Admin Role on the Cluster."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='adminGroupObjectIds', type=d.T.array)]),
        withAdminGroupObjectIdsMixin(adminGroupObjectIds): { adminGroupObjectIds+: if std.isArray(v=adminGroupObjectIds) then adminGroupObjectIds else [adminGroupObjectIds] },
        '#withAzureRbacEnabled':: d.fn(help='"Is Role Based Access Control based on Azure AD enabled?"', args=[d.arg(name='azureRbacEnabled', type=d.T.boolean)]),
        withAzureRbacEnabled(azureRbacEnabled): { azureRbacEnabled: azureRbacEnabled },
        '#withTenantId':: d.fn(help="\"The Tenant ID used for Azure Active Directory Application. If this isn't specified the Tenant ID of the current Subscription is used.\"", args=[d.arg(name='tenantId', type=d.T.string)]),
        withTenantId(tenantId): { tenantId: tenantId },
      },
      '#bootstrapProfile':: d.obj(help='"A bootstrap_profile block as defined below."'),
      bootstrapProfile: {
        '#withArtifactSource':: d.fn(help='"The artifact source. The source where the artifacts are downloaded from. Possible values are Cache and Direct. Defaults to Direct."', args=[d.arg(name='artifactSource', type=d.T.string)]),
        withArtifactSource(artifactSource): { artifactSource: artifactSource },
        '#withContainerRegistryId':: d.fn(help='"The resource Id of Azure Container Registry."', args=[d.arg(name='containerRegistryId', type=d.T.string)]),
        withContainerRegistryId(containerRegistryId): { containerRegistryId: containerRegistryId },
      },
      '#confidentialComputing':: d.obj(help='"A confidential_computing block as defined below. For more details please the documentation"'),
      confidentialComputing: {
        '#withSgxQuoteHelperEnabled':: d.fn(help='"Should the SGX quote helper be enabled?"', args=[d.arg(name='sgxQuoteHelperEnabled', type=d.T.boolean)]),
        withSgxQuoteHelperEnabled(sgxQuoteHelperEnabled): { sgxQuoteHelperEnabled: sgxQuoteHelperEnabled },
      },
      '#defaultNodePool':: d.obj(help='"Specifies configuration for \\"System\\" mode node pool. A default_node_pool block as defined below."'),
      defaultNodePool: {
        '#kubeletConfig':: d.obj(help='"A kubelet_config block as defined below. temporary_name_for_rotation must be specified when changing this block."'),
        kubeletConfig: {
          '#withAllowedUnsafeSysctls':: d.fn(help='"Specifies the allow list of unsafe sysctls command or patterns (ending in *)."', args=[d.arg(name='allowedUnsafeSysctls', type=d.T.array)]),
          withAllowedUnsafeSysctls(allowedUnsafeSysctls): { allowedUnsafeSysctls: if std.isArray(v=allowedUnsafeSysctls) then allowedUnsafeSysctls else [allowedUnsafeSysctls] },
          '#withAllowedUnsafeSysctlsMixin':: d.fn(help='"Specifies the allow list of unsafe sysctls command or patterns (ending in *)."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='allowedUnsafeSysctls', type=d.T.array)]),
          withAllowedUnsafeSysctlsMixin(allowedUnsafeSysctls): { allowedUnsafeSysctls+: if std.isArray(v=allowedUnsafeSysctls) then allowedUnsafeSysctls else [allowedUnsafeSysctls] },
          '#withContainerLogMaxLine':: d.fn(help='"Specifies the maximum number of container log files that can be present for a container. must be at least 2."', args=[d.arg(name='containerLogMaxLine', type=d.T.number)]),
          withContainerLogMaxLine(containerLogMaxLine): { containerLogMaxLine: containerLogMaxLine },
          '#withContainerLogMaxSizeMb':: d.fn(help='"Specifies the maximum size (e.g. 10MB) of container log file before it is rotated."', args=[d.arg(name='containerLogMaxSizeMb', type=d.T.number)]),
          withContainerLogMaxSizeMb(containerLogMaxSizeMb): { containerLogMaxSizeMb: containerLogMaxSizeMb },
          '#withCpuCfsQuotaEnabled':: d.fn(help='"Is CPU CFS quota enforcement for containers enabled? Defaults to true."', args=[d.arg(name='cpuCfsQuotaEnabled', type=d.T.boolean)]),
          withCpuCfsQuotaEnabled(cpuCfsQuotaEnabled): { cpuCfsQuotaEnabled: cpuCfsQuotaEnabled },
          '#withCpuCfsQuotaPeriod':: d.fn(help='"Specifies the CPU CFS quota period value."', args=[d.arg(name='cpuCfsQuotaPeriod', type=d.T.string)]),
          withCpuCfsQuotaPeriod(cpuCfsQuotaPeriod): { cpuCfsQuotaPeriod: cpuCfsQuotaPeriod },
          '#withCpuManagerPolicy':: d.fn(help='"Specifies the CPU Manager policy to use. Possible values are none and static,."', args=[d.arg(name='cpuManagerPolicy', type=d.T.string)]),
          withCpuManagerPolicy(cpuManagerPolicy): { cpuManagerPolicy: cpuManagerPolicy },
          '#withImageGcHighThreshold':: d.fn(help='"Specifies the percent of disk usage above which image garbage collection is always run. Must be between 0 and 100."', args=[d.arg(name='imageGcHighThreshold', type=d.T.number)]),
          withImageGcHighThreshold(imageGcHighThreshold): { imageGcHighThreshold: imageGcHighThreshold },
          '#withImageGcLowThreshold':: d.fn(help='"Specifies the percent of disk usage lower than which image garbage collection is never run. Must be between 0 and 100."', args=[d.arg(name='imageGcLowThreshold', type=d.T.number)]),
          withImageGcLowThreshold(imageGcLowThreshold): { imageGcLowThreshold: imageGcLowThreshold },
          '#withPodMaxPid':: d.fn(help='"Specifies the maximum number of processes per pod."', args=[d.arg(name='podMaxPid', type=d.T.number)]),
          withPodMaxPid(podMaxPid): { podMaxPid: podMaxPid },
          '#withTopologyManagerPolicy':: d.fn(help='"Specifies the Topology Manager policy to use. Possible values are none, best-effort, restricted or single-numa-node."', args=[d.arg(name='topologyManagerPolicy', type=d.T.string)]),
          withTopologyManagerPolicy(topologyManagerPolicy): { topologyManagerPolicy: topologyManagerPolicy },
        },
        '#linuxOsConfig':: d.obj(help='"A linux_os_config block as defined below. temporary_name_for_rotation must be specified when changing this block."'),
        linuxOsConfig: {
          '#sysctlConfig':: d.obj(help='"A sysctl_config block as defined below."'),
          sysctlConfig: {
            '#withFsAioMaxNr':: d.fn(help='"The sysctl setting fs.aio-max-nr. Must be between 65536 and 6553500."', args=[d.arg(name='fsAioMaxNr', type=d.T.number)]),
            withFsAioMaxNr(fsAioMaxNr): { fsAioMaxNr: fsAioMaxNr },
            '#withFsFileMax':: d.fn(help='"The sysctl setting fs.file-max. Must be between 8192 and 12000500."', args=[d.arg(name='fsFileMax', type=d.T.number)]),
            withFsFileMax(fsFileMax): { fsFileMax: fsFileMax },
            '#withFsInotifyMaxUserWatches':: d.fn(help='"The sysctl setting fs.inotify.max_user_watches. Must be between 781250 and 2097152."', args=[d.arg(name='fsInotifyMaxUserWatches', type=d.T.number)]),
            withFsInotifyMaxUserWatches(fsInotifyMaxUserWatches): { fsInotifyMaxUserWatches: fsInotifyMaxUserWatches },
            '#withFsNrOpen':: d.fn(help='"The sysctl setting fs.nr_open. Must be between 8192 and 20000500."', args=[d.arg(name='fsNrOpen', type=d.T.number)]),
            withFsNrOpen(fsNrOpen): { fsNrOpen: fsNrOpen },
            '#withKernelThreadsMax':: d.fn(help='"The sysctl setting kernel.threads-max. Must be between 20 and 513785."', args=[d.arg(name='kernelThreadsMax', type=d.T.number)]),
            withKernelThreadsMax(kernelThreadsMax): { kernelThreadsMax: kernelThreadsMax },
            '#withNetCoreNetdevMaxBacklog':: d.fn(help='"The sysctl setting net.core.netdev_max_backlog. Must be between 1000 and 3240000."', args=[d.arg(name='netCoreNetdevMaxBacklog', type=d.T.number)]),
            withNetCoreNetdevMaxBacklog(netCoreNetdevMaxBacklog): { netCoreNetdevMaxBacklog: netCoreNetdevMaxBacklog },
            '#withNetCoreOptmemMax':: d.fn(help='"The sysctl setting net.core.optmem_max. Must be between 20480 and 4194304."', args=[d.arg(name='netCoreOptmemMax', type=d.T.number)]),
            withNetCoreOptmemMax(netCoreOptmemMax): { netCoreOptmemMax: netCoreOptmemMax },
            '#withNetCoreRmemDefault':: d.fn(help='"The sysctl setting net.core.rmem_default. Must be between 212992 and 134217728."', args=[d.arg(name='netCoreRmemDefault', type=d.T.number)]),
            withNetCoreRmemDefault(netCoreRmemDefault): { netCoreRmemDefault: netCoreRmemDefault },
            '#withNetCoreRmemMax':: d.fn(help='"The sysctl setting net.core.rmem_max. Must be between 212992 and 134217728."', args=[d.arg(name='netCoreRmemMax', type=d.T.number)]),
            withNetCoreRmemMax(netCoreRmemMax): { netCoreRmemMax: netCoreRmemMax },
            '#withNetCoreSomaxconn':: d.fn(help='"The sysctl setting net.core.somaxconn. Must be between 4096 and 3240000."', args=[d.arg(name='netCoreSomaxconn', type=d.T.number)]),
            withNetCoreSomaxconn(netCoreSomaxconn): { netCoreSomaxconn: netCoreSomaxconn },
            '#withNetCoreWmemDefault':: d.fn(help='"The sysctl setting net.core.wmem_default. Must be between 212992 and 134217728."', args=[d.arg(name='netCoreWmemDefault', type=d.T.number)]),
            withNetCoreWmemDefault(netCoreWmemDefault): { netCoreWmemDefault: netCoreWmemDefault },
            '#withNetCoreWmemMax':: d.fn(help='"The sysctl setting net.core.wmem_max. Must be between 212992 and 134217728."', args=[d.arg(name='netCoreWmemMax', type=d.T.number)]),
            withNetCoreWmemMax(netCoreWmemMax): { netCoreWmemMax: netCoreWmemMax },
            '#withNetIpv4IpLocalPortRangeMax':: d.fn(help='"The sysctl setting net.ipv4.ip_local_port_range max value. Must be between 32768 and 65535."', args=[d.arg(name='netIpv4IpLocalPortRangeMax', type=d.T.number)]),
            withNetIpv4IpLocalPortRangeMax(netIpv4IpLocalPortRangeMax): { netIpv4IpLocalPortRangeMax: netIpv4IpLocalPortRangeMax },
            '#withNetIpv4IpLocalPortRangeMin':: d.fn(help='"The sysctl setting net.ipv4.ip_local_port_range min value. Must be between 1024 and 60999."', args=[d.arg(name='netIpv4IpLocalPortRangeMin', type=d.T.number)]),
            withNetIpv4IpLocalPortRangeMin(netIpv4IpLocalPortRangeMin): { netIpv4IpLocalPortRangeMin: netIpv4IpLocalPortRangeMin },
            '#withNetIpv4NeighDefaultGcThresh1':: d.fn(help='"The sysctl setting net.ipv4.neigh.default.gc_thresh1. Must be between 128 and 80000."', args=[d.arg(name='netIpv4NeighDefaultGcThresh1', type=d.T.number)]),
            withNetIpv4NeighDefaultGcThresh1(netIpv4NeighDefaultGcThresh1): { netIpv4NeighDefaultGcThresh1: netIpv4NeighDefaultGcThresh1 },
            '#withNetIpv4NeighDefaultGcThresh2':: d.fn(help='"The sysctl setting net.ipv4.neigh.default.gc_thresh2. Must be between 512 and 90000."', args=[d.arg(name='netIpv4NeighDefaultGcThresh2', type=d.T.number)]),
            withNetIpv4NeighDefaultGcThresh2(netIpv4NeighDefaultGcThresh2): { netIpv4NeighDefaultGcThresh2: netIpv4NeighDefaultGcThresh2 },
            '#withNetIpv4NeighDefaultGcThresh3':: d.fn(help='"The sysctl setting net.ipv4.neigh.default.gc_thresh3. Must be between 1024 and 100000."', args=[d.arg(name='netIpv4NeighDefaultGcThresh3', type=d.T.number)]),
            withNetIpv4NeighDefaultGcThresh3(netIpv4NeighDefaultGcThresh3): { netIpv4NeighDefaultGcThresh3: netIpv4NeighDefaultGcThresh3 },
            '#withNetIpv4TcpFinTimeout':: d.fn(help='"The sysctl setting net.ipv4.tcp_fin_timeout. Must be between 5 and 120."', args=[d.arg(name='netIpv4TcpFinTimeout', type=d.T.number)]),
            withNetIpv4TcpFinTimeout(netIpv4TcpFinTimeout): { netIpv4TcpFinTimeout: netIpv4TcpFinTimeout },
            '#withNetIpv4TcpKeepaliveIntvl':: d.fn(help='"The sysctl setting net.ipv4.tcp_keepalive_intvl. Must be between 10 and 90."', args=[d.arg(name='netIpv4TcpKeepaliveIntvl', type=d.T.number)]),
            withNetIpv4TcpKeepaliveIntvl(netIpv4TcpKeepaliveIntvl): { netIpv4TcpKeepaliveIntvl: netIpv4TcpKeepaliveIntvl },
            '#withNetIpv4TcpKeepaliveProbes':: d.fn(help='"The sysctl setting net.ipv4.tcp_keepalive_probes. Must be between 1 and 15."', args=[d.arg(name='netIpv4TcpKeepaliveProbes', type=d.T.number)]),
            withNetIpv4TcpKeepaliveProbes(netIpv4TcpKeepaliveProbes): { netIpv4TcpKeepaliveProbes: netIpv4TcpKeepaliveProbes },
            '#withNetIpv4TcpKeepaliveTime':: d.fn(help='"The sysctl setting net.ipv4.tcp_keepalive_time. Must be between 30 and 432000."', args=[d.arg(name='netIpv4TcpKeepaliveTime', type=d.T.number)]),
            withNetIpv4TcpKeepaliveTime(netIpv4TcpKeepaliveTime): { netIpv4TcpKeepaliveTime: netIpv4TcpKeepaliveTime },
            '#withNetIpv4TcpMaxSynBacklog':: d.fn(help='"The sysctl setting net.ipv4.tcp_max_syn_backlog. Must be between 128 and 3240000."', args=[d.arg(name='netIpv4TcpMaxSynBacklog', type=d.T.number)]),
            withNetIpv4TcpMaxSynBacklog(netIpv4TcpMaxSynBacklog): { netIpv4TcpMaxSynBacklog: netIpv4TcpMaxSynBacklog },
            '#withNetIpv4TcpMaxTwBuckets':: d.fn(help='"The sysctl setting net.ipv4.tcp_max_tw_buckets. Must be between 8000 and 1440000."', args=[d.arg(name='netIpv4TcpMaxTwBuckets', type=d.T.number)]),
            withNetIpv4TcpMaxTwBuckets(netIpv4TcpMaxTwBuckets): { netIpv4TcpMaxTwBuckets: netIpv4TcpMaxTwBuckets },
            '#withNetIpv4TcpTwReuse':: d.fn(help='"The sysctl setting net.ipv4.tcp_tw_reuse."', args=[d.arg(name='netIpv4TcpTwReuse', type=d.T.boolean)]),
            withNetIpv4TcpTwReuse(netIpv4TcpTwReuse): { netIpv4TcpTwReuse: netIpv4TcpTwReuse },
            '#withNetNetfilterNfConntrackBuckets':: d.fn(help='"The sysctl setting net.netfilter.nf_conntrack_buckets. Must be between 65536 and 524288."', args=[d.arg(name='netNetfilterNfConntrackBuckets', type=d.T.number)]),
            withNetNetfilterNfConntrackBuckets(netNetfilterNfConntrackBuckets): { netNetfilterNfConntrackBuckets: netNetfilterNfConntrackBuckets },
            '#withNetNetfilterNfConntrackMax':: d.fn(help='"The sysctl setting net.netfilter.nf_conntrack_max. Must be between 131072 and 2097152."', args=[d.arg(name='netNetfilterNfConntrackMax', type=d.T.number)]),
            withNetNetfilterNfConntrackMax(netNetfilterNfConntrackMax): { netNetfilterNfConntrackMax: netNetfilterNfConntrackMax },
            '#withVmMaxMapCount':: d.fn(help='"The sysctl setting vm.max_map_count. Must be between 65530 and 262144."', args=[d.arg(name='vmMaxMapCount', type=d.T.number)]),
            withVmMaxMapCount(vmMaxMapCount): { vmMaxMapCount: vmMaxMapCount },
            '#withVmSwappiness':: d.fn(help='"The sysctl setting vm.swappiness. Must be between 0 and 100."', args=[d.arg(name='vmSwappiness', type=d.T.number)]),
            withVmSwappiness(vmSwappiness): { vmSwappiness: vmSwappiness },
            '#withVmVfsCachePressure':: d.fn(help='"The sysctl setting vm.vfs_cache_pressure. Must be between 0 and 100."', args=[d.arg(name='vmVfsCachePressure', type=d.T.number)]),
            withVmVfsCachePressure(vmVfsCachePressure): { vmVfsCachePressure: vmVfsCachePressure },
          },
          '#withSwapFileSizeMb':: d.fn(help='"Specifies the size of the swap file on each node in MB."', args=[d.arg(name='swapFileSizeMb', type=d.T.number)]),
          withSwapFileSizeMb(swapFileSizeMb): { swapFileSizeMb: swapFileSizeMb },
          '#withSysctlConfig':: d.fn(help='"A sysctl_config block as defined below."', args=[d.arg(name='sysctlConfig', type=d.T.array)]),
          withSysctlConfig(sysctlConfig): { sysctlConfig: if std.isArray(v=sysctlConfig) then sysctlConfig else [sysctlConfig] },
          '#withSysctlConfigMixin':: d.fn(help='"A sysctl_config block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sysctlConfig', type=d.T.array)]),
          withSysctlConfigMixin(sysctlConfig): { sysctlConfig+: if std.isArray(v=sysctlConfig) then sysctlConfig else [sysctlConfig] },
          '#withTransparentHugePage':: d.fn(help='"Specifies the Transparent Huge Page configuration. Possible values are always, madvise and never."', args=[d.arg(name='transparentHugePage', type=d.T.string)]),
          withTransparentHugePage(transparentHugePage): { transparentHugePage: transparentHugePage },
          '#withTransparentHugePageDefrag':: d.fn(help='"specifies the defrag configuration for Transparent Huge Page. Possible values are always, defer, defer+madvise, madvise and never."', args=[d.arg(name='transparentHugePageDefrag', type=d.T.string)]),
          withTransparentHugePageDefrag(transparentHugePageDefrag): { transparentHugePageDefrag: transparentHugePageDefrag },
          '#withTransparentHugePageEnabled':: d.fn(help='', args=[d.arg(name='transparentHugePageEnabled', type=d.T.string)]),
          withTransparentHugePageEnabled(transparentHugePageEnabled): { transparentHugePageEnabled: transparentHugePageEnabled },
        },
        '#nodeNetworkProfile':: d.obj(help='"A node_network_profile block as documented below."'),
        nodeNetworkProfile: {
          '#allowedHostPorts':: d.obj(help='"One or more allowed_host_ports blocks as defined below."'),
          allowedHostPorts: {
            '#withPortEnd':: d.fn(help='"Specifies the end of the port range."', args=[d.arg(name='portEnd', type=d.T.number)]),
            withPortEnd(portEnd): { portEnd: portEnd },
            '#withPortStart':: d.fn(help='"Specifies the start of the port range."', args=[d.arg(name='portStart', type=d.T.number)]),
            withPortStart(portStart): { portStart: portStart },
            '#withProtocol':: d.fn(help='"Specifies the protocol of the port range. Possible values are TCP and UDP."', args=[d.arg(name='protocol', type=d.T.string)]),
            withProtocol(protocol): { protocol: protocol },
          },
          '#withAllowedHostPorts':: d.fn(help='"One or more allowed_host_ports blocks as defined below."', args=[d.arg(name='allowedHostPorts', type=d.T.array)]),
          withAllowedHostPorts(allowedHostPorts): { allowedHostPorts: if std.isArray(v=allowedHostPorts) then allowedHostPorts else [allowedHostPorts] },
          '#withAllowedHostPortsMixin':: d.fn(help='"One or more allowed_host_ports blocks as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='allowedHostPorts', type=d.T.array)]),
          withAllowedHostPortsMixin(allowedHostPorts): { allowedHostPorts+: if std.isArray(v=allowedHostPorts) then allowedHostPorts else [allowedHostPorts] },
          '#withApplicationSecurityGroupIds':: d.fn(help='"A list of Application Security Group IDs which should be associated with this Node Pool."', args=[d.arg(name='applicationSecurityGroupIds', type=d.T.array)]),
          withApplicationSecurityGroupIds(applicationSecurityGroupIds): { applicationSecurityGroupIds: if std.isArray(v=applicationSecurityGroupIds) then applicationSecurityGroupIds else [applicationSecurityGroupIds] },
          '#withApplicationSecurityGroupIdsMixin':: d.fn(help='"A list of Application Security Group IDs which should be associated with this Node Pool."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='applicationSecurityGroupIds', type=d.T.array)]),
          withApplicationSecurityGroupIdsMixin(applicationSecurityGroupIds): { applicationSecurityGroupIds+: if std.isArray(v=applicationSecurityGroupIds) then applicationSecurityGroupIds else [applicationSecurityGroupIds] },
          '#withNodePublicIpTags':: d.fn(help='"Specifies a mapping of tags to the instance-level public IPs. Changing this forces a new resource to be created."', args=[d.arg(name='nodePublicIpTags', type=d.T.object)]),
          withNodePublicIpTags(nodePublicIpTags): { nodePublicIpTags: nodePublicIpTags },
          '#withNodePublicIpTagsMixin':: d.fn(help='"Specifies a mapping of tags to the instance-level public IPs. Changing this forces a new resource to be created."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodePublicIpTags', type=d.T.object)]),
          withNodePublicIpTagsMixin(nodePublicIpTags): { nodePublicIpTags+: nodePublicIpTags },
        },
        '#podSubnetIdRef':: d.obj(help='"Reference to a Subnet in network to populate podSubnetId."'),
        podSubnetIdRef: {
          '#policy':: d.obj(help='"Policies for referencing."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { podSubnetIdRef+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { podSubnetIdRef+: { policy+: { resolve: resolve } } },
          },
          '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { podSubnetIdRef+: { name: name } },
        },
        '#podSubnetIdSelector':: d.obj(help='"Selector for a Subnet in network to populate podSubnetId."'),
        podSubnetIdSelector: {
          '#policy':: d.obj(help='"Policies for selection."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { podSubnetIdSelector+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { podSubnetIdSelector+: { policy+: { resolve: resolve } } },
          },
          '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference\\nas the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
          withMatchControllerRef(matchControllerRef): { podSubnetIdSelector+: { matchControllerRef: matchControllerRef } },
          '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabels(matchLabels): { podSubnetIdSelector+: { matchLabels: matchLabels } },
          '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabelsMixin(matchLabels): { podSubnetIdSelector+: { matchLabels+: matchLabels } },
        },
        '#upgradeSettings':: d.obj(help='"A upgrade_settings block as documented below."'),
        upgradeSettings: {
          '#withDrainTimeoutInMinutes':: d.fn(help='"The amount of time in minutes to wait on eviction of pods and graceful termination per node. This eviction wait time honors pod disruption budgets for upgrades. If this time is exceeded, the upgrade fails. Unsetting this after configuring it will force a new resource to be created."', args=[d.arg(name='drainTimeoutInMinutes', type=d.T.number)]),
          withDrainTimeoutInMinutes(drainTimeoutInMinutes): { drainTimeoutInMinutes: drainTimeoutInMinutes },
          '#withMaxSurge':: d.fn(help='"The maximum number or percentage of nodes which will be added to the Node Pool size during an upgrade."', args=[d.arg(name='maxSurge', type=d.T.string)]),
          withMaxSurge(maxSurge): { maxSurge: maxSurge },
          '#withNodeSoakDurationInMinutes':: d.fn(help='"The amount of time in minutes to wait after draining a node and before reimaging and moving on to next node."', args=[d.arg(name='nodeSoakDurationInMinutes', type=d.T.number)]),
          withNodeSoakDurationInMinutes(nodeSoakDurationInMinutes): { nodeSoakDurationInMinutes: nodeSoakDurationInMinutes },
          '#withUndrainableNodeBehavior':: d.fn(help='"Specifies the action when a node is undrainable during upgrade. Possible values are Cordon and Schedule. Unsetting this after configuring it will force a new resource to be created."', args=[d.arg(name='undrainableNodeBehavior', type=d.T.string)]),
          withUndrainableNodeBehavior(undrainableNodeBehavior): { undrainableNodeBehavior: undrainableNodeBehavior },
        },
        '#vnetSubnetIdRef':: d.obj(help='"Reference to a Subnet in network to populate vnetSubnetId."'),
        vnetSubnetIdRef: {
          '#policy':: d.obj(help='"Policies for referencing."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { vnetSubnetIdRef+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { vnetSubnetIdRef+: { policy+: { resolve: resolve } } },
          },
          '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { vnetSubnetIdRef+: { name: name } },
        },
        '#vnetSubnetIdSelector':: d.obj(help='"Selector for a Subnet in network to populate vnetSubnetId."'),
        vnetSubnetIdSelector: {
          '#policy':: d.obj(help='"Policies for selection."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { vnetSubnetIdSelector+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { vnetSubnetIdSelector+: { policy+: { resolve: resolve } } },
          },
          '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference\\nas the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
          withMatchControllerRef(matchControllerRef): { vnetSubnetIdSelector+: { matchControllerRef: matchControllerRef } },
          '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabels(matchLabels): { vnetSubnetIdSelector+: { matchLabels: matchLabels } },
          '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabelsMixin(matchLabels): { vnetSubnetIdSelector+: { matchLabels+: matchLabels } },
        },
        '#withAutoScalingEnabled':: d.fn(help='"Should the Kubernetes Auto Scaler be enabled for this Node Pool?"', args=[d.arg(name='autoScalingEnabled', type=d.T.boolean)]),
        withAutoScalingEnabled(autoScalingEnabled): { autoScalingEnabled: autoScalingEnabled },
        '#withCapacityReservationGroupId':: d.fn(help='"Specifies the ID of the Capacity Reservation Group within which this AKS Cluster should be created. Changing this forces a new resource to be created."', args=[d.arg(name='capacityReservationGroupId', type=d.T.string)]),
        withCapacityReservationGroupId(capacityReservationGroupId): { capacityReservationGroupId: capacityReservationGroupId },
        '#withFipsEnabled':: d.fn(help='"Should the nodes in this Node Pool have Federal Information Processing Standard enabled? temporary_name_for_rotation must be specified when changing this block."', args=[d.arg(name='fipsEnabled', type=d.T.boolean)]),
        withFipsEnabled(fipsEnabled): { fipsEnabled: fipsEnabled },
        '#withGpuDriver':: d.fn(help='"Specifies the driver type for GPU nodes. Possible values are Install and None. Changing this forces a new resource to be created."', args=[d.arg(name='gpuDriver', type=d.T.string)]),
        withGpuDriver(gpuDriver): { gpuDriver: gpuDriver },
        '#withGpuInstance':: d.fn(help='"Specifies the GPU MIG instance profile for supported GPU VM SKU. The allowed values are MIG1g, MIG2g, MIG3g, MIG4g and MIG7g. Changing this forces a new resource to be created."', args=[d.arg(name='gpuInstance', type=d.T.string)]),
        withGpuInstance(gpuInstance): { gpuInstance: gpuInstance },
        '#withHostEncryptionEnabled':: d.fn(help='"Should the nodes in the Default Node Pool have host encryption enabled? temporary_name_for_rotation must be specified when changing this property."', args=[d.arg(name='hostEncryptionEnabled', type=d.T.boolean)]),
        withHostEncryptionEnabled(hostEncryptionEnabled): { hostEncryptionEnabled: hostEncryptionEnabled },
        '#withHostGroupId':: d.fn(help='"Specifies the ID of the Host Group within which this AKS Cluster should be created. Changing this forces a new resource to be created."', args=[d.arg(name='hostGroupId', type=d.T.string)]),
        withHostGroupId(hostGroupId): { hostGroupId: hostGroupId },
        '#withKubeletConfig':: d.fn(help='"A kubelet_config block as defined below. temporary_name_for_rotation must be specified when changing this block."', args=[d.arg(name='kubeletConfig', type=d.T.array)]),
        withKubeletConfig(kubeletConfig): { kubeletConfig: if std.isArray(v=kubeletConfig) then kubeletConfig else [kubeletConfig] },
        '#withKubeletConfigMixin':: d.fn(help='"A kubelet_config block as defined below. temporary_name_for_rotation must be specified when changing this block."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='kubeletConfig', type=d.T.array)]),
        withKubeletConfigMixin(kubeletConfig): { kubeletConfig+: if std.isArray(v=kubeletConfig) then kubeletConfig else [kubeletConfig] },
        '#withKubeletDiskType':: d.fn(help='"The type of disk used by kubelet. Possible values are OS and Temporary. temporary_name_for_rotation must be specified when changing this block."', args=[d.arg(name='kubeletDiskType', type=d.T.string)]),
        withKubeletDiskType(kubeletDiskType): { kubeletDiskType: kubeletDiskType },
        '#withLinuxOsConfig':: d.fn(help='"A linux_os_config block as defined below. temporary_name_for_rotation must be specified when changing this block."', args=[d.arg(name='linuxOsConfig', type=d.T.array)]),
        withLinuxOsConfig(linuxOsConfig): { linuxOsConfig: if std.isArray(v=linuxOsConfig) then linuxOsConfig else [linuxOsConfig] },
        '#withLinuxOsConfigMixin':: d.fn(help='"A linux_os_config block as defined below. temporary_name_for_rotation must be specified when changing this block."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='linuxOsConfig', type=d.T.array)]),
        withLinuxOsConfigMixin(linuxOsConfig): { linuxOsConfig+: if std.isArray(v=linuxOsConfig) then linuxOsConfig else [linuxOsConfig] },
        '#withMaxCount':: d.fn(help='"The maximum number of nodes which should exist in this Node Pool. If specified this must be between 1 and 1000."', args=[d.arg(name='maxCount', type=d.T.number)]),
        withMaxCount(maxCount): { maxCount: maxCount },
        '#withMaxPods':: d.fn(help='"The maximum number of pods that can run on each agent. temporary_name_for_rotation must be specified when changing this property."', args=[d.arg(name='maxPods', type=d.T.number)]),
        withMaxPods(maxPods): { maxPods: maxPods },
        '#withMinCount':: d.fn(help='"The minimum number of nodes which should exist in this Node Pool. If specified this must be between 1 and 1000."', args=[d.arg(name='minCount', type=d.T.number)]),
        withMinCount(minCount): { minCount: minCount },
        '#withName':: d.fn(help='"The name which should be used for the default Kubernetes Node Pool."', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
        '#withNodeCount':: d.fn(help='"The initial number of nodes which should exist in this Node Pool. If specified this must be between 1 and 1000 and between min_count and max_count."', args=[d.arg(name='nodeCount', type=d.T.number)]),
        withNodeCount(nodeCount): { nodeCount: nodeCount },
        '#withNodeLabels':: d.fn(help='"A map of Kubernetes labels which should be applied to nodes in the Default Node Pool."', args=[d.arg(name='nodeLabels', type=d.T.object)]),
        withNodeLabels(nodeLabels): { nodeLabels: nodeLabels },
        '#withNodeLabelsMixin':: d.fn(help='"A map of Kubernetes labels which should be applied to nodes in the Default Node Pool."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodeLabels', type=d.T.object)]),
        withNodeLabelsMixin(nodeLabels): { nodeLabels+: nodeLabels },
        '#withNodeNetworkProfile':: d.fn(help='"A node_network_profile block as documented below."', args=[d.arg(name='nodeNetworkProfile', type=d.T.array)]),
        withNodeNetworkProfile(nodeNetworkProfile): { nodeNetworkProfile: if std.isArray(v=nodeNetworkProfile) then nodeNetworkProfile else [nodeNetworkProfile] },
        '#withNodeNetworkProfileMixin':: d.fn(help='"A node_network_profile block as documented below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodeNetworkProfile', type=d.T.array)]),
        withNodeNetworkProfileMixin(nodeNetworkProfile): { nodeNetworkProfile+: if std.isArray(v=nodeNetworkProfile) then nodeNetworkProfile else [nodeNetworkProfile] },
        '#withNodePublicIpEnabled':: d.fn(help='"Should nodes in this Node Pool have a Public IP Address? temporary_name_for_rotation must be specified when changing this property."', args=[d.arg(name='nodePublicIpEnabled', type=d.T.boolean)]),
        withNodePublicIpEnabled(nodePublicIpEnabled): { nodePublicIpEnabled: nodePublicIpEnabled },
        '#withNodePublicIpPrefixId':: d.fn(help='"Resource ID for the Public IP Addresses Prefix for the nodes in this Node Pool. node_public_ip_enabled should be true. Changing this forces a new resource to be created."', args=[d.arg(name='nodePublicIpPrefixId', type=d.T.string)]),
        withNodePublicIpPrefixId(nodePublicIpPrefixId): { nodePublicIpPrefixId: nodePublicIpPrefixId },
        '#withOnlyCriticalAddonsEnabled':: d.fn(help='"Enabling this option will taint default node pool with CriticalAddonsOnly=true:NoSchedule taint. temporary_name_for_rotation must be specified when changing this property."', args=[d.arg(name='onlyCriticalAddonsEnabled', type=d.T.boolean)]),
        withOnlyCriticalAddonsEnabled(onlyCriticalAddonsEnabled): { onlyCriticalAddonsEnabled: onlyCriticalAddonsEnabled },
        '#withOrchestratorVersion':: d.fn(help="\"Version of Kubernetes used for the Agents. If not specified, the default node pool will be created with the version specified by kubernetes_version. If both are unspecified, the latest recommended version will be used at provisioning time (but won't auto-upgrade). AKS does not require an exact patch version to be specified, minor version aliases such as 1.22 are also supported. - The minor version's latest GA patch is automatically chosen in that case. More details can be found in the documentation.\"", args=[d.arg(name='orchestratorVersion', type=d.T.string)]),
        withOrchestratorVersion(orchestratorVersion): { orchestratorVersion: orchestratorVersion },
        '#withOsDiskSizeGb':: d.fn(help='"The size of the OS Disk which should be used for each agent in the Node Pool. temporary_name_for_rotation must be specified when attempting a change."', args=[d.arg(name='osDiskSizeGb', type=d.T.number)]),
        withOsDiskSizeGb(osDiskSizeGb): { osDiskSizeGb: osDiskSizeGb },
        '#withOsDiskType':: d.fn(help='"The type of disk which should be used for the Operating System. Possible values are Ephemeral and Managed. Defaults to Managed. temporary_name_for_rotation must be specified when attempting a change."', args=[d.arg(name='osDiskType', type=d.T.string)]),
        withOsDiskType(osDiskType): { osDiskType: osDiskType },
        '#withOsSku':: d.fn(help='"Specifies the OS SKU used by the agent pool. Possible values are AzureLinux, AzureLinux3, Ubuntu, Ubuntu2204, Windows2019 and Windows2022. If not specified, the default is Ubuntu if OSType=Linux or Windows2019 if OSType=Windows. And the default Windows OSSKU will be changed to Windows2022 after Windows2019 is deprecated. Changing this from AzureLinux or Ubuntu to AzureLinux or Ubuntu will not replace the resource, otherwise temporary_name_for_rotation must be specified when attempting a change."', args=[d.arg(name='osSku', type=d.T.string)]),
        withOsSku(osSku): { osSku: osSku },
        '#withPodSubnetId':: d.fn(help='"The ID of the Subnet where the pods in the default Node Pool should exist."', args=[d.arg(name='podSubnetId', type=d.T.string)]),
        withPodSubnetId(podSubnetId): { podSubnetId: podSubnetId },
        '#withProximityPlacementGroupId':: d.fn(help='"The ID of the Proximity Placement Group. Changing this forces a new resource to be created."', args=[d.arg(name='proximityPlacementGroupId', type=d.T.string)]),
        withProximityPlacementGroupId(proximityPlacementGroupId): { proximityPlacementGroupId: proximityPlacementGroupId },
        '#withScaleDownMode':: d.fn(help='"Specifies the autoscaling behaviour of the Kubernetes Cluster. Allowed values are Delete and Deallocate. Defaults to Delete."', args=[d.arg(name='scaleDownMode', type=d.T.string)]),
        withScaleDownMode(scaleDownMode): { scaleDownMode: scaleDownMode },
        '#withSnapshotId':: d.fn(help='"The ID of the Snapshot which should be used to create this default Node Pool. temporary_name_for_rotation must be specified when changing this property."', args=[d.arg(name='snapshotId', type=d.T.string)]),
        withSnapshotId(snapshotId): { snapshotId: snapshotId },
        '#withTags':: d.fn(help='"A mapping of tags to assign to the Node Pool."', args=[d.arg(name='tags', type=d.T.object)]),
        withTags(tags): { tags: tags },
        '#withTagsMixin':: d.fn(help='"A mapping of tags to assign to the Node Pool."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tags', type=d.T.object)]),
        withTagsMixin(tags): { tags+: tags },
        '#withTemporaryNameForRotation':: d.fn(help='"Specifies the name of the temporary node pool used to cycle the default node pool for VM resizing."', args=[d.arg(name='temporaryNameForRotation', type=d.T.string)]),
        withTemporaryNameForRotation(temporaryNameForRotation): { temporaryNameForRotation: temporaryNameForRotation },
        '#withType':: d.fn(help='"The type of Node Pool which should be created. Possible values are VirtualMachineScaleSets. Defaults to VirtualMachineScaleSets. Changing this forces a new resource to be created."', args=[d.arg(name='type', type=d.T.string)]),
        withType(type): { type: type },
        '#withUltraSsdEnabled':: d.fn(help='"Used to specify whether the UltraSSD is enabled in the Default Node Pool. Defaults to false. See the documentation for more information. temporary_name_for_rotation must be specified when attempting a change."', args=[d.arg(name='ultraSsdEnabled', type=d.T.boolean)]),
        withUltraSsdEnabled(ultraSsdEnabled): { ultraSsdEnabled: ultraSsdEnabled },
        '#withUpgradeSettings':: d.fn(help='"A upgrade_settings block as documented below."', args=[d.arg(name='upgradeSettings', type=d.T.array)]),
        withUpgradeSettings(upgradeSettings): { upgradeSettings: if std.isArray(v=upgradeSettings) then upgradeSettings else [upgradeSettings] },
        '#withUpgradeSettingsMixin':: d.fn(help='"A upgrade_settings block as documented below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='upgradeSettings', type=d.T.array)]),
        withUpgradeSettingsMixin(upgradeSettings): { upgradeSettings+: if std.isArray(v=upgradeSettings) then upgradeSettings else [upgradeSettings] },
        '#withVmSize':: d.fn(help='"The size of the Virtual Machine, such as Standard_DS2_v2. temporary_name_for_rotation must be specified when attempting a resize."', args=[d.arg(name='vmSize', type=d.T.string)]),
        withVmSize(vmSize): { vmSize: vmSize },
        '#withVnetSubnetId':: d.fn(help='"The ID of a Subnet where the Kubernetes Node Pool should exist."', args=[d.arg(name='vnetSubnetId', type=d.T.string)]),
        withVnetSubnetId(vnetSubnetId): { vnetSubnetId: vnetSubnetId },
        '#withWorkloadRuntime':: d.fn(help='"Specifies the workload runtime used by the node pool. Possible value is OCIContainer."', args=[d.arg(name='workloadRuntime', type=d.T.string)]),
        withWorkloadRuntime(workloadRuntime): { workloadRuntime: workloadRuntime },
        '#withZones':: d.fn(help='"Specifies a list of Availability Zones in which this Kubernetes Cluster should be located. temporary_name_for_rotation must be specified when changing this property."', args=[d.arg(name='zones', type=d.T.array)]),
        withZones(zones): { zones: if std.isArray(v=zones) then zones else [zones] },
        '#withZonesMixin':: d.fn(help='"Specifies a list of Availability Zones in which this Kubernetes Cluster should be located. temporary_name_for_rotation must be specified when changing this property."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='zones', type=d.T.array)]),
        withZonesMixin(zones): { zones+: if std.isArray(v=zones) then zones else [zones] },
      },
      '#httpProxyConfig':: d.obj(help='"A http_proxy_config block as defined below."'),
      httpProxyConfig: {
        '#trustedCaSecretRef':: d.obj(help='"The base64 encoded alternative CA certificate content in PEM format."'),
        trustedCaSecretRef: {
          '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { trustedCaSecretRef+: { key: key } },
          '#withName':: d.fn(help='"Name of the secret."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { trustedCaSecretRef+: { name: name } },
          '#withNamespace':: d.fn(help='"Namespace of the secret."', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { trustedCaSecretRef+: { namespace: namespace } },
        },
        '#withHttpProxy':: d.fn(help='"The proxy address to be used when communicating over HTTP."', args=[d.arg(name='httpProxy', type=d.T.string)]),
        withHttpProxy(httpProxy): { httpProxy: httpProxy },
        '#withHttpsProxy':: d.fn(help='"The proxy address to be used when communicating over HTTPS."', args=[d.arg(name='httpsProxy', type=d.T.string)]),
        withHttpsProxy(httpsProxy): { httpsProxy: httpsProxy },
        '#withNoProxy':: d.fn(help='"The list of domains that will not use the proxy for communication."', args=[d.arg(name='noProxy', type=d.T.array)]),
        withNoProxy(noProxy): { noProxy: if std.isArray(v=noProxy) then noProxy else [noProxy] },
        '#withNoProxyMixin':: d.fn(help='"The list of domains that will not use the proxy for communication."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='noProxy', type=d.T.array)]),
        withNoProxyMixin(noProxy): { noProxy+: if std.isArray(v=noProxy) then noProxy else [noProxy] },
      },
      '#identity':: d.obj(help='"An identity block as defined below. One of either identity or service_principal must be specified."'),
      identity: {
        '#identityIdsRefs':: d.obj(help='"References to UserAssignedIdentity in managedidentity to populate identityIds."'),
        identityIdsRefs: {
          '#policy':: d.obj(help='"Policies for referencing."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { policy+: { resolution: resolution } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { policy+: { resolve: resolve } },
          },
          '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
        },
        '#identityIdsSelector':: d.obj(help='"Selector for a list of UserAssignedIdentity in managedidentity to populate identityIds."'),
        identityIdsSelector: {
          '#policy':: d.obj(help='"Policies for selection."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { identityIdsSelector+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { identityIdsSelector+: { policy+: { resolve: resolve } } },
          },
          '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference\\nas the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
          withMatchControllerRef(matchControllerRef): { identityIdsSelector+: { matchControllerRef: matchControllerRef } },
          '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabels(matchLabels): { identityIdsSelector+: { matchLabels: matchLabels } },
          '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabelsMixin(matchLabels): { identityIdsSelector+: { matchLabels+: matchLabels } },
        },
        '#withIdentityIds':: d.fn(help='"Specifies a list of User Assigned Managed Identity IDs to be assigned to this Kubernetes Cluster."', args=[d.arg(name='identityIds', type=d.T.array)]),
        withIdentityIds(identityIds): { identityIds: if std.isArray(v=identityIds) then identityIds else [identityIds] },
        '#withIdentityIdsMixin':: d.fn(help='"Specifies a list of User Assigned Managed Identity IDs to be assigned to this Kubernetes Cluster."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='identityIds', type=d.T.array)]),
        withIdentityIdsMixin(identityIds): { identityIds+: if std.isArray(v=identityIds) then identityIds else [identityIds] },
        '#withIdentityIdsRefs':: d.fn(help='"References to UserAssignedIdentity in managedidentity to populate identityIds."', args=[d.arg(name='identityIdsRefs', type=d.T.array)]),
        withIdentityIdsRefs(identityIdsRefs): { identityIdsRefs: if std.isArray(v=identityIdsRefs) then identityIdsRefs else [identityIdsRefs] },
        '#withIdentityIdsRefsMixin':: d.fn(help='"References to UserAssignedIdentity in managedidentity to populate identityIds."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='identityIdsRefs', type=d.T.array)]),
        withIdentityIdsRefsMixin(identityIdsRefs): { identityIdsRefs+: if std.isArray(v=identityIdsRefs) then identityIdsRefs else [identityIdsRefs] },
        '#withType':: d.fn(help='"Specifies the type of Managed Service Identity that should be configured on this Kubernetes Cluster. Possible values are SystemAssigned or UserAssigned."', args=[d.arg(name='type', type=d.T.string)]),
        withType(type): { type: type },
      },
      '#ingressApplicationGateway':: d.obj(help='"An ingress_application_gateway block as defined below."'),
      ingressApplicationGateway: {
        '#subnetIdRef':: d.obj(help='"Reference to a Subnet in network to populate subnetId."'),
        subnetIdRef: {
          '#policy':: d.obj(help='"Policies for referencing."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { subnetIdRef+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { subnetIdRef+: { policy+: { resolve: resolve } } },
          },
          '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { subnetIdRef+: { name: name } },
        },
        '#subnetIdSelector':: d.obj(help='"Selector for a Subnet in network to populate subnetId."'),
        subnetIdSelector: {
          '#policy':: d.obj(help='"Policies for selection."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { subnetIdSelector+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { subnetIdSelector+: { policy+: { resolve: resolve } } },
          },
          '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference\\nas the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
          withMatchControllerRef(matchControllerRef): { subnetIdSelector+: { matchControllerRef: matchControllerRef } },
          '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabels(matchLabels): { subnetIdSelector+: { matchLabels: matchLabels } },
          '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabelsMixin(matchLabels): { subnetIdSelector+: { matchLabels+: matchLabels } },
        },
        '#withGatewayId':: d.fn(help='"The ID of the Application Gateway to integrate with the ingress controller of this Kubernetes Cluster. See this page for further details."', args=[d.arg(name='gatewayId', type=d.T.string)]),
        withGatewayId(gatewayId): { gatewayId: gatewayId },
        '#withGatewayName':: d.fn(help='"The name of the Application Gateway to be used or created in the Nodepool Resource Group, which in turn will be integrated with the ingress controller of this Kubernetes Cluster. See this page for further details."', args=[d.arg(name='gatewayName', type=d.T.string)]),
        withGatewayName(gatewayName): { gatewayName: gatewayName },
        '#withSubnetCidr':: d.fn(help='"The subnet CIDR to be used to create an Application Gateway, which in turn will be integrated with the ingress controller of this Kubernetes Cluster. See this page for further details."', args=[d.arg(name='subnetCidr', type=d.T.string)]),
        withSubnetCidr(subnetCidr): { subnetCidr: subnetCidr },
        '#withSubnetId':: d.fn(help='"The ID of the subnet on which to create an Application Gateway, which in turn will be integrated with the ingress controller of this Kubernetes Cluster. See this page for further details."', args=[d.arg(name='subnetId', type=d.T.string)]),
        withSubnetId(subnetId): { subnetId: subnetId },
      },
      '#keyManagementService':: d.obj(help='"A key_management_service block as defined below. For more details, please visit Key Management Service (KMS) etcd encryption to an AKS cluster."'),
      keyManagementService: {
        '#withKeyVaultKeyId':: d.fn(help='"Identifier of Azure Key Vault key. See key identifier format for more details."', args=[d.arg(name='keyVaultKeyId', type=d.T.string)]),
        withKeyVaultKeyId(keyVaultKeyId): { keyVaultKeyId: keyVaultKeyId },
        '#withKeyVaultNetworkAccess':: d.fn(help='"Network access of the key vault Network access of key vault. The possible values are Public and Private. Public means the key vault allows public access from all networks. Private means the key vault disables public access and enables private link. Defaults to Public."', args=[d.arg(name='keyVaultNetworkAccess', type=d.T.string)]),
        withKeyVaultNetworkAccess(keyVaultNetworkAccess): { keyVaultNetworkAccess: keyVaultNetworkAccess },
      },
      '#keyVaultSecretsProvider':: d.obj(help='"A key_vault_secrets_provider block as defined below."'),
      keyVaultSecretsProvider: {
        '#withSecretRotationEnabled':: d.fn(help='"Should the secret store CSI driver on the AKS cluster be enabled?"', args=[d.arg(name='secretRotationEnabled', type=d.T.boolean)]),
        withSecretRotationEnabled(secretRotationEnabled): { secretRotationEnabled: secretRotationEnabled },
        '#withSecretRotationInterval':: d.fn(help='"The interval to poll for secret rotation. This attribute is only set when secret_rotation_enabled is true. Defaults to 2m."', args=[d.arg(name='secretRotationInterval', type=d.T.string)]),
        withSecretRotationInterval(secretRotationInterval): { secretRotationInterval: secretRotationInterval },
      },
      '#kubeletIdentity':: d.obj(help='"A kubelet_identity block as defined below."'),
      kubeletIdentity: {
        '#withClientId':: d.fn(help='"The Client ID of the user-defined Managed Identity to be assigned to the Kubelets. If not specified a Managed Identity is created automatically. Changing this forces a new resource to be created."', args=[d.arg(name='clientId', type=d.T.string)]),
        withClientId(clientId): { clientId: clientId },
        '#withObjectId':: d.fn(help='"The Object ID of the user-defined Managed Identity assigned to the Kubelets.If not specified a Managed Identity is created automatically. Changing this forces a new resource to be created."', args=[d.arg(name='objectId', type=d.T.string)]),
        withObjectId(objectId): { objectId: objectId },
        '#withUserAssignedIdentityId':: d.fn(help='"The ID of the User Assigned Identity assigned to the Kubelets. If not specified a Managed Identity is created automatically. Changing this forces a new resource to be created."', args=[d.arg(name='userAssignedIdentityId', type=d.T.string)]),
        withUserAssignedIdentityId(userAssignedIdentityId): { userAssignedIdentityId: userAssignedIdentityId },
      },
      '#linuxProfile':: d.obj(help='"A linux_profile block as defined below."'),
      linuxProfile: {
        '#sshKey':: d.obj(help='"An ssh_key block as defined below. Only one is currently allowed. Changing this will update the key on all node pools. More information can be found in the documentation."'),
        sshKey: {
          '#withKeyData':: d.fn(help='"The Public SSH Key used to access the cluster. Changing this forces a new resource to be created."', args=[d.arg(name='keyData', type=d.T.string)]),
          withKeyData(keyData): { keyData: keyData },
        },
        '#withAdminUsername':: d.fn(help='"The Admin Username for the Cluster. Changing this forces a new resource to be created."', args=[d.arg(name='adminUsername', type=d.T.string)]),
        withAdminUsername(adminUsername): { adminUsername: adminUsername },
        '#withSshKey':: d.fn(help='"An ssh_key block as defined below. Only one is currently allowed. Changing this will update the key on all node pools. More information can be found in the documentation."', args=[d.arg(name='sshKey', type=d.T.array)]),
        withSshKey(sshKey): { sshKey: if std.isArray(v=sshKey) then sshKey else [sshKey] },
        '#withSshKeyMixin':: d.fn(help='"An ssh_key block as defined below. Only one is currently allowed. Changing this will update the key on all node pools. More information can be found in the documentation."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sshKey', type=d.T.array)]),
        withSshKeyMixin(sshKey): { sshKey+: if std.isArray(v=sshKey) then sshKey else [sshKey] },
      },
      '#maintenanceWindow':: d.obj(help='"A maintenance_window block as defined below."'),
      maintenanceWindow: {
        '#allowed':: d.obj(help='"One or more allowed blocks as defined below."'),
        allowed: {
          '#withDay':: d.fn(help='"A day in a week. Possible values are Sunday, Monday, Tuesday, Wednesday, Thursday, Friday and Saturday."', args=[d.arg(name='day', type=d.T.string)]),
          withDay(day): { day: day },
          '#withHours':: d.fn(help='"An array of hour slots in a day. For example, specifying 1 will allow maintenance from 1:00am to 2:00am. Specifying 1, 2 will allow maintenance from 1:00am to 3:00m. Possible values are between 0 and 23."', args=[d.arg(name='hours', type=d.T.array)]),
          withHours(hours): { hours: if std.isArray(v=hours) then hours else [hours] },
          '#withHoursMixin':: d.fn(help='"An array of hour slots in a day. For example, specifying 1 will allow maintenance from 1:00am to 2:00am. Specifying 1, 2 will allow maintenance from 1:00am to 3:00m. Possible values are between 0 and 23."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='hours', type=d.T.array)]),
          withHoursMixin(hours): { hours+: if std.isArray(v=hours) then hours else [hours] },
        },
        '#notAllowed':: d.obj(help='"One or more not_allowed block as defined below."'),
        notAllowed: {
          '#withEnd':: d.fn(help='"The end of a time span, formatted as an RFC3339 string."', args=[d.arg(name='end', type=d.T.string)]),
          withEnd(end): { end: end },
          '#withStart':: d.fn(help='"The start of a time span, formatted as an RFC3339 string."', args=[d.arg(name='start', type=d.T.string)]),
          withStart(start): { start: start },
        },
        '#withAllowed':: d.fn(help='"One or more allowed blocks as defined below."', args=[d.arg(name='allowed', type=d.T.array)]),
        withAllowed(allowed): { allowed: if std.isArray(v=allowed) then allowed else [allowed] },
        '#withAllowedMixin':: d.fn(help='"One or more allowed blocks as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='allowed', type=d.T.array)]),
        withAllowedMixin(allowed): { allowed+: if std.isArray(v=allowed) then allowed else [allowed] },
        '#withNotAllowed':: d.fn(help='"One or more not_allowed block as defined below."', args=[d.arg(name='notAllowed', type=d.T.array)]),
        withNotAllowed(notAllowed): { notAllowed: if std.isArray(v=notAllowed) then notAllowed else [notAllowed] },
        '#withNotAllowedMixin':: d.fn(help='"One or more not_allowed block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='notAllowed', type=d.T.array)]),
        withNotAllowedMixin(notAllowed): { notAllowed+: if std.isArray(v=notAllowed) then notAllowed else [notAllowed] },
      },
      '#maintenanceWindowAutoUpgrade':: d.obj(help='"A maintenance_window_auto_upgrade block as defined below."'),
      maintenanceWindowAutoUpgrade: {
        '#notAllowed':: d.obj(help='"One or more not_allowed block as defined below."'),
        notAllowed: {
          '#withEnd':: d.fn(help='"The end of a time span, formatted as an RFC3339 string."', args=[d.arg(name='end', type=d.T.string)]),
          withEnd(end): { end: end },
          '#withStart':: d.fn(help='"The start of a time span, formatted as an RFC3339 string."', args=[d.arg(name='start', type=d.T.string)]),
          withStart(start): { start: start },
        },
        '#withDayOfMonth':: d.fn(help='"The day of the month for the maintenance run. Required in combination with AbsoluteMonthly frequency. Value between 0 and 31 (inclusive)."', args=[d.arg(name='dayOfMonth', type=d.T.number)]),
        withDayOfMonth(dayOfMonth): { dayOfMonth: dayOfMonth },
        '#withDayOfWeek':: d.fn(help='"The day of the week for the maintenance run. Required in combination with weekly frequency. Possible values are Friday, Monday, Saturday, Sunday, Thursday, Tuesday and Wednesday."', args=[d.arg(name='dayOfWeek', type=d.T.string)]),
        withDayOfWeek(dayOfWeek): { dayOfWeek: dayOfWeek },
        '#withDuration':: d.fn(help='"The duration of the window for maintenance to run in hours. Possible options are between 4 to 24."', args=[d.arg(name='duration', type=d.T.number)]),
        withDuration(duration): { duration: duration },
        '#withFrequency':: d.fn(help='"Frequency of maintenance. Possible options are Daily, Weekly, AbsoluteMonthly and RelativeMonthly."', args=[d.arg(name='frequency', type=d.T.string)]),
        withFrequency(frequency): { frequency: frequency },
        '#withInterval':: d.fn(help='"The interval for maintenance runs. Depending on the frequency this interval is week or month based."', args=[d.arg(name='interval', type=d.T.number)]),
        withInterval(interval): { interval: interval },
        '#withNotAllowed':: d.fn(help='"One or more not_allowed block as defined below."', args=[d.arg(name='notAllowed', type=d.T.array)]),
        withNotAllowed(notAllowed): { notAllowed: if std.isArray(v=notAllowed) then notAllowed else [notAllowed] },
        '#withNotAllowedMixin':: d.fn(help='"One or more not_allowed block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='notAllowed', type=d.T.array)]),
        withNotAllowedMixin(notAllowed): { notAllowed+: if std.isArray(v=notAllowed) then notAllowed else [notAllowed] },
        '#withStartDate':: d.fn(help='"The date on which the maintenance window begins to take effect."', args=[d.arg(name='startDate', type=d.T.string)]),
        withStartDate(startDate): { startDate: startDate },
        '#withStartTime':: d.fn(help='"The time for maintenance to begin, based on the timezone determined by utc_offset. Format is HH:mm."', args=[d.arg(name='startTime', type=d.T.string)]),
        withStartTime(startTime): { startTime: startTime },
        '#withUtcOffset':: d.fn(help='"Used to determine the timezone for cluster maintenance."', args=[d.arg(name='utcOffset', type=d.T.string)]),
        withUtcOffset(utcOffset): { utcOffset: utcOffset },
        '#withWeekIndex':: d.fn(help='"Specifies on which instance of the allowed days specified in day_of_week the maintenance occurs. Options are First, Second, Third, Fourth, and Last.\\nRequired in combination with relative monthly frequency."', args=[d.arg(name='weekIndex', type=d.T.string)]),
        withWeekIndex(weekIndex): { weekIndex: weekIndex },
      },
      '#maintenanceWindowNodeOs':: d.obj(help='"A maintenance_window_node_os block as defined below."'),
      maintenanceWindowNodeOs: {
        '#notAllowed':: d.obj(help='"One or more not_allowed block as defined below."'),
        notAllowed: {
          '#withEnd':: d.fn(help='"The end of a time span, formatted as an RFC3339 string."', args=[d.arg(name='end', type=d.T.string)]),
          withEnd(end): { end: end },
          '#withStart':: d.fn(help='"The start of a time span, formatted as an RFC3339 string."', args=[d.arg(name='start', type=d.T.string)]),
          withStart(start): { start: start },
        },
        '#withDayOfMonth':: d.fn(help='"The day of the month for the maintenance run. Required in combination with AbsoluteMonthly frequency. Value between 0 and 31 (inclusive)."', args=[d.arg(name='dayOfMonth', type=d.T.number)]),
        withDayOfMonth(dayOfMonth): { dayOfMonth: dayOfMonth },
        '#withDayOfWeek':: d.fn(help='"The day of the week for the maintenance run. Required in combination with weekly frequency. Possible values are Friday, Monday, Saturday, Sunday, Thursday, Tuesday and Wednesday."', args=[d.arg(name='dayOfWeek', type=d.T.string)]),
        withDayOfWeek(dayOfWeek): { dayOfWeek: dayOfWeek },
        '#withDuration':: d.fn(help='"The duration of the window for maintenance to run in hours. Possible options are between 4 to 24."', args=[d.arg(name='duration', type=d.T.number)]),
        withDuration(duration): { duration: duration },
        '#withFrequency':: d.fn(help='"Frequency of maintenance. Possible options are Daily, Weekly, AbsoluteMonthly and RelativeMonthly."', args=[d.arg(name='frequency', type=d.T.string)]),
        withFrequency(frequency): { frequency: frequency },
        '#withInterval':: d.fn(help='"The interval for maintenance runs. Depending on the frequency this interval is week or month based."', args=[d.arg(name='interval', type=d.T.number)]),
        withInterval(interval): { interval: interval },
        '#withNotAllowed':: d.fn(help='"One or more not_allowed block as defined below."', args=[d.arg(name='notAllowed', type=d.T.array)]),
        withNotAllowed(notAllowed): { notAllowed: if std.isArray(v=notAllowed) then notAllowed else [notAllowed] },
        '#withNotAllowedMixin':: d.fn(help='"One or more not_allowed block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='notAllowed', type=d.T.array)]),
        withNotAllowedMixin(notAllowed): { notAllowed+: if std.isArray(v=notAllowed) then notAllowed else [notAllowed] },
        '#withStartDate':: d.fn(help='"The date on which the maintenance window begins to take effect."', args=[d.arg(name='startDate', type=d.T.string)]),
        withStartDate(startDate): { startDate: startDate },
        '#withStartTime':: d.fn(help='"The time for maintenance to begin, based on the timezone determined by utc_offset. Format is HH:mm."', args=[d.arg(name='startTime', type=d.T.string)]),
        withStartTime(startTime): { startTime: startTime },
        '#withUtcOffset':: d.fn(help='"Used to determine the timezone for cluster maintenance."', args=[d.arg(name='utcOffset', type=d.T.string)]),
        withUtcOffset(utcOffset): { utcOffset: utcOffset },
        '#withWeekIndex':: d.fn(help='"The week in the month used for the maintenance run. Options are First, Second, Third, Fourth, and Last."', args=[d.arg(name='weekIndex', type=d.T.string)]),
        withWeekIndex(weekIndex): { weekIndex: weekIndex },
      },
      '#microsoftDefender':: d.obj(help='"A microsoft_defender block as defined below."'),
      microsoftDefender: {
        '#withLogAnalyticsWorkspaceId':: d.fn(help='"Specifies the ID of the Log Analytics Workspace where the audit logs collected by Microsoft Defender should be sent to."', args=[d.arg(name='logAnalyticsWorkspaceId', type=d.T.string)]),
        withLogAnalyticsWorkspaceId(logAnalyticsWorkspaceId): { logAnalyticsWorkspaceId: logAnalyticsWorkspaceId },
      },
      '#monitorMetrics':: d.obj(help='"Specifies a Prometheus add-on profile for the Kubernetes Cluster. A monitor_metrics block as defined below."'),
      monitorMetrics: {
        '#withAnnotationsAllowed':: d.fn(help="\"Specifies a comma-separated list of Kubernetes annotation keys that will be used in the resource's labels metric.\"", args=[d.arg(name='annotationsAllowed', type=d.T.string)]),
        withAnnotationsAllowed(annotationsAllowed): { annotationsAllowed: annotationsAllowed },
        '#withLabelsAllowed':: d.fn(help="\"Specifies a Comma-separated list of additional Kubernetes label keys that will be used in the resource's labels metric.\"", args=[d.arg(name='labelsAllowed', type=d.T.string)]),
        withLabelsAllowed(labelsAllowed): { labelsAllowed: labelsAllowed },
      },
      '#networkProfile':: d.obj(help='"A network_profile block as defined below."'),
      networkProfile: {
        '#advancedNetworking':: d.obj(help='"An advanced_networking block as defined below. This can only be specified when network_plugin is set to azure and network_data_plane is set to cilium."'),
        advancedNetworking: {
          '#withObservabilityEnabled':: d.fn(help='"Is observability enabled? Defaults to false."', args=[d.arg(name='observabilityEnabled', type=d.T.boolean)]),
          withObservabilityEnabled(observabilityEnabled): { observabilityEnabled: observabilityEnabled },
          '#withSecurityEnabled':: d.fn(help='"Is security enabled? Defaults to false."', args=[d.arg(name='securityEnabled', type=d.T.boolean)]),
          withSecurityEnabled(securityEnabled): { securityEnabled: securityEnabled },
        },
        '#loadBalancerProfile':: d.obj(help='"A load_balancer_profile block as defined below. This can only be specified when load_balancer_sku is set to standard. Changing this forces a new resource to be created."'),
        loadBalancerProfile: {
          '#withBackendPoolType':: d.fn(help='"The type of the managed inbound Load Balancer Backend Pool. Possible values are NodeIP and NodeIPConfiguration. Defaults to NodeIPConfiguration. See the documentation for more information."', args=[d.arg(name='backendPoolType', type=d.T.string)]),
          withBackendPoolType(backendPoolType): { backendPoolType: backendPoolType },
          '#withIdleTimeoutInMinutes':: d.fn(help='"Desired outbound flow idle timeout in minutes for the managed nat gateway. Must be between 4 and 120 inclusive. Defaults to 4."', args=[d.arg(name='idleTimeoutInMinutes', type=d.T.number)]),
          withIdleTimeoutInMinutes(idleTimeoutInMinutes): { idleTimeoutInMinutes: idleTimeoutInMinutes },
          '#withManagedOutboundIpCount':: d.fn(help='"Count of desired managed outbound IPs for the managed nat gateway. Must be between 1 and 16 inclusive."', args=[d.arg(name='managedOutboundIpCount', type=d.T.number)]),
          withManagedOutboundIpCount(managedOutboundIpCount): { managedOutboundIpCount: managedOutboundIpCount },
          '#withManagedOutboundIpv6Count':: d.fn(help='"The desired number of IPv6 outbound IPs created and managed by Azure for the cluster load balancer. Must be in the range of 1 to 100 (inclusive). The default value is 0 for single-stack and 1 for dual-stack."', args=[d.arg(name='managedOutboundIpv6Count', type=d.T.number)]),
          withManagedOutboundIpv6Count(managedOutboundIpv6Count): { managedOutboundIpv6Count: managedOutboundIpv6Count },
          '#withOutboundIpAddressIds':: d.fn(help='"The ID of the Public IP Addresses which should be used for outbound communication for the cluster load balancer."', args=[d.arg(name='outboundIpAddressIds', type=d.T.array)]),
          withOutboundIpAddressIds(outboundIpAddressIds): { outboundIpAddressIds: if std.isArray(v=outboundIpAddressIds) then outboundIpAddressIds else [outboundIpAddressIds] },
          '#withOutboundIpAddressIdsMixin':: d.fn(help='"The ID of the Public IP Addresses which should be used for outbound communication for the cluster load balancer."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='outboundIpAddressIds', type=d.T.array)]),
          withOutboundIpAddressIdsMixin(outboundIpAddressIds): { outboundIpAddressIds+: if std.isArray(v=outboundIpAddressIds) then outboundIpAddressIds else [outboundIpAddressIds] },
          '#withOutboundIpPrefixIds':: d.fn(help='"The ID of the outbound Public IP Address Prefixes which should be used for the cluster load balancer."', args=[d.arg(name='outboundIpPrefixIds', type=d.T.array)]),
          withOutboundIpPrefixIds(outboundIpPrefixIds): { outboundIpPrefixIds: if std.isArray(v=outboundIpPrefixIds) then outboundIpPrefixIds else [outboundIpPrefixIds] },
          '#withOutboundIpPrefixIdsMixin':: d.fn(help='"The ID of the outbound Public IP Address Prefixes which should be used for the cluster load balancer."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='outboundIpPrefixIds', type=d.T.array)]),
          withOutboundIpPrefixIdsMixin(outboundIpPrefixIds): { outboundIpPrefixIds+: if std.isArray(v=outboundIpPrefixIds) then outboundIpPrefixIds else [outboundIpPrefixIds] },
          '#withOutboundPortsAllocated':: d.fn(help='"Number of desired SNAT port for each VM in the clusters load balancer. Must be between 0 and 64000 inclusive. Defaults to 0."', args=[d.arg(name='outboundPortsAllocated', type=d.T.number)]),
          withOutboundPortsAllocated(outboundPortsAllocated): { outboundPortsAllocated: outboundPortsAllocated },
        },
        '#natGatewayProfile':: d.obj(help='"A nat_gateway_profile block as defined below. This can only be specified when load_balancer_sku is set to standard and outbound_type is set to managedNATGateway or userAssignedNATGateway. Changing this forces a new resource to be created."'),
        natGatewayProfile: {
          '#withIdleTimeoutInMinutes':: d.fn(help='"Desired outbound flow idle timeout in minutes for the managed nat gateway. Must be between 4 and 120 inclusive. Defaults to 4."', args=[d.arg(name='idleTimeoutInMinutes', type=d.T.number)]),
          withIdleTimeoutInMinutes(idleTimeoutInMinutes): { idleTimeoutInMinutes: idleTimeoutInMinutes },
          '#withManagedOutboundIpCount':: d.fn(help='"Count of desired managed outbound IPs for the managed nat gateway. Must be between 1 and 16 inclusive."', args=[d.arg(name='managedOutboundIpCount', type=d.T.number)]),
          withManagedOutboundIpCount(managedOutboundIpCount): { managedOutboundIpCount: managedOutboundIpCount },
        },
        '#withAdvancedNetworking':: d.fn(help='"An advanced_networking block as defined below. This can only be specified when network_plugin is set to azure and network_data_plane is set to cilium."', args=[d.arg(name='advancedNetworking', type=d.T.array)]),
        withAdvancedNetworking(advancedNetworking): { advancedNetworking: if std.isArray(v=advancedNetworking) then advancedNetworking else [advancedNetworking] },
        '#withAdvancedNetworkingMixin':: d.fn(help='"An advanced_networking block as defined below. This can only be specified when network_plugin is set to azure and network_data_plane is set to cilium."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='advancedNetworking', type=d.T.array)]),
        withAdvancedNetworkingMixin(advancedNetworking): { advancedNetworking+: if std.isArray(v=advancedNetworking) then advancedNetworking else [advancedNetworking] },
        '#withDnsServiceIp':: d.fn(help='"IP address within the Kubernetes service address range that will be used by cluster service discovery (kube-dns). Changing this forces a new resource to be created."', args=[d.arg(name='dnsServiceIp', type=d.T.string)]),
        withDnsServiceIp(dnsServiceIp): { dnsServiceIp: dnsServiceIp },
        '#withIpVersions':: d.fn(help='"Specifies a list of IP versions the Kubernetes Cluster will use to assign IP addresses to its nodes and pods. Possible values are IPv4 and/or IPv6. IPv4 must always be specified. Changing this forces a new resource to be created."', args=[d.arg(name='ipVersions', type=d.T.array)]),
        withIpVersions(ipVersions): { ipVersions: if std.isArray(v=ipVersions) then ipVersions else [ipVersions] },
        '#withIpVersionsMixin':: d.fn(help='"Specifies a list of IP versions the Kubernetes Cluster will use to assign IP addresses to its nodes and pods. Possible values are IPv4 and/or IPv6. IPv4 must always be specified. Changing this forces a new resource to be created."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ipVersions', type=d.T.array)]),
        withIpVersionsMixin(ipVersions): { ipVersions+: if std.isArray(v=ipVersions) then ipVersions else [ipVersions] },
        '#withLoadBalancerProfile':: d.fn(help='"A load_balancer_profile block as defined below. This can only be specified when load_balancer_sku is set to standard. Changing this forces a new resource to be created."', args=[d.arg(name='loadBalancerProfile', type=d.T.array)]),
        withLoadBalancerProfile(loadBalancerProfile): { loadBalancerProfile: if std.isArray(v=loadBalancerProfile) then loadBalancerProfile else [loadBalancerProfile] },
        '#withLoadBalancerProfileMixin':: d.fn(help='"A load_balancer_profile block as defined below. This can only be specified when load_balancer_sku is set to standard. Changing this forces a new resource to be created."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='loadBalancerProfile', type=d.T.array)]),
        withLoadBalancerProfileMixin(loadBalancerProfile): { loadBalancerProfile+: if std.isArray(v=loadBalancerProfile) then loadBalancerProfile else [loadBalancerProfile] },
        '#withLoadBalancerSku':: d.fn(help='"Specifies the SKU of the Load Balancer used for this Kubernetes Cluster. Possible values are basic and standard. Defaults to standard. Changing this forces a new resource to be created."', args=[d.arg(name='loadBalancerSku', type=d.T.string)]),
        withLoadBalancerSku(loadBalancerSku): { loadBalancerSku: loadBalancerSku },
        '#withNatGatewayProfile':: d.fn(help='"A nat_gateway_profile block as defined below. This can only be specified when load_balancer_sku is set to standard and outbound_type is set to managedNATGateway or userAssignedNATGateway. Changing this forces a new resource to be created."', args=[d.arg(name='natGatewayProfile', type=d.T.array)]),
        withNatGatewayProfile(natGatewayProfile): { natGatewayProfile: if std.isArray(v=natGatewayProfile) then natGatewayProfile else [natGatewayProfile] },
        '#withNatGatewayProfileMixin':: d.fn(help='"A nat_gateway_profile block as defined below. This can only be specified when load_balancer_sku is set to standard and outbound_type is set to managedNATGateway or userAssignedNATGateway. Changing this forces a new resource to be created."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='natGatewayProfile', type=d.T.array)]),
        withNatGatewayProfileMixin(natGatewayProfile): { natGatewayProfile+: if std.isArray(v=natGatewayProfile) then natGatewayProfile else [natGatewayProfile] },
        '#withNetworkDataPlane':: d.fn(help='"Specifies the data plane used for building the Kubernetes network. Possible values are azure and cilium. Defaults to azure. Disabling this forces a new resource to be created."', args=[d.arg(name='networkDataPlane', type=d.T.string)]),
        withNetworkDataPlane(networkDataPlane): { networkDataPlane: networkDataPlane },
        '#withNetworkMode':: d.fn(help='"Network mode to be used with Azure CNI. Possible values are bridge and transparent. Changing this forces a new resource to be created."', args=[d.arg(name='networkMode', type=d.T.string)]),
        withNetworkMode(networkMode): { networkMode: networkMode },
        '#withNetworkPlugin':: d.fn(help='"Network plugin to use for networking. Currently supported values are azure, kubenet and none. Changing this forces a new resource to be created."', args=[d.arg(name='networkPlugin', type=d.T.string)]),
        withNetworkPlugin(networkPlugin): { networkPlugin: networkPlugin },
        '#withNetworkPluginMode':: d.fn(help='"Specifies the network plugin mode used for building the Kubernetes network. Possible value is overlay."', args=[d.arg(name='networkPluginMode', type=d.T.string)]),
        withNetworkPluginMode(networkPluginMode): { networkPluginMode: networkPluginMode },
        '#withNetworkPolicy':: d.fn(help='"Sets up network policy to be used with Azure CNI. Network policy allows us to control the traffic flow between pods. Currently supported values are calico, azure and cilium."', args=[d.arg(name='networkPolicy', type=d.T.string)]),
        withNetworkPolicy(networkPolicy): { networkPolicy: networkPolicy },
        '#withOutboundType':: d.fn(help='"The outbound (egress) routing method which should be used for this Kubernetes Cluster. Possible values are loadBalancer, userDefinedRouting, managedNATGateway, userAssignedNATGateway and none. Defaults to loadBalancer."', args=[d.arg(name='outboundType', type=d.T.string)]),
        withOutboundType(outboundType): { outboundType: outboundType },
        '#withPodCidr':: d.fn(help='"The CIDR to use for pod IP addresses. This field can only be set when network_plugin is set to kubenet or network_plugin_mode is set to overlay. Changing this forces a new resource to be created."', args=[d.arg(name='podCidr', type=d.T.string)]),
        withPodCidr(podCidr): { podCidr: podCidr },
        '#withPodCidrs':: d.fn(help='"A list of CIDRs to use for pod IP addresses. For single-stack networking a single IPv4 CIDR is expected. For dual-stack networking an IPv4 and IPv6 CIDR are expected. Changing this forces a new resource to be created."', args=[d.arg(name='podCidrs', type=d.T.array)]),
        withPodCidrs(podCidrs): { podCidrs: if std.isArray(v=podCidrs) then podCidrs else [podCidrs] },
        '#withPodCidrsMixin':: d.fn(help='"A list of CIDRs to use for pod IP addresses. For single-stack networking a single IPv4 CIDR is expected. For dual-stack networking an IPv4 and IPv6 CIDR are expected. Changing this forces a new resource to be created."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='podCidrs', type=d.T.array)]),
        withPodCidrsMixin(podCidrs): { podCidrs+: if std.isArray(v=podCidrs) then podCidrs else [podCidrs] },
        '#withServiceCidr':: d.fn(help='"The Network Range used by the Kubernetes service. Changing this forces a new resource to be created."', args=[d.arg(name='serviceCidr', type=d.T.string)]),
        withServiceCidr(serviceCidr): { serviceCidr: serviceCidr },
        '#withServiceCidrs':: d.fn(help='"A list of CIDRs to use for Kubernetes services. For single-stack networking a single IPv4 CIDR is expected. For dual-stack networking an IPv4 and IPv6 CIDR are expected. Changing this forces a new resource to be created."', args=[d.arg(name='serviceCidrs', type=d.T.array)]),
        withServiceCidrs(serviceCidrs): { serviceCidrs: if std.isArray(v=serviceCidrs) then serviceCidrs else [serviceCidrs] },
        '#withServiceCidrsMixin':: d.fn(help='"A list of CIDRs to use for Kubernetes services. For single-stack networking a single IPv4 CIDR is expected. For dual-stack networking an IPv4 and IPv6 CIDR are expected. Changing this forces a new resource to be created."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='serviceCidrs', type=d.T.array)]),
        withServiceCidrsMixin(serviceCidrs): { serviceCidrs+: if std.isArray(v=serviceCidrs) then serviceCidrs else [serviceCidrs] },
      },
      '#omsAgent':: d.obj(help='"An oms_agent block as defined below."'),
      omsAgent: {
        '#withLogAnalyticsWorkspaceId':: d.fn(help='"The ID of the Log Analytics Workspace which the OMS Agent should send data to."', args=[d.arg(name='logAnalyticsWorkspaceId', type=d.T.string)]),
        withLogAnalyticsWorkspaceId(logAnalyticsWorkspaceId): { logAnalyticsWorkspaceId: logAnalyticsWorkspaceId },
        '#withMsiAuthForMonitoringEnabled':: d.fn(help='"Is managed identity authentication for monitoring enabled?"', args=[d.arg(name='msiAuthForMonitoringEnabled', type=d.T.boolean)]),
        withMsiAuthForMonitoringEnabled(msiAuthForMonitoringEnabled): { msiAuthForMonitoringEnabled: msiAuthForMonitoringEnabled },
      },
      '#privateDnsZoneIdRef':: d.obj(help='"Reference to a PrivateDNSZone in network to populate privateDnsZoneId."'),
      privateDnsZoneIdRef: {
        '#policy':: d.obj(help='"Policies for referencing."'),
        policy: {
          '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
          withResolution(resolution): { spec+: { forProvider+: { privateDnsZoneIdRef+: { policy+: { resolution: resolution } } } } },
          '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
          withResolve(resolve): { spec+: { forProvider+: { privateDnsZoneIdRef+: { policy+: { resolve: resolve } } } } },
        },
        '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { forProvider+: { privateDnsZoneIdRef+: { name: name } } } },
      },
      '#privateDnsZoneIdSelector':: d.obj(help='"Selector for a PrivateDNSZone in network to populate privateDnsZoneId."'),
      privateDnsZoneIdSelector: {
        '#policy':: d.obj(help='"Policies for selection."'),
        policy: {
          '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
          withResolution(resolution): { spec+: { forProvider+: { privateDnsZoneIdSelector+: { policy+: { resolution: resolution } } } } },
          '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
          withResolve(resolve): { spec+: { forProvider+: { privateDnsZoneIdSelector+: { policy+: { resolve: resolve } } } } },
        },
        '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference\\nas the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
        withMatchControllerRef(matchControllerRef): { spec+: { forProvider+: { privateDnsZoneIdSelector+: { matchControllerRef: matchControllerRef } } } },
        '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
        withMatchLabels(matchLabels): { spec+: { forProvider+: { privateDnsZoneIdSelector+: { matchLabels: matchLabels } } } },
        '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
        withMatchLabelsMixin(matchLabels): { spec+: { forProvider+: { privateDnsZoneIdSelector+: { matchLabels+: matchLabels } } } },
      },
      '#resourceGroupNameRef':: d.obj(help='"Reference to a ResourceGroup in azure to populate resourceGroupName."'),
      resourceGroupNameRef: {
        '#policy':: d.obj(help='"Policies for referencing."'),
        policy: {
          '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
          withResolution(resolution): { spec+: { forProvider+: { resourceGroupNameRef+: { policy+: { resolution: resolution } } } } },
          '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
          withResolve(resolve): { spec+: { forProvider+: { resourceGroupNameRef+: { policy+: { resolve: resolve } } } } },
        },
        '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { forProvider+: { resourceGroupNameRef+: { name: name } } } },
      },
      '#resourceGroupNameSelector':: d.obj(help='"Selector for a ResourceGroup in azure to populate resourceGroupName."'),
      resourceGroupNameSelector: {
        '#policy':: d.obj(help='"Policies for selection."'),
        policy: {
          '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
          withResolution(resolution): { spec+: { forProvider+: { resourceGroupNameSelector+: { policy+: { resolution: resolution } } } } },
          '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
          withResolve(resolve): { spec+: { forProvider+: { resourceGroupNameSelector+: { policy+: { resolve: resolve } } } } },
        },
        '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference\\nas the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
        withMatchControllerRef(matchControllerRef): { spec+: { forProvider+: { resourceGroupNameSelector+: { matchControllerRef: matchControllerRef } } } },
        '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
        withMatchLabels(matchLabels): { spec+: { forProvider+: { resourceGroupNameSelector+: { matchLabels: matchLabels } } } },
        '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
        withMatchLabelsMixin(matchLabels): { spec+: { forProvider+: { resourceGroupNameSelector+: { matchLabels+: matchLabels } } } },
      },
      '#serviceMeshProfile':: d.obj(help='"A service_mesh_profile block as defined below."'),
      serviceMeshProfile: {
        '#certificateAuthority':: d.obj(help='"A certificate_authority block as defined below. When this property is specified, key_vault_secrets_provider is also required to be set. This configuration allows you to bring your own root certificate and keys for Istio CA in the Istio-based service mesh add-on for Azure Kubernetes Service."'),
        certificateAuthority: {
          '#withCertChainObjectName':: d.fn(help='"The certificate chain object name in Azure Key Vault."', args=[d.arg(name='certChainObjectName', type=d.T.string)]),
          withCertChainObjectName(certChainObjectName): { certChainObjectName: certChainObjectName },
          '#withCertObjectName':: d.fn(help='"The intermediate certificate object name in Azure Key Vault."', args=[d.arg(name='certObjectName', type=d.T.string)]),
          withCertObjectName(certObjectName): { certObjectName: certObjectName },
          '#withKeyObjectName':: d.fn(help='"The intermediate certificate private key object name in Azure Key Vault."', args=[d.arg(name='keyObjectName', type=d.T.string)]),
          withKeyObjectName(keyObjectName): { keyObjectName: keyObjectName },
          '#withKeyVaultId':: d.fn(help='"The resource ID of the Key Vault."', args=[d.arg(name='keyVaultId', type=d.T.string)]),
          withKeyVaultId(keyVaultId): { keyVaultId: keyVaultId },
          '#withRootCertObjectName':: d.fn(help='"The root certificate object name in Azure Key Vault."', args=[d.arg(name='rootCertObjectName', type=d.T.string)]),
          withRootCertObjectName(rootCertObjectName): { rootCertObjectName: rootCertObjectName },
        },
        '#withCertificateAuthority':: d.fn(help='"A certificate_authority block as defined below. When this property is specified, key_vault_secrets_provider is also required to be set. This configuration allows you to bring your own root certificate and keys for Istio CA in the Istio-based service mesh add-on for Azure Kubernetes Service."', args=[d.arg(name='certificateAuthority', type=d.T.array)]),
        withCertificateAuthority(certificateAuthority): { certificateAuthority: if std.isArray(v=certificateAuthority) then certificateAuthority else [certificateAuthority] },
        '#withCertificateAuthorityMixin':: d.fn(help='"A certificate_authority block as defined below. When this property is specified, key_vault_secrets_provider is also required to be set. This configuration allows you to bring your own root certificate and keys for Istio CA in the Istio-based service mesh add-on for Azure Kubernetes Service."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='certificateAuthority', type=d.T.array)]),
        withCertificateAuthorityMixin(certificateAuthority): { certificateAuthority+: if std.isArray(v=certificateAuthority) then certificateAuthority else [certificateAuthority] },
        '#withExternalIngressGatewayEnabled':: d.fn(help='"Is Istio External Ingress Gateway enabled?"', args=[d.arg(name='externalIngressGatewayEnabled', type=d.T.boolean)]),
        withExternalIngressGatewayEnabled(externalIngressGatewayEnabled): { externalIngressGatewayEnabled: externalIngressGatewayEnabled },
        '#withInternalIngressGatewayEnabled':: d.fn(help='"Is Istio Internal Ingress Gateway enabled?"', args=[d.arg(name='internalIngressGatewayEnabled', type=d.T.boolean)]),
        withInternalIngressGatewayEnabled(internalIngressGatewayEnabled): { internalIngressGatewayEnabled: internalIngressGatewayEnabled },
        '#withMode':: d.fn(help='"The mode of the service mesh. Possible value is Istio."', args=[d.arg(name='mode', type=d.T.string)]),
        withMode(mode): { mode: mode },
        '#withRevisions':: d.fn(help='"Specify 1 or 2 Istio control plane revisions for managing minor upgrades using the canary upgrade process. For example, create the resource with revisions set to [\\"asm-1-25\\"], or leave it empty (the revisions will only be known after apply). To start the canary upgrade, change revisions to [\\"asm-1-25\\", \\"asm-1-26\\"]. To roll back the canary upgrade, revert to [\\"asm-1-25\\"]. To confirm the upgrade, change to [\\"asm-1-26\\"]."', args=[d.arg(name='revisions', type=d.T.array)]),
        withRevisions(revisions): { revisions: if std.isArray(v=revisions) then revisions else [revisions] },
        '#withRevisionsMixin':: d.fn(help='"Specify 1 or 2 Istio control plane revisions for managing minor upgrades using the canary upgrade process. For example, create the resource with revisions set to [\\"asm-1-25\\"], or leave it empty (the revisions will only be known after apply). To start the canary upgrade, change revisions to [\\"asm-1-25\\", \\"asm-1-26\\"]. To roll back the canary upgrade, revert to [\\"asm-1-25\\"]. To confirm the upgrade, change to [\\"asm-1-26\\"]."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='revisions', type=d.T.array)]),
        withRevisionsMixin(revisions): { revisions+: if std.isArray(v=revisions) then revisions else [revisions] },
      },
      '#servicePrincipal':: d.obj(help='"A service_principal block as documented below. One of either identity or service_principal must be specified."'),
      servicePrincipal: {
        '#clientSecretSecretRef':: d.obj(help='"The Client Secret for the Service Principal."'),
        clientSecretSecretRef: {
          '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { clientSecretSecretRef+: { key: key } },
          '#withName':: d.fn(help='"Name of the secret."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { clientSecretSecretRef+: { name: name } },
          '#withNamespace':: d.fn(help='"Namespace of the secret."', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { clientSecretSecretRef+: { namespace: namespace } },
        },
        '#withClientId':: d.fn(help='"The Client ID for the Service Principal."', args=[d.arg(name='clientId', type=d.T.string)]),
        withClientId(clientId): { clientId: clientId },
      },
      '#storageProfile':: d.obj(help='"A storage_profile block as defined below."'),
      storageProfile: {
        '#withBlobDriverEnabled':: d.fn(help='"Is the Blob CSI driver enabled? Defaults to false."', args=[d.arg(name='blobDriverEnabled', type=d.T.boolean)]),
        withBlobDriverEnabled(blobDriverEnabled): { blobDriverEnabled: blobDriverEnabled },
        '#withDiskDriverEnabled':: d.fn(help='"Is the Disk CSI driver enabled? Defaults to true."', args=[d.arg(name='diskDriverEnabled', type=d.T.boolean)]),
        withDiskDriverEnabled(diskDriverEnabled): { diskDriverEnabled: diskDriverEnabled },
        '#withFileDriverEnabled':: d.fn(help='"Is the File CSI driver enabled? Defaults to true."', args=[d.arg(name='fileDriverEnabled', type=d.T.boolean)]),
        withFileDriverEnabled(fileDriverEnabled): { fileDriverEnabled: fileDriverEnabled },
        '#withSnapshotControllerEnabled':: d.fn(help='"Is the Snapshot Controller enabled? Defaults to true."', args=[d.arg(name='snapshotControllerEnabled', type=d.T.boolean)]),
        withSnapshotControllerEnabled(snapshotControllerEnabled): { snapshotControllerEnabled: snapshotControllerEnabled },
      },
      '#upgradeOverride':: d.obj(help='"A upgrade_override block as defined below."'),
      upgradeOverride: {
        '#withEffectiveUntil':: d.fn(help='"Specifies the duration, in RFC 3339 format (e.g., 2025-10-01T13:00:00Z), the upgrade_override values are effective. This field must be set for the upgrade_override values to take effect. The date-time must be within the next 30 days."', args=[d.arg(name='effectiveUntil', type=d.T.string)]),
        withEffectiveUntil(effectiveUntil): { effectiveUntil: effectiveUntil },
        '#withForceUpgradeEnabled':: d.fn(help='"Whether to force upgrade the cluster. Possible values are true or false."', args=[d.arg(name='forceUpgradeEnabled', type=d.T.boolean)]),
        withForceUpgradeEnabled(forceUpgradeEnabled): { forceUpgradeEnabled: forceUpgradeEnabled },
      },
      '#webAppRouting':: d.obj(help='"A web_app_routing block as defined below."'),
      webAppRouting: {
        '#withDefaultNginxController':: d.fn(help='"Specifies the ingress type for the default NginxIngressController custom resource. The allowed values are None, Internal, External and AnnotationControlled. Defaults to AnnotationControlled."', args=[d.arg(name='defaultNginxController', type=d.T.string)]),
        withDefaultNginxController(defaultNginxController): { defaultNginxController: defaultNginxController },
        '#withDnsZoneIds':: d.fn(help='"Specifies the list of the DNS Zone IDs in which DNS entries are created for applications deployed to the cluster when Web App Routing is enabled. If not using Bring-Your-Own DNS zones this property should be set to an empty list."', args=[d.arg(name='dnsZoneIds', type=d.T.array)]),
        withDnsZoneIds(dnsZoneIds): { dnsZoneIds: if std.isArray(v=dnsZoneIds) then dnsZoneIds else [dnsZoneIds] },
        '#withDnsZoneIdsMixin':: d.fn(help='"Specifies the list of the DNS Zone IDs in which DNS entries are created for applications deployed to the cluster when Web App Routing is enabled. If not using Bring-Your-Own DNS zones this property should be set to an empty list."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='dnsZoneIds', type=d.T.array)]),
        withDnsZoneIdsMixin(dnsZoneIds): { dnsZoneIds+: if std.isArray(v=dnsZoneIds) then dnsZoneIds else [dnsZoneIds] },
      },
      '#windowsProfile':: d.obj(help='"A windows_profile block as defined below."'),
      windowsProfile: {
        '#adminPasswordSecretRef':: d.obj(help='"The Admin Password for Windows VMs. Length must be between 14 and 123 characters."'),
        adminPasswordSecretRef: {
          '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { adminPasswordSecretRef+: { key: key } },
          '#withName':: d.fn(help='"Name of the secret."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { adminPasswordSecretRef+: { name: name } },
          '#withNamespace':: d.fn(help='"Namespace of the secret."', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { adminPasswordSecretRef+: { namespace: namespace } },
        },
        '#gmsa':: d.obj(help='"A gmsa block as defined below."'),
        gmsa: {
          '#withDnsServer':: d.fn(help='"Specifies the DNS server for Windows gMSA. Set this to an empty string if you have configured the DNS server in the VNet which was used to create the managed cluster."', args=[d.arg(name='dnsServer', type=d.T.string)]),
          withDnsServer(dnsServer): { dnsServer: dnsServer },
          '#withRootDomain':: d.fn(help='"Specifies the root domain name for Windows gMSA. Set this to an empty string if you have configured the DNS server in the VNet which was used to create the managed cluster."', args=[d.arg(name='rootDomain', type=d.T.string)]),
          withRootDomain(rootDomain): { rootDomain: rootDomain },
        },
        '#withAdminUsername':: d.fn(help='"The Admin Username for Windows VMs. Changing this forces a new resource to be created."', args=[d.arg(name='adminUsername', type=d.T.string)]),
        withAdminUsername(adminUsername): { adminUsername: adminUsername },
        '#withGmsa':: d.fn(help='"A gmsa block as defined below."', args=[d.arg(name='gmsa', type=d.T.array)]),
        withGmsa(gmsa): { gmsa: if std.isArray(v=gmsa) then gmsa else [gmsa] },
        '#withGmsaMixin':: d.fn(help='"A gmsa block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='gmsa', type=d.T.array)]),
        withGmsaMixin(gmsa): { gmsa+: if std.isArray(v=gmsa) then gmsa else [gmsa] },
        '#withLicense':: d.fn(help='"Specifies the type of on-premise license which should be used for Node Pool Windows Virtual Machine. At this time the only possible value is Windows_Server."', args=[d.arg(name='license', type=d.T.string)]),
        withLicense(license): { license: license },
      },
      '#withAciConnectorLinux':: d.fn(help='"A aci_connector_linux block as defined below. For more details, please visit Create and configure an AKS cluster to use virtual nodes."', args=[d.arg(name='aciConnectorLinux', type=d.T.array)]),
      withAciConnectorLinux(aciConnectorLinux): { spec+: { forProvider+: { aciConnectorLinux: if std.isArray(v=aciConnectorLinux) then aciConnectorLinux else [aciConnectorLinux] } } },
      '#withAciConnectorLinuxMixin':: d.fn(help='"A aci_connector_linux block as defined below. For more details, please visit Create and configure an AKS cluster to use virtual nodes."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='aciConnectorLinux', type=d.T.array)]),
      withAciConnectorLinuxMixin(aciConnectorLinux): { spec+: { forProvider+: { aciConnectorLinux+: if std.isArray(v=aciConnectorLinux) then aciConnectorLinux else [aciConnectorLinux] } } },
      '#withAiToolchainOperatorEnabled':: d.fn(help='"Specifies whether the AI Toolchain Operator should be enabled for the Cluster. Defaults to false."', args=[d.arg(name='aiToolchainOperatorEnabled', type=d.T.boolean)]),
      withAiToolchainOperatorEnabled(aiToolchainOperatorEnabled): { spec+: { forProvider+: { aiToolchainOperatorEnabled: aiToolchainOperatorEnabled } } },
      '#withApiServerAccessProfile':: d.fn(help='"An api_server_access_profile block as defined below."', args=[d.arg(name='apiServerAccessProfile', type=d.T.array)]),
      withApiServerAccessProfile(apiServerAccessProfile): { spec+: { forProvider+: { apiServerAccessProfile: if std.isArray(v=apiServerAccessProfile) then apiServerAccessProfile else [apiServerAccessProfile] } } },
      '#withApiServerAccessProfileMixin':: d.fn(help='"An api_server_access_profile block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='apiServerAccessProfile', type=d.T.array)]),
      withApiServerAccessProfileMixin(apiServerAccessProfile): { spec+: { forProvider+: { apiServerAccessProfile+: if std.isArray(v=apiServerAccessProfile) then apiServerAccessProfile else [apiServerAccessProfile] } } },
      '#withAutoScalerProfile':: d.fn(help='"A auto_scaler_profile block as defined below."', args=[d.arg(name='autoScalerProfile', type=d.T.array)]),
      withAutoScalerProfile(autoScalerProfile): { spec+: { forProvider+: { autoScalerProfile: if std.isArray(v=autoScalerProfile) then autoScalerProfile else [autoScalerProfile] } } },
      '#withAutoScalerProfileMixin':: d.fn(help='"A auto_scaler_profile block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='autoScalerProfile', type=d.T.array)]),
      withAutoScalerProfileMixin(autoScalerProfile): { spec+: { forProvider+: { autoScalerProfile+: if std.isArray(v=autoScalerProfile) then autoScalerProfile else [autoScalerProfile] } } },
      '#withAutomaticUpgradeChannel':: d.fn(help='"The upgrade channel for this Kubernetes Cluster. Possible values are patch, rapid, node-image and stable. Omitting this field sets this value to none."', args=[d.arg(name='automaticUpgradeChannel', type=d.T.string)]),
      withAutomaticUpgradeChannel(automaticUpgradeChannel): { spec+: { forProvider+: { automaticUpgradeChannel: automaticUpgradeChannel } } },
      '#withAzureActiveDirectoryRoleBasedAccessControl':: d.fn(help='"A azure_active_directory_role_based_access_control block as defined below."', args=[d.arg(name='azureActiveDirectoryRoleBasedAccessControl', type=d.T.array)]),
      withAzureActiveDirectoryRoleBasedAccessControl(azureActiveDirectoryRoleBasedAccessControl): { spec+: { forProvider+: { azureActiveDirectoryRoleBasedAccessControl: if std.isArray(v=azureActiveDirectoryRoleBasedAccessControl) then azureActiveDirectoryRoleBasedAccessControl else [azureActiveDirectoryRoleBasedAccessControl] } } },
      '#withAzureActiveDirectoryRoleBasedAccessControlMixin':: d.fn(help='"A azure_active_directory_role_based_access_control block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='azureActiveDirectoryRoleBasedAccessControl', type=d.T.array)]),
      withAzureActiveDirectoryRoleBasedAccessControlMixin(azureActiveDirectoryRoleBasedAccessControl): { spec+: { forProvider+: { azureActiveDirectoryRoleBasedAccessControl+: if std.isArray(v=azureActiveDirectoryRoleBasedAccessControl) then azureActiveDirectoryRoleBasedAccessControl else [azureActiveDirectoryRoleBasedAccessControl] } } },
      '#withAzurePolicyEnabled':: d.fn(help='"Should the Azure Policy Add-On be enabled? For more details please visit Understand Azure Policy for Azure Kubernetes Service"', args=[d.arg(name='azurePolicyEnabled', type=d.T.boolean)]),
      withAzurePolicyEnabled(azurePolicyEnabled): { spec+: { forProvider+: { azurePolicyEnabled: azurePolicyEnabled } } },
      '#withBootstrapProfile':: d.fn(help='"A bootstrap_profile block as defined below."', args=[d.arg(name='bootstrapProfile', type=d.T.array)]),
      withBootstrapProfile(bootstrapProfile): { spec+: { forProvider+: { bootstrapProfile: if std.isArray(v=bootstrapProfile) then bootstrapProfile else [bootstrapProfile] } } },
      '#withBootstrapProfileMixin':: d.fn(help='"A bootstrap_profile block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='bootstrapProfile', type=d.T.array)]),
      withBootstrapProfileMixin(bootstrapProfile): { spec+: { forProvider+: { bootstrapProfile+: if std.isArray(v=bootstrapProfile) then bootstrapProfile else [bootstrapProfile] } } },
      '#withConfidentialComputing':: d.fn(help='"A confidential_computing block as defined below. For more details please the documentation"', args=[d.arg(name='confidentialComputing', type=d.T.array)]),
      withConfidentialComputing(confidentialComputing): { spec+: { forProvider+: { confidentialComputing: if std.isArray(v=confidentialComputing) then confidentialComputing else [confidentialComputing] } } },
      '#withConfidentialComputingMixin':: d.fn(help='"A confidential_computing block as defined below. For more details please the documentation"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='confidentialComputing', type=d.T.array)]),
      withConfidentialComputingMixin(confidentialComputing): { spec+: { forProvider+: { confidentialComputing+: if std.isArray(v=confidentialComputing) then confidentialComputing else [confidentialComputing] } } },
      '#withCostAnalysisEnabled':: d.fn(help='"Should cost analysis be enabled for this Kubernetes Cluster? Defaults to false. The sku_tier must be set to Standard or Premium to enable this feature. Enabling this will add Kubernetes Namespace and Deployment details to the Cost Analysis views in the Azure portal."', args=[d.arg(name='costAnalysisEnabled', type=d.T.boolean)]),
      withCostAnalysisEnabled(costAnalysisEnabled): { spec+: { forProvider+: { costAnalysisEnabled: costAnalysisEnabled } } },
      '#withCustomCaTrustCertificatesBase64':: d.fn(help='"A list of up to 10 base64 encoded CA certificates that will be added to the trust store on nodes."', args=[d.arg(name='customCaTrustCertificatesBase64', type=d.T.array)]),
      withCustomCaTrustCertificatesBase64(customCaTrustCertificatesBase64): { spec+: { forProvider+: { customCaTrustCertificatesBase64: if std.isArray(v=customCaTrustCertificatesBase64) then customCaTrustCertificatesBase64 else [customCaTrustCertificatesBase64] } } },
      '#withCustomCaTrustCertificatesBase64Mixin':: d.fn(help='"A list of up to 10 base64 encoded CA certificates that will be added to the trust store on nodes."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='customCaTrustCertificatesBase64', type=d.T.array)]),
      withCustomCaTrustCertificatesBase64Mixin(customCaTrustCertificatesBase64): { spec+: { forProvider+: { customCaTrustCertificatesBase64+: if std.isArray(v=customCaTrustCertificatesBase64) then customCaTrustCertificatesBase64 else [customCaTrustCertificatesBase64] } } },
      '#withDefaultNodePool':: d.fn(help='"Specifies configuration for \\"System\\" mode node pool. A default_node_pool block as defined below."', args=[d.arg(name='defaultNodePool', type=d.T.array)]),
      withDefaultNodePool(defaultNodePool): { spec+: { forProvider+: { defaultNodePool: if std.isArray(v=defaultNodePool) then defaultNodePool else [defaultNodePool] } } },
      '#withDefaultNodePoolMixin':: d.fn(help='"Specifies configuration for \\"System\\" mode node pool. A default_node_pool block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='defaultNodePool', type=d.T.array)]),
      withDefaultNodePoolMixin(defaultNodePool): { spec+: { forProvider+: { defaultNodePool+: if std.isArray(v=defaultNodePool) then defaultNodePool else [defaultNodePool] } } },
      '#withDiskEncryptionSetId':: d.fn(help='"The ID of the Disk Encryption Set which should be used for the Nodes and Volumes. More information can be found in the documentation. Changing this forces a new resource to be created."', args=[d.arg(name='diskEncryptionSetId', type=d.T.string)]),
      withDiskEncryptionSetId(diskEncryptionSetId): { spec+: { forProvider+: { diskEncryptionSetId: diskEncryptionSetId } } },
      '#withDnsPrefix':: d.fn(help='"DNS prefix specified when creating the managed cluster. Possible values must begin and end with a letter or number, contain only letters, numbers, and hyphens and be between 1 and 54 characters in length. Changing this forces a new resource to be created."', args=[d.arg(name='dnsPrefix', type=d.T.string)]),
      withDnsPrefix(dnsPrefix): { spec+: { forProvider+: { dnsPrefix: dnsPrefix } } },
      '#withDnsPrefixPrivateCluster':: d.fn(help='"Specifies the DNS prefix to use with private clusters. Changing this forces a new resource to be created."', args=[d.arg(name='dnsPrefixPrivateCluster', type=d.T.string)]),
      withDnsPrefixPrivateCluster(dnsPrefixPrivateCluster): { spec+: { forProvider+: { dnsPrefixPrivateCluster: dnsPrefixPrivateCluster } } },
      '#withEdgeZone':: d.fn(help='"Specifies the Extended Zone (formerly called Edge Zone) within the Azure Region where this Managed Kubernetes Cluster should exist. Changing this forces a new resource to be created."', args=[d.arg(name='edgeZone', type=d.T.string)]),
      withEdgeZone(edgeZone): { spec+: { forProvider+: { edgeZone: edgeZone } } },
      '#withHttpApplicationRoutingEnabled':: d.fn(help='"Should HTTP Application Routing be enabled?"', args=[d.arg(name='httpApplicationRoutingEnabled', type=d.T.boolean)]),
      withHttpApplicationRoutingEnabled(httpApplicationRoutingEnabled): { spec+: { forProvider+: { httpApplicationRoutingEnabled: httpApplicationRoutingEnabled } } },
      '#withHttpProxyConfig':: d.fn(help='"A http_proxy_config block as defined below."', args=[d.arg(name='httpProxyConfig', type=d.T.array)]),
      withHttpProxyConfig(httpProxyConfig): { spec+: { forProvider+: { httpProxyConfig: if std.isArray(v=httpProxyConfig) then httpProxyConfig else [httpProxyConfig] } } },
      '#withHttpProxyConfigMixin':: d.fn(help='"A http_proxy_config block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpProxyConfig', type=d.T.array)]),
      withHttpProxyConfigMixin(httpProxyConfig): { spec+: { forProvider+: { httpProxyConfig+: if std.isArray(v=httpProxyConfig) then httpProxyConfig else [httpProxyConfig] } } },
      '#withIdentity':: d.fn(help='"An identity block as defined below. One of either identity or service_principal must be specified."', args=[d.arg(name='identity', type=d.T.array)]),
      withIdentity(identity): { spec+: { forProvider+: { identity: if std.isArray(v=identity) then identity else [identity] } } },
      '#withIdentityMixin':: d.fn(help='"An identity block as defined below. One of either identity or service_principal must be specified."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='identity', type=d.T.array)]),
      withIdentityMixin(identity): { spec+: { forProvider+: { identity+: if std.isArray(v=identity) then identity else [identity] } } },
      '#withImageCleanerEnabled':: d.fn(help='"Specifies whether Image Cleaner is enabled."', args=[d.arg(name='imageCleanerEnabled', type=d.T.boolean)]),
      withImageCleanerEnabled(imageCleanerEnabled): { spec+: { forProvider+: { imageCleanerEnabled: imageCleanerEnabled } } },
      '#withImageCleanerIntervalHours':: d.fn(help='"Specifies the interval in hours when images should be cleaned up."', args=[d.arg(name='imageCleanerIntervalHours', type=d.T.number)]),
      withImageCleanerIntervalHours(imageCleanerIntervalHours): { spec+: { forProvider+: { imageCleanerIntervalHours: imageCleanerIntervalHours } } },
      '#withIngressApplicationGateway':: d.fn(help='"An ingress_application_gateway block as defined below."', args=[d.arg(name='ingressApplicationGateway', type=d.T.array)]),
      withIngressApplicationGateway(ingressApplicationGateway): { spec+: { forProvider+: { ingressApplicationGateway: if std.isArray(v=ingressApplicationGateway) then ingressApplicationGateway else [ingressApplicationGateway] } } },
      '#withIngressApplicationGatewayMixin':: d.fn(help='"An ingress_application_gateway block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ingressApplicationGateway', type=d.T.array)]),
      withIngressApplicationGatewayMixin(ingressApplicationGateway): { spec+: { forProvider+: { ingressApplicationGateway+: if std.isArray(v=ingressApplicationGateway) then ingressApplicationGateway else [ingressApplicationGateway] } } },
      '#withKeyManagementService':: d.fn(help='"A key_management_service block as defined below. For more details, please visit Key Management Service (KMS) etcd encryption to an AKS cluster."', args=[d.arg(name='keyManagementService', type=d.T.array)]),
      withKeyManagementService(keyManagementService): { spec+: { forProvider+: { keyManagementService: if std.isArray(v=keyManagementService) then keyManagementService else [keyManagementService] } } },
      '#withKeyManagementServiceMixin':: d.fn(help='"A key_management_service block as defined below. For more details, please visit Key Management Service (KMS) etcd encryption to an AKS cluster."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='keyManagementService', type=d.T.array)]),
      withKeyManagementServiceMixin(keyManagementService): { spec+: { forProvider+: { keyManagementService+: if std.isArray(v=keyManagementService) then keyManagementService else [keyManagementService] } } },
      '#withKeyVaultSecretsProvider':: d.fn(help='"A key_vault_secrets_provider block as defined below."', args=[d.arg(name='keyVaultSecretsProvider', type=d.T.array)]),
      withKeyVaultSecretsProvider(keyVaultSecretsProvider): { spec+: { forProvider+: { keyVaultSecretsProvider: if std.isArray(v=keyVaultSecretsProvider) then keyVaultSecretsProvider else [keyVaultSecretsProvider] } } },
      '#withKeyVaultSecretsProviderMixin':: d.fn(help='"A key_vault_secrets_provider block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='keyVaultSecretsProvider', type=d.T.array)]),
      withKeyVaultSecretsProviderMixin(keyVaultSecretsProvider): { spec+: { forProvider+: { keyVaultSecretsProvider+: if std.isArray(v=keyVaultSecretsProvider) then keyVaultSecretsProvider else [keyVaultSecretsProvider] } } },
      '#withKubeletIdentity':: d.fn(help='"A kubelet_identity block as defined below."', args=[d.arg(name='kubeletIdentity', type=d.T.array)]),
      withKubeletIdentity(kubeletIdentity): { spec+: { forProvider+: { kubeletIdentity: if std.isArray(v=kubeletIdentity) then kubeletIdentity else [kubeletIdentity] } } },
      '#withKubeletIdentityMixin':: d.fn(help='"A kubelet_identity block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='kubeletIdentity', type=d.T.array)]),
      withKubeletIdentityMixin(kubeletIdentity): { spec+: { forProvider+: { kubeletIdentity+: if std.isArray(v=kubeletIdentity) then kubeletIdentity else [kubeletIdentity] } } },
      '#withKubernetesVersion':: d.fn(help="\"Version of Kubernetes specified when creating the AKS managed cluster. If not specified, the latest recommended version will be used at provisioning time (but won't auto-upgrade). AKS does not require an exact patch version to be specified, minor version aliases such as 1.22 are also supported. - The minor version's latest GA patch is automatically chosen in that case. More details can be found in the documentation.\"", args=[d.arg(name='kubernetesVersion', type=d.T.string)]),
      withKubernetesVersion(kubernetesVersion): { spec+: { forProvider+: { kubernetesVersion: kubernetesVersion } } },
      '#withLinuxProfile':: d.fn(help='"A linux_profile block as defined below."', args=[d.arg(name='linuxProfile', type=d.T.array)]),
      withLinuxProfile(linuxProfile): { spec+: { forProvider+: { linuxProfile: if std.isArray(v=linuxProfile) then linuxProfile else [linuxProfile] } } },
      '#withLinuxProfileMixin':: d.fn(help='"A linux_profile block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='linuxProfile', type=d.T.array)]),
      withLinuxProfileMixin(linuxProfile): { spec+: { forProvider+: { linuxProfile+: if std.isArray(v=linuxProfile) then linuxProfile else [linuxProfile] } } },
      '#withLocalAccountDisabled':: d.fn(help='"If true local accounts will be disabled. See the documentation for more information."', args=[d.arg(name='localAccountDisabled', type=d.T.boolean)]),
      withLocalAccountDisabled(localAccountDisabled): { spec+: { forProvider+: { localAccountDisabled: localAccountDisabled } } },
      '#withLocation':: d.fn(help='"The location where the Managed Kubernetes Cluster should be created. Changing this forces a new resource to be created."', args=[d.arg(name='location', type=d.T.string)]),
      withLocation(location): { spec+: { forProvider+: { location: location } } },
      '#withMaintenanceWindow':: d.fn(help='"A maintenance_window block as defined below."', args=[d.arg(name='maintenanceWindow', type=d.T.array)]),
      withMaintenanceWindow(maintenanceWindow): { spec+: { forProvider+: { maintenanceWindow: if std.isArray(v=maintenanceWindow) then maintenanceWindow else [maintenanceWindow] } } },
      '#withMaintenanceWindowAutoUpgrade':: d.fn(help='"A maintenance_window_auto_upgrade block as defined below."', args=[d.arg(name='maintenanceWindowAutoUpgrade', type=d.T.array)]),
      withMaintenanceWindowAutoUpgrade(maintenanceWindowAutoUpgrade): { spec+: { forProvider+: { maintenanceWindowAutoUpgrade: if std.isArray(v=maintenanceWindowAutoUpgrade) then maintenanceWindowAutoUpgrade else [maintenanceWindowAutoUpgrade] } } },
      '#withMaintenanceWindowAutoUpgradeMixin':: d.fn(help='"A maintenance_window_auto_upgrade block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='maintenanceWindowAutoUpgrade', type=d.T.array)]),
      withMaintenanceWindowAutoUpgradeMixin(maintenanceWindowAutoUpgrade): { spec+: { forProvider+: { maintenanceWindowAutoUpgrade+: if std.isArray(v=maintenanceWindowAutoUpgrade) then maintenanceWindowAutoUpgrade else [maintenanceWindowAutoUpgrade] } } },
      '#withMaintenanceWindowMixin':: d.fn(help='"A maintenance_window block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='maintenanceWindow', type=d.T.array)]),
      withMaintenanceWindowMixin(maintenanceWindow): { spec+: { forProvider+: { maintenanceWindow+: if std.isArray(v=maintenanceWindow) then maintenanceWindow else [maintenanceWindow] } } },
      '#withMaintenanceWindowNodeOs':: d.fn(help='"A maintenance_window_node_os block as defined below."', args=[d.arg(name='maintenanceWindowNodeOs', type=d.T.array)]),
      withMaintenanceWindowNodeOs(maintenanceWindowNodeOs): { spec+: { forProvider+: { maintenanceWindowNodeOs: if std.isArray(v=maintenanceWindowNodeOs) then maintenanceWindowNodeOs else [maintenanceWindowNodeOs] } } },
      '#withMaintenanceWindowNodeOsMixin':: d.fn(help='"A maintenance_window_node_os block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='maintenanceWindowNodeOs', type=d.T.array)]),
      withMaintenanceWindowNodeOsMixin(maintenanceWindowNodeOs): { spec+: { forProvider+: { maintenanceWindowNodeOs+: if std.isArray(v=maintenanceWindowNodeOs) then maintenanceWindowNodeOs else [maintenanceWindowNodeOs] } } },
      '#withMicrosoftDefender':: d.fn(help='"A microsoft_defender block as defined below."', args=[d.arg(name='microsoftDefender', type=d.T.array)]),
      withMicrosoftDefender(microsoftDefender): { spec+: { forProvider+: { microsoftDefender: if std.isArray(v=microsoftDefender) then microsoftDefender else [microsoftDefender] } } },
      '#withMicrosoftDefenderMixin':: d.fn(help='"A microsoft_defender block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='microsoftDefender', type=d.T.array)]),
      withMicrosoftDefenderMixin(microsoftDefender): { spec+: { forProvider+: { microsoftDefender+: if std.isArray(v=microsoftDefender) then microsoftDefender else [microsoftDefender] } } },
      '#withMonitorMetrics':: d.fn(help='"Specifies a Prometheus add-on profile for the Kubernetes Cluster. A monitor_metrics block as defined below."', args=[d.arg(name='monitorMetrics', type=d.T.array)]),
      withMonitorMetrics(monitorMetrics): { spec+: { forProvider+: { monitorMetrics: if std.isArray(v=monitorMetrics) then monitorMetrics else [monitorMetrics] } } },
      '#withMonitorMetricsMixin':: d.fn(help='"Specifies a Prometheus add-on profile for the Kubernetes Cluster. A monitor_metrics block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='monitorMetrics', type=d.T.array)]),
      withMonitorMetricsMixin(monitorMetrics): { spec+: { forProvider+: { monitorMetrics+: if std.isArray(v=monitorMetrics) then monitorMetrics else [monitorMetrics] } } },
      '#withNetworkProfile':: d.fn(help='"A network_profile block as defined below."', args=[d.arg(name='networkProfile', type=d.T.array)]),
      withNetworkProfile(networkProfile): { spec+: { forProvider+: { networkProfile: if std.isArray(v=networkProfile) then networkProfile else [networkProfile] } } },
      '#withNetworkProfileMixin':: d.fn(help='"A network_profile block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='networkProfile', type=d.T.array)]),
      withNetworkProfileMixin(networkProfile): { spec+: { forProvider+: { networkProfile+: if std.isArray(v=networkProfile) then networkProfile else [networkProfile] } } },
      '#withNodeOsUpgradeChannel':: d.fn(help="\"The upgrade channel for this Kubernetes Cluster Nodes' OS Image. Possible values are Unmanaged, SecurityPatch, NodeImage and None. Defaults to NodeImage.\"", args=[d.arg(name='nodeOsUpgradeChannel', type=d.T.string)]),
      withNodeOsUpgradeChannel(nodeOsUpgradeChannel): { spec+: { forProvider+: { nodeOsUpgradeChannel: nodeOsUpgradeChannel } } },
      '#withNodeResourceGroup':: d.fn(help='"The auto-generated Resource Group which contains the resources for this Managed Kubernetes Cluster."', args=[d.arg(name='nodeResourceGroup', type=d.T.string)]),
      withNodeResourceGroup(nodeResourceGroup): { spec+: { forProvider+: { nodeResourceGroup: nodeResourceGroup } } },
      '#withOidcIssuerEnabled':: d.fn(help='"Enable or Disable the OIDC issuer URL"', args=[d.arg(name='oidcIssuerEnabled', type=d.T.boolean)]),
      withOidcIssuerEnabled(oidcIssuerEnabled): { spec+: { forProvider+: { oidcIssuerEnabled: oidcIssuerEnabled } } },
      '#withOmsAgent':: d.fn(help='"An oms_agent block as defined below."', args=[d.arg(name='omsAgent', type=d.T.array)]),
      withOmsAgent(omsAgent): { spec+: { forProvider+: { omsAgent: if std.isArray(v=omsAgent) then omsAgent else [omsAgent] } } },
      '#withOmsAgentMixin':: d.fn(help='"An oms_agent block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='omsAgent', type=d.T.array)]),
      withOmsAgentMixin(omsAgent): { spec+: { forProvider+: { omsAgent+: if std.isArray(v=omsAgent) then omsAgent else [omsAgent] } } },
      '#withOpenServiceMeshEnabled':: d.fn(help='"Is Open Service Mesh enabled? For more details, please visit Open Service Mesh for AKS."', args=[d.arg(name='openServiceMeshEnabled', type=d.T.boolean)]),
      withOpenServiceMeshEnabled(openServiceMeshEnabled): { spec+: { forProvider+: { openServiceMeshEnabled: openServiceMeshEnabled } } },
      '#withPrivateClusterEnabled':: d.fn(help='"Should this Kubernetes Cluster have its API server only exposed on internal IP addresses? This provides a Private IP Address for the Kubernetes API on the Virtual Network where the Kubernetes Cluster is located. Defaults to false. Changing this forces a new resource to be created."', args=[d.arg(name='privateClusterEnabled', type=d.T.boolean)]),
      withPrivateClusterEnabled(privateClusterEnabled): { spec+: { forProvider+: { privateClusterEnabled: privateClusterEnabled } } },
      '#withPrivateClusterPublicFqdnEnabled':: d.fn(help='"Specifies whether a Public FQDN for this Private Cluster should be added. Defaults to false."', args=[d.arg(name='privateClusterPublicFqdnEnabled', type=d.T.boolean)]),
      withPrivateClusterPublicFqdnEnabled(privateClusterPublicFqdnEnabled): { spec+: { forProvider+: { privateClusterPublicFqdnEnabled: privateClusterPublicFqdnEnabled } } },
      '#withPrivateDnsZoneId':: d.fn(help='"Either the ID of Private DNS Zone which should be delegated to this Cluster, System to have AKS manage this or None. In case of None you will need to bring your own DNS server and set up resolving, otherwise, the cluster will have issues after provisioning. Changing this forces a new resource to be created."', args=[d.arg(name='privateDnsZoneId', type=d.T.string)]),
      withPrivateDnsZoneId(privateDnsZoneId): { spec+: { forProvider+: { privateDnsZoneId: privateDnsZoneId } } },
      '#withResourceGroupName':: d.fn(help='"Specifies the Resource Group where the Managed Kubernetes Cluster should exist. Changing this forces a new resource to be created."', args=[d.arg(name='resourceGroupName', type=d.T.string)]),
      withResourceGroupName(resourceGroupName): { spec+: { forProvider+: { resourceGroupName: resourceGroupName } } },
      '#withRoleBasedAccessControlEnabled':: d.fn(help='"Whether Role Based Access Control for the Kubernetes Cluster should be enabled. Defaults to true. Changing this forces a new resource to be created."', args=[d.arg(name='roleBasedAccessControlEnabled', type=d.T.boolean)]),
      withRoleBasedAccessControlEnabled(roleBasedAccessControlEnabled): { spec+: { forProvider+: { roleBasedAccessControlEnabled: roleBasedAccessControlEnabled } } },
      '#withRunCommandEnabled':: d.fn(help='"Whether to enable run command for the cluster or not. Defaults to true."', args=[d.arg(name='runCommandEnabled', type=d.T.boolean)]),
      withRunCommandEnabled(runCommandEnabled): { spec+: { forProvider+: { runCommandEnabled: runCommandEnabled } } },
      '#withServiceMeshProfile':: d.fn(help='"A service_mesh_profile block as defined below."', args=[d.arg(name='serviceMeshProfile', type=d.T.array)]),
      withServiceMeshProfile(serviceMeshProfile): { spec+: { forProvider+: { serviceMeshProfile: if std.isArray(v=serviceMeshProfile) then serviceMeshProfile else [serviceMeshProfile] } } },
      '#withServiceMeshProfileMixin':: d.fn(help='"A service_mesh_profile block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='serviceMeshProfile', type=d.T.array)]),
      withServiceMeshProfileMixin(serviceMeshProfile): { spec+: { forProvider+: { serviceMeshProfile+: if std.isArray(v=serviceMeshProfile) then serviceMeshProfile else [serviceMeshProfile] } } },
      '#withServicePrincipal':: d.fn(help='"A service_principal block as documented below. One of either identity or service_principal must be specified."', args=[d.arg(name='servicePrincipal', type=d.T.array)]),
      withServicePrincipal(servicePrincipal): { spec+: { forProvider+: { servicePrincipal: if std.isArray(v=servicePrincipal) then servicePrincipal else [servicePrincipal] } } },
      '#withServicePrincipalMixin':: d.fn(help='"A service_principal block as documented below. One of either identity or service_principal must be specified."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='servicePrincipal', type=d.T.array)]),
      withServicePrincipalMixin(servicePrincipal): { spec+: { forProvider+: { servicePrincipal+: if std.isArray(v=servicePrincipal) then servicePrincipal else [servicePrincipal] } } },
      '#withSkuTier':: d.fn(help='"The SKU Tier that should be used for this Kubernetes Cluster. Possible values are Free, Standard (which includes the Uptime SLA) and Premium. Defaults to Free."', args=[d.arg(name='skuTier', type=d.T.string)]),
      withSkuTier(skuTier): { spec+: { forProvider+: { skuTier: skuTier } } },
      '#withStorageProfile':: d.fn(help='"A storage_profile block as defined below."', args=[d.arg(name='storageProfile', type=d.T.array)]),
      withStorageProfile(storageProfile): { spec+: { forProvider+: { storageProfile: if std.isArray(v=storageProfile) then storageProfile else [storageProfile] } } },
      '#withStorageProfileMixin':: d.fn(help='"A storage_profile block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='storageProfile', type=d.T.array)]),
      withStorageProfileMixin(storageProfile): { spec+: { forProvider+: { storageProfile+: if std.isArray(v=storageProfile) then storageProfile else [storageProfile] } } },
      '#withSupportPlan':: d.fn(help='"Specifies the support plan which should be used for this Kubernetes Cluster. Possible values are KubernetesOfficial and AKSLongTermSupport. Defaults to KubernetesOfficial."', args=[d.arg(name='supportPlan', type=d.T.string)]),
      withSupportPlan(supportPlan): { spec+: { forProvider+: { supportPlan: supportPlan } } },
      '#withTags':: d.fn(help='"A mapping of tags to assign to the resource."', args=[d.arg(name='tags', type=d.T.object)]),
      withTags(tags): { spec+: { forProvider+: { tags: tags } } },
      '#withTagsMixin':: d.fn(help='"A mapping of tags to assign to the resource."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tags', type=d.T.object)]),
      withTagsMixin(tags): { spec+: { forProvider+: { tags+: tags } } },
      '#withUpgradeOverride':: d.fn(help='"A upgrade_override block as defined below."', args=[d.arg(name='upgradeOverride', type=d.T.array)]),
      withUpgradeOverride(upgradeOverride): { spec+: { forProvider+: { upgradeOverride: if std.isArray(v=upgradeOverride) then upgradeOverride else [upgradeOverride] } } },
      '#withUpgradeOverrideMixin':: d.fn(help='"A upgrade_override block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='upgradeOverride', type=d.T.array)]),
      withUpgradeOverrideMixin(upgradeOverride): { spec+: { forProvider+: { upgradeOverride+: if std.isArray(v=upgradeOverride) then upgradeOverride else [upgradeOverride] } } },
      '#withWebAppRouting':: d.fn(help='"A web_app_routing block as defined below."', args=[d.arg(name='webAppRouting', type=d.T.array)]),
      withWebAppRouting(webAppRouting): { spec+: { forProvider+: { webAppRouting: if std.isArray(v=webAppRouting) then webAppRouting else [webAppRouting] } } },
      '#withWebAppRoutingMixin':: d.fn(help='"A web_app_routing block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='webAppRouting', type=d.T.array)]),
      withWebAppRoutingMixin(webAppRouting): { spec+: { forProvider+: { webAppRouting+: if std.isArray(v=webAppRouting) then webAppRouting else [webAppRouting] } } },
      '#withWindowsProfile':: d.fn(help='"A windows_profile block as defined below."', args=[d.arg(name='windowsProfile', type=d.T.array)]),
      withWindowsProfile(windowsProfile): { spec+: { forProvider+: { windowsProfile: if std.isArray(v=windowsProfile) then windowsProfile else [windowsProfile] } } },
      '#withWindowsProfileMixin':: d.fn(help='"A windows_profile block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='windowsProfile', type=d.T.array)]),
      withWindowsProfileMixin(windowsProfile): { spec+: { forProvider+: { windowsProfile+: if std.isArray(v=windowsProfile) then windowsProfile else [windowsProfile] } } },
      '#withWorkloadAutoscalerProfile':: d.fn(help='"A workload_autoscaler_profile block defined below."', args=[d.arg(name='workloadAutoscalerProfile', type=d.T.array)]),
      withWorkloadAutoscalerProfile(workloadAutoscalerProfile): { spec+: { forProvider+: { workloadAutoscalerProfile: if std.isArray(v=workloadAutoscalerProfile) then workloadAutoscalerProfile else [workloadAutoscalerProfile] } } },
      '#withWorkloadAutoscalerProfileMixin':: d.fn(help='"A workload_autoscaler_profile block defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='workloadAutoscalerProfile', type=d.T.array)]),
      withWorkloadAutoscalerProfileMixin(workloadAutoscalerProfile): { spec+: { forProvider+: { workloadAutoscalerProfile+: if std.isArray(v=workloadAutoscalerProfile) then workloadAutoscalerProfile else [workloadAutoscalerProfile] } } },
      '#withWorkloadIdentityEnabled':: d.fn(help='"Specifies whether Azure AD Workload Identity should be enabled for the Cluster. Defaults to false."', args=[d.arg(name='workloadIdentityEnabled', type=d.T.boolean)]),
      withWorkloadIdentityEnabled(workloadIdentityEnabled): { spec+: { forProvider+: { workloadIdentityEnabled: workloadIdentityEnabled } } },
      '#workloadAutoscalerProfile':: d.obj(help='"A workload_autoscaler_profile block defined below."'),
      workloadAutoscalerProfile: {
        '#withKedaEnabled':: d.fn(help='"Specifies whether KEDA Autoscaler can be used for workloads."', args=[d.arg(name='kedaEnabled', type=d.T.boolean)]),
        withKedaEnabled(kedaEnabled): { kedaEnabled: kedaEnabled },
        '#withVerticalPodAutoscalerEnabled':: d.fn(help='"Specifies whether Vertical Pod Autoscaler should be enabled."', args=[d.arg(name='verticalPodAutoscalerEnabled', type=d.T.boolean)]),
        withVerticalPodAutoscalerEnabled(verticalPodAutoscalerEnabled): { verticalPodAutoscalerEnabled: verticalPodAutoscalerEnabled },
      },
    },
    '#initProvider':: d.obj(help='"THIS IS A BETA FIELD. It will be honored\\nunless the Management Policies feature flag is disabled.\\nInitProvider holds the same fields as ForProvider, with the exception\\nof Identifier and other resource reference fields. The fields that are\\nin InitProvider are merged into ForProvider when the resource is created.\\nThe same fields are also added to the terraform ignore_changes hook, to\\navoid updating them after creation. This is useful for fields that are\\nrequired on creation, but we do not desire to update them after creation,\\nfor example because of an external controller is managing them, like an\\nautoscaler."'),
    initProvider: {
      '#aciConnectorLinux':: d.obj(help='"A aci_connector_linux block as defined below. For more details, please visit Create and configure an AKS cluster to use virtual nodes."'),
      aciConnectorLinux: {
        '#subnetNameRef':: d.obj(help='"Reference to a Subnet in network to populate subnetName."'),
        subnetNameRef: {
          '#policy':: d.obj(help='"Policies for referencing."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { subnetNameRef+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { subnetNameRef+: { policy+: { resolve: resolve } } },
          },
          '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { subnetNameRef+: { name: name } },
        },
        '#subnetNameSelector':: d.obj(help='"Selector for a Subnet in network to populate subnetName."'),
        subnetNameSelector: {
          '#policy':: d.obj(help='"Policies for selection."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { subnetNameSelector+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { subnetNameSelector+: { policy+: { resolve: resolve } } },
          },
          '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference\\nas the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
          withMatchControllerRef(matchControllerRef): { subnetNameSelector+: { matchControllerRef: matchControllerRef } },
          '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabels(matchLabels): { subnetNameSelector+: { matchLabels: matchLabels } },
          '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabelsMixin(matchLabels): { subnetNameSelector+: { matchLabels+: matchLabels } },
        },
        '#withSubnetName':: d.fn(help='"The subnet name for the virtual nodes to run."', args=[d.arg(name='subnetName', type=d.T.string)]),
        withSubnetName(subnetName): { subnetName: subnetName },
      },
      '#apiServerAccessProfile':: d.obj(help='"An api_server_access_profile block as defined below."'),
      apiServerAccessProfile: {
        '#subnetIdRef':: d.obj(help='"Reference to a Subnet in network to populate subnetId."'),
        subnetIdRef: {
          '#policy':: d.obj(help='"Policies for referencing."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { subnetIdRef+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { subnetIdRef+: { policy+: { resolve: resolve } } },
          },
          '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { subnetIdRef+: { name: name } },
        },
        '#subnetIdSelector':: d.obj(help='"Selector for a Subnet in network to populate subnetId."'),
        subnetIdSelector: {
          '#policy':: d.obj(help='"Policies for selection."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { subnetIdSelector+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { subnetIdSelector+: { policy+: { resolve: resolve } } },
          },
          '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference\\nas the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
          withMatchControllerRef(matchControllerRef): { subnetIdSelector+: { matchControllerRef: matchControllerRef } },
          '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabels(matchLabels): { subnetIdSelector+: { matchLabels: matchLabels } },
          '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabelsMixin(matchLabels): { subnetIdSelector+: { matchLabels+: matchLabels } },
        },
        '#withAuthorizedIpRanges':: d.fn(help='"Set of authorized IP ranges to allow access to API server, e.g. [\\"198.51.100.0/24\\"]."', args=[d.arg(name='authorizedIpRanges', type=d.T.array)]),
        withAuthorizedIpRanges(authorizedIpRanges): { authorizedIpRanges: if std.isArray(v=authorizedIpRanges) then authorizedIpRanges else [authorizedIpRanges] },
        '#withAuthorizedIpRangesMixin':: d.fn(help='"Set of authorized IP ranges to allow access to API server, e.g. [\\"198.51.100.0/24\\"]."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='authorizedIpRanges', type=d.T.array)]),
        withAuthorizedIpRangesMixin(authorizedIpRanges): { authorizedIpRanges+: if std.isArray(v=authorizedIpRanges) then authorizedIpRanges else [authorizedIpRanges] },
        '#withSubnetId':: d.fn(help='"The ID of the Subnet where the API server endpoint is delegated to."', args=[d.arg(name='subnetId', type=d.T.string)]),
        withSubnetId(subnetId): { subnetId: subnetId },
        '#withVirtualNetworkIntegrationEnabled':: d.fn(help='"Whether to enable virtual network integration for the API Server. Defaults to false."', args=[d.arg(name='virtualNetworkIntegrationEnabled', type=d.T.boolean)]),
        withVirtualNetworkIntegrationEnabled(virtualNetworkIntegrationEnabled): { virtualNetworkIntegrationEnabled: virtualNetworkIntegrationEnabled },
      },
      '#autoScalerProfile':: d.obj(help='"A auto_scaler_profile block as defined below."'),
      autoScalerProfile: {
        '#withBalanceSimilarNodeGroups':: d.fn(help='"Detect similar node groups and balance the number of nodes between them. Defaults to false."', args=[d.arg(name='balanceSimilarNodeGroups', type=d.T.boolean)]),
        withBalanceSimilarNodeGroups(balanceSimilarNodeGroups): { balanceSimilarNodeGroups: balanceSimilarNodeGroups },
        '#withDaemonsetEvictionForEmptyNodesEnabled':: d.fn(help='"Whether DaemonSet pods will be gracefully terminated from empty nodes. Defaults to false."', args=[d.arg(name='daemonsetEvictionForEmptyNodesEnabled', type=d.T.boolean)]),
        withDaemonsetEvictionForEmptyNodesEnabled(daemonsetEvictionForEmptyNodesEnabled): { daemonsetEvictionForEmptyNodesEnabled: daemonsetEvictionForEmptyNodesEnabled },
        '#withDaemonsetEvictionForOccupiedNodesEnabled':: d.fn(help='"Whether DaemonSet pods will be gracefully terminated from non-empty nodes. Defaults to true."', args=[d.arg(name='daemonsetEvictionForOccupiedNodesEnabled', type=d.T.boolean)]),
        withDaemonsetEvictionForOccupiedNodesEnabled(daemonsetEvictionForOccupiedNodesEnabled): { daemonsetEvictionForOccupiedNodesEnabled: daemonsetEvictionForOccupiedNodesEnabled },
        '#withEmptyBulkDeleteMax':: d.fn(help='"Maximum number of empty nodes that can be deleted at the same time. Defaults to 10."', args=[d.arg(name='emptyBulkDeleteMax', type=d.T.string)]),
        withEmptyBulkDeleteMax(emptyBulkDeleteMax): { emptyBulkDeleteMax: emptyBulkDeleteMax },
        '#withExpander':: d.fn(help='"Expander to use. Possible values are least-waste, priority, most-pods and random. Defaults to random."', args=[d.arg(name='expander', type=d.T.string)]),
        withExpander(expander): { expander: expander },
        '#withIgnoreDaemonsetsUtilizationEnabled':: d.fn(help='"Whether DaemonSet pods will be ignored when calculating resource utilization for scale down. Defaults to false."', args=[d.arg(name='ignoreDaemonsetsUtilizationEnabled', type=d.T.boolean)]),
        withIgnoreDaemonsetsUtilizationEnabled(ignoreDaemonsetsUtilizationEnabled): { ignoreDaemonsetsUtilizationEnabled: ignoreDaemonsetsUtilizationEnabled },
        '#withMaxGracefulTerminationSec':: d.fn(help='"Maximum number of seconds the cluster autoscaler waits for pod termination when trying to scale down a node. Defaults to 600."', args=[d.arg(name='maxGracefulTerminationSec', type=d.T.string)]),
        withMaxGracefulTerminationSec(maxGracefulTerminationSec): { maxGracefulTerminationSec: maxGracefulTerminationSec },
        '#withMaxNodeProvisioningTime':: d.fn(help='"Maximum time the autoscaler waits for a node to be provisioned. Defaults to 15m."', args=[d.arg(name='maxNodeProvisioningTime', type=d.T.string)]),
        withMaxNodeProvisioningTime(maxNodeProvisioningTime): { maxNodeProvisioningTime: maxNodeProvisioningTime },
        '#withMaxUnreadyNodes':: d.fn(help='"Maximum Number of allowed unready nodes. Defaults to 3."', args=[d.arg(name='maxUnreadyNodes', type=d.T.number)]),
        withMaxUnreadyNodes(maxUnreadyNodes): { maxUnreadyNodes: maxUnreadyNodes },
        '#withMaxUnreadyPercentage':: d.fn(help='"Maximum percentage of unready nodes the cluster autoscaler will stop if the percentage is exceeded. Defaults to 45."', args=[d.arg(name='maxUnreadyPercentage', type=d.T.number)]),
        withMaxUnreadyPercentage(maxUnreadyPercentage): { maxUnreadyPercentage: maxUnreadyPercentage },
        '#withNewPodScaleUpDelay':: d.fn(help="\"For scenarios like burst/batch scale where you don't want CA to act before the kubernetes scheduler could schedule all the pods, you can tell CA to ignore unscheduled pods before they're a certain age. Defaults to 10s.\"", args=[d.arg(name='newPodScaleUpDelay', type=d.T.string)]),
        withNewPodScaleUpDelay(newPodScaleUpDelay): { newPodScaleUpDelay: newPodScaleUpDelay },
        '#withScaleDownDelayAfterAdd':: d.fn(help='"How long after the scale up of AKS nodes the scale down evaluation resumes. Defaults to 10m."', args=[d.arg(name='scaleDownDelayAfterAdd', type=d.T.string)]),
        withScaleDownDelayAfterAdd(scaleDownDelayAfterAdd): { scaleDownDelayAfterAdd: scaleDownDelayAfterAdd },
        '#withScaleDownDelayAfterDelete':: d.fn(help='"How long after node deletion that scale down evaluation resumes. Defaults to the value used for scan_interval."', args=[d.arg(name='scaleDownDelayAfterDelete', type=d.T.string)]),
        withScaleDownDelayAfterDelete(scaleDownDelayAfterDelete): { scaleDownDelayAfterDelete: scaleDownDelayAfterDelete },
        '#withScaleDownDelayAfterFailure':: d.fn(help='"How long after scale down failure that scale down evaluation resumes. Defaults to 3m."', args=[d.arg(name='scaleDownDelayAfterFailure', type=d.T.string)]),
        withScaleDownDelayAfterFailure(scaleDownDelayAfterFailure): { scaleDownDelayAfterFailure: scaleDownDelayAfterFailure },
        '#withScaleDownUnneeded':: d.fn(help='"How long a node should be unneeded before it is eligible for scale down. Defaults to 10m."', args=[d.arg(name='scaleDownUnneeded', type=d.T.string)]),
        withScaleDownUnneeded(scaleDownUnneeded): { scaleDownUnneeded: scaleDownUnneeded },
        '#withScaleDownUnready':: d.fn(help='"How long an unready node should be unneeded before it is eligible for scale down. Defaults to 20m."', args=[d.arg(name='scaleDownUnready', type=d.T.string)]),
        withScaleDownUnready(scaleDownUnready): { scaleDownUnready: scaleDownUnready },
        '#withScaleDownUtilizationThreshold':: d.fn(help='"Node utilization level, defined as sum of requested resources divided by capacity, below which a node can be considered for scale down. Defaults to 0.5."', args=[d.arg(name='scaleDownUtilizationThreshold', type=d.T.string)]),
        withScaleDownUtilizationThreshold(scaleDownUtilizationThreshold): { scaleDownUtilizationThreshold: scaleDownUtilizationThreshold },
        '#withScanInterval':: d.fn(help='"How often the AKS Cluster should be re-evaluated for scale up/down. Defaults to 10s."', args=[d.arg(name='scanInterval', type=d.T.string)]),
        withScanInterval(scanInterval): { scanInterval: scanInterval },
        '#withSkipNodesWithLocalStorage':: d.fn(help='"If true cluster autoscaler will never delete nodes with pods with local storage, for example, EmptyDir or HostPath. Defaults to false."', args=[d.arg(name='skipNodesWithLocalStorage', type=d.T.boolean)]),
        withSkipNodesWithLocalStorage(skipNodesWithLocalStorage): { skipNodesWithLocalStorage: skipNodesWithLocalStorage },
        '#withSkipNodesWithSystemPods':: d.fn(help='"If true cluster autoscaler will never delete nodes with pods from kube-system (except for DaemonSet or mirror pods). Defaults to true."', args=[d.arg(name='skipNodesWithSystemPods', type=d.T.boolean)]),
        withSkipNodesWithSystemPods(skipNodesWithSystemPods): { skipNodesWithSystemPods: skipNodesWithSystemPods },
      },
      '#azureActiveDirectoryRoleBasedAccessControl':: d.obj(help='"A azure_active_directory_role_based_access_control block as defined below."'),
      azureActiveDirectoryRoleBasedAccessControl: {
        '#withAdminGroupObjectIds':: d.fn(help='"A list of Object IDs of Azure Active Directory Groups which should have Admin Role on the Cluster."', args=[d.arg(name='adminGroupObjectIds', type=d.T.array)]),
        withAdminGroupObjectIds(adminGroupObjectIds): { adminGroupObjectIds: if std.isArray(v=adminGroupObjectIds) then adminGroupObjectIds else [adminGroupObjectIds] },
        '#withAdminGroupObjectIdsMixin':: d.fn(help='"A list of Object IDs of Azure Active Directory Groups which should have Admin Role on the Cluster."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='adminGroupObjectIds', type=d.T.array)]),
        withAdminGroupObjectIdsMixin(adminGroupObjectIds): { adminGroupObjectIds+: if std.isArray(v=adminGroupObjectIds) then adminGroupObjectIds else [adminGroupObjectIds] },
        '#withAzureRbacEnabled':: d.fn(help='"Is Role Based Access Control based on Azure AD enabled?"', args=[d.arg(name='azureRbacEnabled', type=d.T.boolean)]),
        withAzureRbacEnabled(azureRbacEnabled): { azureRbacEnabled: azureRbacEnabled },
        '#withTenantId':: d.fn(help="\"The Tenant ID used for Azure Active Directory Application. If this isn't specified the Tenant ID of the current Subscription is used.\"", args=[d.arg(name='tenantId', type=d.T.string)]),
        withTenantId(tenantId): { tenantId: tenantId },
      },
      '#bootstrapProfile':: d.obj(help='"A bootstrap_profile block as defined below."'),
      bootstrapProfile: {
        '#withArtifactSource':: d.fn(help='"The artifact source. The source where the artifacts are downloaded from. Possible values are Cache and Direct. Defaults to Direct."', args=[d.arg(name='artifactSource', type=d.T.string)]),
        withArtifactSource(artifactSource): { artifactSource: artifactSource },
        '#withContainerRegistryId':: d.fn(help='"The resource Id of Azure Container Registry."', args=[d.arg(name='containerRegistryId', type=d.T.string)]),
        withContainerRegistryId(containerRegistryId): { containerRegistryId: containerRegistryId },
      },
      '#confidentialComputing':: d.obj(help='"A confidential_computing block as defined below. For more details please the documentation"'),
      confidentialComputing: {
        '#withSgxQuoteHelperEnabled':: d.fn(help='"Should the SGX quote helper be enabled?"', args=[d.arg(name='sgxQuoteHelperEnabled', type=d.T.boolean)]),
        withSgxQuoteHelperEnabled(sgxQuoteHelperEnabled): { sgxQuoteHelperEnabled: sgxQuoteHelperEnabled },
      },
      '#defaultNodePool':: d.obj(help='"Specifies configuration for \\"System\\" mode node pool. A default_node_pool block as defined below."'),
      defaultNodePool: {
        '#kubeletConfig':: d.obj(help='"A kubelet_config block as defined below. temporary_name_for_rotation must be specified when changing this block."'),
        kubeletConfig: {
          '#withAllowedUnsafeSysctls':: d.fn(help='"Specifies the allow list of unsafe sysctls command or patterns (ending in *)."', args=[d.arg(name='allowedUnsafeSysctls', type=d.T.array)]),
          withAllowedUnsafeSysctls(allowedUnsafeSysctls): { allowedUnsafeSysctls: if std.isArray(v=allowedUnsafeSysctls) then allowedUnsafeSysctls else [allowedUnsafeSysctls] },
          '#withAllowedUnsafeSysctlsMixin':: d.fn(help='"Specifies the allow list of unsafe sysctls command or patterns (ending in *)."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='allowedUnsafeSysctls', type=d.T.array)]),
          withAllowedUnsafeSysctlsMixin(allowedUnsafeSysctls): { allowedUnsafeSysctls+: if std.isArray(v=allowedUnsafeSysctls) then allowedUnsafeSysctls else [allowedUnsafeSysctls] },
          '#withContainerLogMaxLine':: d.fn(help='"Specifies the maximum number of container log files that can be present for a container. must be at least 2."', args=[d.arg(name='containerLogMaxLine', type=d.T.number)]),
          withContainerLogMaxLine(containerLogMaxLine): { containerLogMaxLine: containerLogMaxLine },
          '#withContainerLogMaxSizeMb':: d.fn(help='"Specifies the maximum size (e.g. 10MB) of container log file before it is rotated."', args=[d.arg(name='containerLogMaxSizeMb', type=d.T.number)]),
          withContainerLogMaxSizeMb(containerLogMaxSizeMb): { containerLogMaxSizeMb: containerLogMaxSizeMb },
          '#withCpuCfsQuotaEnabled':: d.fn(help='"Is CPU CFS quota enforcement for containers enabled? Defaults to true."', args=[d.arg(name='cpuCfsQuotaEnabled', type=d.T.boolean)]),
          withCpuCfsQuotaEnabled(cpuCfsQuotaEnabled): { cpuCfsQuotaEnabled: cpuCfsQuotaEnabled },
          '#withCpuCfsQuotaPeriod':: d.fn(help='"Specifies the CPU CFS quota period value."', args=[d.arg(name='cpuCfsQuotaPeriod', type=d.T.string)]),
          withCpuCfsQuotaPeriod(cpuCfsQuotaPeriod): { cpuCfsQuotaPeriod: cpuCfsQuotaPeriod },
          '#withCpuManagerPolicy':: d.fn(help='"Specifies the CPU Manager policy to use. Possible values are none and static,."', args=[d.arg(name='cpuManagerPolicy', type=d.T.string)]),
          withCpuManagerPolicy(cpuManagerPolicy): { cpuManagerPolicy: cpuManagerPolicy },
          '#withImageGcHighThreshold':: d.fn(help='"Specifies the percent of disk usage above which image garbage collection is always run. Must be between 0 and 100."', args=[d.arg(name='imageGcHighThreshold', type=d.T.number)]),
          withImageGcHighThreshold(imageGcHighThreshold): { imageGcHighThreshold: imageGcHighThreshold },
          '#withImageGcLowThreshold':: d.fn(help='"Specifies the percent of disk usage lower than which image garbage collection is never run. Must be between 0 and 100."', args=[d.arg(name='imageGcLowThreshold', type=d.T.number)]),
          withImageGcLowThreshold(imageGcLowThreshold): { imageGcLowThreshold: imageGcLowThreshold },
          '#withPodMaxPid':: d.fn(help='"Specifies the maximum number of processes per pod."', args=[d.arg(name='podMaxPid', type=d.T.number)]),
          withPodMaxPid(podMaxPid): { podMaxPid: podMaxPid },
          '#withTopologyManagerPolicy':: d.fn(help='"Specifies the Topology Manager policy to use. Possible values are none, best-effort, restricted or single-numa-node."', args=[d.arg(name='topologyManagerPolicy', type=d.T.string)]),
          withTopologyManagerPolicy(topologyManagerPolicy): { topologyManagerPolicy: topologyManagerPolicy },
        },
        '#linuxOsConfig':: d.obj(help='"A linux_os_config block as defined below. temporary_name_for_rotation must be specified when changing this block."'),
        linuxOsConfig: {
          '#sysctlConfig':: d.obj(help='"A sysctl_config block as defined below."'),
          sysctlConfig: {
            '#withFsAioMaxNr':: d.fn(help='"The sysctl setting fs.aio-max-nr. Must be between 65536 and 6553500."', args=[d.arg(name='fsAioMaxNr', type=d.T.number)]),
            withFsAioMaxNr(fsAioMaxNr): { fsAioMaxNr: fsAioMaxNr },
            '#withFsFileMax':: d.fn(help='"The sysctl setting fs.file-max. Must be between 8192 and 12000500."', args=[d.arg(name='fsFileMax', type=d.T.number)]),
            withFsFileMax(fsFileMax): { fsFileMax: fsFileMax },
            '#withFsInotifyMaxUserWatches':: d.fn(help='"The sysctl setting fs.inotify.max_user_watches. Must be between 781250 and 2097152."', args=[d.arg(name='fsInotifyMaxUserWatches', type=d.T.number)]),
            withFsInotifyMaxUserWatches(fsInotifyMaxUserWatches): { fsInotifyMaxUserWatches: fsInotifyMaxUserWatches },
            '#withFsNrOpen':: d.fn(help='"The sysctl setting fs.nr_open. Must be between 8192 and 20000500."', args=[d.arg(name='fsNrOpen', type=d.T.number)]),
            withFsNrOpen(fsNrOpen): { fsNrOpen: fsNrOpen },
            '#withKernelThreadsMax':: d.fn(help='"The sysctl setting kernel.threads-max. Must be between 20 and 513785."', args=[d.arg(name='kernelThreadsMax', type=d.T.number)]),
            withKernelThreadsMax(kernelThreadsMax): { kernelThreadsMax: kernelThreadsMax },
            '#withNetCoreNetdevMaxBacklog':: d.fn(help='"The sysctl setting net.core.netdev_max_backlog. Must be between 1000 and 3240000."', args=[d.arg(name='netCoreNetdevMaxBacklog', type=d.T.number)]),
            withNetCoreNetdevMaxBacklog(netCoreNetdevMaxBacklog): { netCoreNetdevMaxBacklog: netCoreNetdevMaxBacklog },
            '#withNetCoreOptmemMax':: d.fn(help='"The sysctl setting net.core.optmem_max. Must be between 20480 and 4194304."', args=[d.arg(name='netCoreOptmemMax', type=d.T.number)]),
            withNetCoreOptmemMax(netCoreOptmemMax): { netCoreOptmemMax: netCoreOptmemMax },
            '#withNetCoreRmemDefault':: d.fn(help='"The sysctl setting net.core.rmem_default. Must be between 212992 and 134217728."', args=[d.arg(name='netCoreRmemDefault', type=d.T.number)]),
            withNetCoreRmemDefault(netCoreRmemDefault): { netCoreRmemDefault: netCoreRmemDefault },
            '#withNetCoreRmemMax':: d.fn(help='"The sysctl setting net.core.rmem_max. Must be between 212992 and 134217728."', args=[d.arg(name='netCoreRmemMax', type=d.T.number)]),
            withNetCoreRmemMax(netCoreRmemMax): { netCoreRmemMax: netCoreRmemMax },
            '#withNetCoreSomaxconn':: d.fn(help='"The sysctl setting net.core.somaxconn. Must be between 4096 and 3240000."', args=[d.arg(name='netCoreSomaxconn', type=d.T.number)]),
            withNetCoreSomaxconn(netCoreSomaxconn): { netCoreSomaxconn: netCoreSomaxconn },
            '#withNetCoreWmemDefault':: d.fn(help='"The sysctl setting net.core.wmem_default. Must be between 212992 and 134217728."', args=[d.arg(name='netCoreWmemDefault', type=d.T.number)]),
            withNetCoreWmemDefault(netCoreWmemDefault): { netCoreWmemDefault: netCoreWmemDefault },
            '#withNetCoreWmemMax':: d.fn(help='"The sysctl setting net.core.wmem_max. Must be between 212992 and 134217728."', args=[d.arg(name='netCoreWmemMax', type=d.T.number)]),
            withNetCoreWmemMax(netCoreWmemMax): { netCoreWmemMax: netCoreWmemMax },
            '#withNetIpv4IpLocalPortRangeMax':: d.fn(help='"The sysctl setting net.ipv4.ip_local_port_range max value. Must be between 32768 and 65535."', args=[d.arg(name='netIpv4IpLocalPortRangeMax', type=d.T.number)]),
            withNetIpv4IpLocalPortRangeMax(netIpv4IpLocalPortRangeMax): { netIpv4IpLocalPortRangeMax: netIpv4IpLocalPortRangeMax },
            '#withNetIpv4IpLocalPortRangeMin':: d.fn(help='"The sysctl setting net.ipv4.ip_local_port_range min value. Must be between 1024 and 60999."', args=[d.arg(name='netIpv4IpLocalPortRangeMin', type=d.T.number)]),
            withNetIpv4IpLocalPortRangeMin(netIpv4IpLocalPortRangeMin): { netIpv4IpLocalPortRangeMin: netIpv4IpLocalPortRangeMin },
            '#withNetIpv4NeighDefaultGcThresh1':: d.fn(help='"The sysctl setting net.ipv4.neigh.default.gc_thresh1. Must be between 128 and 80000."', args=[d.arg(name='netIpv4NeighDefaultGcThresh1', type=d.T.number)]),
            withNetIpv4NeighDefaultGcThresh1(netIpv4NeighDefaultGcThresh1): { netIpv4NeighDefaultGcThresh1: netIpv4NeighDefaultGcThresh1 },
            '#withNetIpv4NeighDefaultGcThresh2':: d.fn(help='"The sysctl setting net.ipv4.neigh.default.gc_thresh2. Must be between 512 and 90000."', args=[d.arg(name='netIpv4NeighDefaultGcThresh2', type=d.T.number)]),
            withNetIpv4NeighDefaultGcThresh2(netIpv4NeighDefaultGcThresh2): { netIpv4NeighDefaultGcThresh2: netIpv4NeighDefaultGcThresh2 },
            '#withNetIpv4NeighDefaultGcThresh3':: d.fn(help='"The sysctl setting net.ipv4.neigh.default.gc_thresh3. Must be between 1024 and 100000."', args=[d.arg(name='netIpv4NeighDefaultGcThresh3', type=d.T.number)]),
            withNetIpv4NeighDefaultGcThresh3(netIpv4NeighDefaultGcThresh3): { netIpv4NeighDefaultGcThresh3: netIpv4NeighDefaultGcThresh3 },
            '#withNetIpv4TcpFinTimeout':: d.fn(help='"The sysctl setting net.ipv4.tcp_fin_timeout. Must be between 5 and 120."', args=[d.arg(name='netIpv4TcpFinTimeout', type=d.T.number)]),
            withNetIpv4TcpFinTimeout(netIpv4TcpFinTimeout): { netIpv4TcpFinTimeout: netIpv4TcpFinTimeout },
            '#withNetIpv4TcpKeepaliveIntvl':: d.fn(help='"The sysctl setting net.ipv4.tcp_keepalive_intvl. Must be between 10 and 90."', args=[d.arg(name='netIpv4TcpKeepaliveIntvl', type=d.T.number)]),
            withNetIpv4TcpKeepaliveIntvl(netIpv4TcpKeepaliveIntvl): { netIpv4TcpKeepaliveIntvl: netIpv4TcpKeepaliveIntvl },
            '#withNetIpv4TcpKeepaliveProbes':: d.fn(help='"The sysctl setting net.ipv4.tcp_keepalive_probes. Must be between 1 and 15."', args=[d.arg(name='netIpv4TcpKeepaliveProbes', type=d.T.number)]),
            withNetIpv4TcpKeepaliveProbes(netIpv4TcpKeepaliveProbes): { netIpv4TcpKeepaliveProbes: netIpv4TcpKeepaliveProbes },
            '#withNetIpv4TcpKeepaliveTime':: d.fn(help='"The sysctl setting net.ipv4.tcp_keepalive_time. Must be between 30 and 432000."', args=[d.arg(name='netIpv4TcpKeepaliveTime', type=d.T.number)]),
            withNetIpv4TcpKeepaliveTime(netIpv4TcpKeepaliveTime): { netIpv4TcpKeepaliveTime: netIpv4TcpKeepaliveTime },
            '#withNetIpv4TcpMaxSynBacklog':: d.fn(help='"The sysctl setting net.ipv4.tcp_max_syn_backlog. Must be between 128 and 3240000."', args=[d.arg(name='netIpv4TcpMaxSynBacklog', type=d.T.number)]),
            withNetIpv4TcpMaxSynBacklog(netIpv4TcpMaxSynBacklog): { netIpv4TcpMaxSynBacklog: netIpv4TcpMaxSynBacklog },
            '#withNetIpv4TcpMaxTwBuckets':: d.fn(help='"The sysctl setting net.ipv4.tcp_max_tw_buckets. Must be between 8000 and 1440000."', args=[d.arg(name='netIpv4TcpMaxTwBuckets', type=d.T.number)]),
            withNetIpv4TcpMaxTwBuckets(netIpv4TcpMaxTwBuckets): { netIpv4TcpMaxTwBuckets: netIpv4TcpMaxTwBuckets },
            '#withNetIpv4TcpTwReuse':: d.fn(help='"The sysctl setting net.ipv4.tcp_tw_reuse."', args=[d.arg(name='netIpv4TcpTwReuse', type=d.T.boolean)]),
            withNetIpv4TcpTwReuse(netIpv4TcpTwReuse): { netIpv4TcpTwReuse: netIpv4TcpTwReuse },
            '#withNetNetfilterNfConntrackBuckets':: d.fn(help='"The sysctl setting net.netfilter.nf_conntrack_buckets. Must be between 65536 and 524288."', args=[d.arg(name='netNetfilterNfConntrackBuckets', type=d.T.number)]),
            withNetNetfilterNfConntrackBuckets(netNetfilterNfConntrackBuckets): { netNetfilterNfConntrackBuckets: netNetfilterNfConntrackBuckets },
            '#withNetNetfilterNfConntrackMax':: d.fn(help='"The sysctl setting net.netfilter.nf_conntrack_max. Must be between 131072 and 2097152."', args=[d.arg(name='netNetfilterNfConntrackMax', type=d.T.number)]),
            withNetNetfilterNfConntrackMax(netNetfilterNfConntrackMax): { netNetfilterNfConntrackMax: netNetfilterNfConntrackMax },
            '#withVmMaxMapCount':: d.fn(help='"The sysctl setting vm.max_map_count. Must be between 65530 and 262144."', args=[d.arg(name='vmMaxMapCount', type=d.T.number)]),
            withVmMaxMapCount(vmMaxMapCount): { vmMaxMapCount: vmMaxMapCount },
            '#withVmSwappiness':: d.fn(help='"The sysctl setting vm.swappiness. Must be between 0 and 100."', args=[d.arg(name='vmSwappiness', type=d.T.number)]),
            withVmSwappiness(vmSwappiness): { vmSwappiness: vmSwappiness },
            '#withVmVfsCachePressure':: d.fn(help='"The sysctl setting vm.vfs_cache_pressure. Must be between 0 and 100."', args=[d.arg(name='vmVfsCachePressure', type=d.T.number)]),
            withVmVfsCachePressure(vmVfsCachePressure): { vmVfsCachePressure: vmVfsCachePressure },
          },
          '#withSwapFileSizeMb':: d.fn(help='"Specifies the size of the swap file on each node in MB."', args=[d.arg(name='swapFileSizeMb', type=d.T.number)]),
          withSwapFileSizeMb(swapFileSizeMb): { swapFileSizeMb: swapFileSizeMb },
          '#withSysctlConfig':: d.fn(help='"A sysctl_config block as defined below."', args=[d.arg(name='sysctlConfig', type=d.T.array)]),
          withSysctlConfig(sysctlConfig): { sysctlConfig: if std.isArray(v=sysctlConfig) then sysctlConfig else [sysctlConfig] },
          '#withSysctlConfigMixin':: d.fn(help='"A sysctl_config block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sysctlConfig', type=d.T.array)]),
          withSysctlConfigMixin(sysctlConfig): { sysctlConfig+: if std.isArray(v=sysctlConfig) then sysctlConfig else [sysctlConfig] },
          '#withTransparentHugePage':: d.fn(help='"Specifies the Transparent Huge Page configuration. Possible values are always, madvise and never."', args=[d.arg(name='transparentHugePage', type=d.T.string)]),
          withTransparentHugePage(transparentHugePage): { transparentHugePage: transparentHugePage },
          '#withTransparentHugePageDefrag':: d.fn(help='"specifies the defrag configuration for Transparent Huge Page. Possible values are always, defer, defer+madvise, madvise and never."', args=[d.arg(name='transparentHugePageDefrag', type=d.T.string)]),
          withTransparentHugePageDefrag(transparentHugePageDefrag): { transparentHugePageDefrag: transparentHugePageDefrag },
          '#withTransparentHugePageEnabled':: d.fn(help='', args=[d.arg(name='transparentHugePageEnabled', type=d.T.string)]),
          withTransparentHugePageEnabled(transparentHugePageEnabled): { transparentHugePageEnabled: transparentHugePageEnabled },
        },
        '#nodeNetworkProfile':: d.obj(help='"A node_network_profile block as documented below."'),
        nodeNetworkProfile: {
          '#allowedHostPorts':: d.obj(help='"One or more allowed_host_ports blocks as defined below."'),
          allowedHostPorts: {
            '#withPortEnd':: d.fn(help='"Specifies the end of the port range."', args=[d.arg(name='portEnd', type=d.T.number)]),
            withPortEnd(portEnd): { portEnd: portEnd },
            '#withPortStart':: d.fn(help='"Specifies the start of the port range."', args=[d.arg(name='portStart', type=d.T.number)]),
            withPortStart(portStart): { portStart: portStart },
            '#withProtocol':: d.fn(help='"Specifies the protocol of the port range. Possible values are TCP and UDP."', args=[d.arg(name='protocol', type=d.T.string)]),
            withProtocol(protocol): { protocol: protocol },
          },
          '#withAllowedHostPorts':: d.fn(help='"One or more allowed_host_ports blocks as defined below."', args=[d.arg(name='allowedHostPorts', type=d.T.array)]),
          withAllowedHostPorts(allowedHostPorts): { allowedHostPorts: if std.isArray(v=allowedHostPorts) then allowedHostPorts else [allowedHostPorts] },
          '#withAllowedHostPortsMixin':: d.fn(help='"One or more allowed_host_ports blocks as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='allowedHostPorts', type=d.T.array)]),
          withAllowedHostPortsMixin(allowedHostPorts): { allowedHostPorts+: if std.isArray(v=allowedHostPorts) then allowedHostPorts else [allowedHostPorts] },
          '#withApplicationSecurityGroupIds':: d.fn(help='"A list of Application Security Group IDs which should be associated with this Node Pool."', args=[d.arg(name='applicationSecurityGroupIds', type=d.T.array)]),
          withApplicationSecurityGroupIds(applicationSecurityGroupIds): { applicationSecurityGroupIds: if std.isArray(v=applicationSecurityGroupIds) then applicationSecurityGroupIds else [applicationSecurityGroupIds] },
          '#withApplicationSecurityGroupIdsMixin':: d.fn(help='"A list of Application Security Group IDs which should be associated with this Node Pool."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='applicationSecurityGroupIds', type=d.T.array)]),
          withApplicationSecurityGroupIdsMixin(applicationSecurityGroupIds): { applicationSecurityGroupIds+: if std.isArray(v=applicationSecurityGroupIds) then applicationSecurityGroupIds else [applicationSecurityGroupIds] },
          '#withNodePublicIpTags':: d.fn(help='"Specifies a mapping of tags to the instance-level public IPs. Changing this forces a new resource to be created."', args=[d.arg(name='nodePublicIpTags', type=d.T.object)]),
          withNodePublicIpTags(nodePublicIpTags): { nodePublicIpTags: nodePublicIpTags },
          '#withNodePublicIpTagsMixin':: d.fn(help='"Specifies a mapping of tags to the instance-level public IPs. Changing this forces a new resource to be created."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodePublicIpTags', type=d.T.object)]),
          withNodePublicIpTagsMixin(nodePublicIpTags): { nodePublicIpTags+: nodePublicIpTags },
        },
        '#podSubnetIdRef':: d.obj(help='"Reference to a Subnet in network to populate podSubnetId."'),
        podSubnetIdRef: {
          '#policy':: d.obj(help='"Policies for referencing."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { podSubnetIdRef+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { podSubnetIdRef+: { policy+: { resolve: resolve } } },
          },
          '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { podSubnetIdRef+: { name: name } },
        },
        '#podSubnetIdSelector':: d.obj(help='"Selector for a Subnet in network to populate podSubnetId."'),
        podSubnetIdSelector: {
          '#policy':: d.obj(help='"Policies for selection."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { podSubnetIdSelector+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { podSubnetIdSelector+: { policy+: { resolve: resolve } } },
          },
          '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference\\nas the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
          withMatchControllerRef(matchControllerRef): { podSubnetIdSelector+: { matchControllerRef: matchControllerRef } },
          '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabels(matchLabels): { podSubnetIdSelector+: { matchLabels: matchLabels } },
          '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabelsMixin(matchLabels): { podSubnetIdSelector+: { matchLabels+: matchLabels } },
        },
        '#upgradeSettings':: d.obj(help='"A upgrade_settings block as documented below."'),
        upgradeSettings: {
          '#withDrainTimeoutInMinutes':: d.fn(help='"The amount of time in minutes to wait on eviction of pods and graceful termination per node. This eviction wait time honors pod disruption budgets for upgrades. If this time is exceeded, the upgrade fails. Unsetting this after configuring it will force a new resource to be created."', args=[d.arg(name='drainTimeoutInMinutes', type=d.T.number)]),
          withDrainTimeoutInMinutes(drainTimeoutInMinutes): { drainTimeoutInMinutes: drainTimeoutInMinutes },
          '#withMaxSurge':: d.fn(help='"The maximum number or percentage of nodes which will be added to the Node Pool size during an upgrade."', args=[d.arg(name='maxSurge', type=d.T.string)]),
          withMaxSurge(maxSurge): { maxSurge: maxSurge },
          '#withNodeSoakDurationInMinutes':: d.fn(help='"The amount of time in minutes to wait after draining a node and before reimaging and moving on to next node."', args=[d.arg(name='nodeSoakDurationInMinutes', type=d.T.number)]),
          withNodeSoakDurationInMinutes(nodeSoakDurationInMinutes): { nodeSoakDurationInMinutes: nodeSoakDurationInMinutes },
          '#withUndrainableNodeBehavior':: d.fn(help='"Specifies the action when a node is undrainable during upgrade. Possible values are Cordon and Schedule. Unsetting this after configuring it will force a new resource to be created."', args=[d.arg(name='undrainableNodeBehavior', type=d.T.string)]),
          withUndrainableNodeBehavior(undrainableNodeBehavior): { undrainableNodeBehavior: undrainableNodeBehavior },
        },
        '#vnetSubnetIdRef':: d.obj(help='"Reference to a Subnet in network to populate vnetSubnetId."'),
        vnetSubnetIdRef: {
          '#policy':: d.obj(help='"Policies for referencing."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { vnetSubnetIdRef+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { vnetSubnetIdRef+: { policy+: { resolve: resolve } } },
          },
          '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { vnetSubnetIdRef+: { name: name } },
        },
        '#vnetSubnetIdSelector':: d.obj(help='"Selector for a Subnet in network to populate vnetSubnetId."'),
        vnetSubnetIdSelector: {
          '#policy':: d.obj(help='"Policies for selection."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { vnetSubnetIdSelector+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { vnetSubnetIdSelector+: { policy+: { resolve: resolve } } },
          },
          '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference\\nas the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
          withMatchControllerRef(matchControllerRef): { vnetSubnetIdSelector+: { matchControllerRef: matchControllerRef } },
          '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabels(matchLabels): { vnetSubnetIdSelector+: { matchLabels: matchLabels } },
          '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabelsMixin(matchLabels): { vnetSubnetIdSelector+: { matchLabels+: matchLabels } },
        },
        '#withAutoScalingEnabled':: d.fn(help='"Should the Kubernetes Auto Scaler be enabled for this Node Pool?"', args=[d.arg(name='autoScalingEnabled', type=d.T.boolean)]),
        withAutoScalingEnabled(autoScalingEnabled): { autoScalingEnabled: autoScalingEnabled },
        '#withCapacityReservationGroupId':: d.fn(help='"Specifies the ID of the Capacity Reservation Group within which this AKS Cluster should be created. Changing this forces a new resource to be created."', args=[d.arg(name='capacityReservationGroupId', type=d.T.string)]),
        withCapacityReservationGroupId(capacityReservationGroupId): { capacityReservationGroupId: capacityReservationGroupId },
        '#withFipsEnabled':: d.fn(help='"Should the nodes in this Node Pool have Federal Information Processing Standard enabled? temporary_name_for_rotation must be specified when changing this block."', args=[d.arg(name='fipsEnabled', type=d.T.boolean)]),
        withFipsEnabled(fipsEnabled): { fipsEnabled: fipsEnabled },
        '#withGpuDriver':: d.fn(help='"Specifies the driver type for GPU nodes. Possible values are Install and None. Changing this forces a new resource to be created."', args=[d.arg(name='gpuDriver', type=d.T.string)]),
        withGpuDriver(gpuDriver): { gpuDriver: gpuDriver },
        '#withGpuInstance':: d.fn(help='"Specifies the GPU MIG instance profile for supported GPU VM SKU. The allowed values are MIG1g, MIG2g, MIG3g, MIG4g and MIG7g. Changing this forces a new resource to be created."', args=[d.arg(name='gpuInstance', type=d.T.string)]),
        withGpuInstance(gpuInstance): { gpuInstance: gpuInstance },
        '#withHostEncryptionEnabled':: d.fn(help='"Should the nodes in the Default Node Pool have host encryption enabled? temporary_name_for_rotation must be specified when changing this property."', args=[d.arg(name='hostEncryptionEnabled', type=d.T.boolean)]),
        withHostEncryptionEnabled(hostEncryptionEnabled): { hostEncryptionEnabled: hostEncryptionEnabled },
        '#withHostGroupId':: d.fn(help='"Specifies the ID of the Host Group within which this AKS Cluster should be created. Changing this forces a new resource to be created."', args=[d.arg(name='hostGroupId', type=d.T.string)]),
        withHostGroupId(hostGroupId): { hostGroupId: hostGroupId },
        '#withKubeletConfig':: d.fn(help='"A kubelet_config block as defined below. temporary_name_for_rotation must be specified when changing this block."', args=[d.arg(name='kubeletConfig', type=d.T.array)]),
        withKubeletConfig(kubeletConfig): { kubeletConfig: if std.isArray(v=kubeletConfig) then kubeletConfig else [kubeletConfig] },
        '#withKubeletConfigMixin':: d.fn(help='"A kubelet_config block as defined below. temporary_name_for_rotation must be specified when changing this block."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='kubeletConfig', type=d.T.array)]),
        withKubeletConfigMixin(kubeletConfig): { kubeletConfig+: if std.isArray(v=kubeletConfig) then kubeletConfig else [kubeletConfig] },
        '#withKubeletDiskType':: d.fn(help='"The type of disk used by kubelet. Possible values are OS and Temporary. temporary_name_for_rotation must be specified when changing this block."', args=[d.arg(name='kubeletDiskType', type=d.T.string)]),
        withKubeletDiskType(kubeletDiskType): { kubeletDiskType: kubeletDiskType },
        '#withLinuxOsConfig':: d.fn(help='"A linux_os_config block as defined below. temporary_name_for_rotation must be specified when changing this block."', args=[d.arg(name='linuxOsConfig', type=d.T.array)]),
        withLinuxOsConfig(linuxOsConfig): { linuxOsConfig: if std.isArray(v=linuxOsConfig) then linuxOsConfig else [linuxOsConfig] },
        '#withLinuxOsConfigMixin':: d.fn(help='"A linux_os_config block as defined below. temporary_name_for_rotation must be specified when changing this block."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='linuxOsConfig', type=d.T.array)]),
        withLinuxOsConfigMixin(linuxOsConfig): { linuxOsConfig+: if std.isArray(v=linuxOsConfig) then linuxOsConfig else [linuxOsConfig] },
        '#withMaxCount':: d.fn(help='"The maximum number of nodes which should exist in this Node Pool. If specified this must be between 1 and 1000."', args=[d.arg(name='maxCount', type=d.T.number)]),
        withMaxCount(maxCount): { maxCount: maxCount },
        '#withMaxPods':: d.fn(help='"The maximum number of pods that can run on each agent. temporary_name_for_rotation must be specified when changing this property."', args=[d.arg(name='maxPods', type=d.T.number)]),
        withMaxPods(maxPods): { maxPods: maxPods },
        '#withMinCount':: d.fn(help='"The minimum number of nodes which should exist in this Node Pool. If specified this must be between 1 and 1000."', args=[d.arg(name='minCount', type=d.T.number)]),
        withMinCount(minCount): { minCount: minCount },
        '#withName':: d.fn(help='"The name which should be used for the default Kubernetes Node Pool."', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
        '#withNodeCount':: d.fn(help='"The initial number of nodes which should exist in this Node Pool. If specified this must be between 1 and 1000 and between min_count and max_count."', args=[d.arg(name='nodeCount', type=d.T.number)]),
        withNodeCount(nodeCount): { nodeCount: nodeCount },
        '#withNodeLabels':: d.fn(help='"A map of Kubernetes labels which should be applied to nodes in the Default Node Pool."', args=[d.arg(name='nodeLabels', type=d.T.object)]),
        withNodeLabels(nodeLabels): { nodeLabels: nodeLabels },
        '#withNodeLabelsMixin':: d.fn(help='"A map of Kubernetes labels which should be applied to nodes in the Default Node Pool."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodeLabels', type=d.T.object)]),
        withNodeLabelsMixin(nodeLabels): { nodeLabels+: nodeLabels },
        '#withNodeNetworkProfile':: d.fn(help='"A node_network_profile block as documented below."', args=[d.arg(name='nodeNetworkProfile', type=d.T.array)]),
        withNodeNetworkProfile(nodeNetworkProfile): { nodeNetworkProfile: if std.isArray(v=nodeNetworkProfile) then nodeNetworkProfile else [nodeNetworkProfile] },
        '#withNodeNetworkProfileMixin':: d.fn(help='"A node_network_profile block as documented below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodeNetworkProfile', type=d.T.array)]),
        withNodeNetworkProfileMixin(nodeNetworkProfile): { nodeNetworkProfile+: if std.isArray(v=nodeNetworkProfile) then nodeNetworkProfile else [nodeNetworkProfile] },
        '#withNodePublicIpEnabled':: d.fn(help='"Should nodes in this Node Pool have a Public IP Address? temporary_name_for_rotation must be specified when changing this property."', args=[d.arg(name='nodePublicIpEnabled', type=d.T.boolean)]),
        withNodePublicIpEnabled(nodePublicIpEnabled): { nodePublicIpEnabled: nodePublicIpEnabled },
        '#withNodePublicIpPrefixId':: d.fn(help='"Resource ID for the Public IP Addresses Prefix for the nodes in this Node Pool. node_public_ip_enabled should be true. Changing this forces a new resource to be created."', args=[d.arg(name='nodePublicIpPrefixId', type=d.T.string)]),
        withNodePublicIpPrefixId(nodePublicIpPrefixId): { nodePublicIpPrefixId: nodePublicIpPrefixId },
        '#withOnlyCriticalAddonsEnabled':: d.fn(help='"Enabling this option will taint default node pool with CriticalAddonsOnly=true:NoSchedule taint. temporary_name_for_rotation must be specified when changing this property."', args=[d.arg(name='onlyCriticalAddonsEnabled', type=d.T.boolean)]),
        withOnlyCriticalAddonsEnabled(onlyCriticalAddonsEnabled): { onlyCriticalAddonsEnabled: onlyCriticalAddonsEnabled },
        '#withOrchestratorVersion':: d.fn(help="\"Version of Kubernetes used for the Agents. If not specified, the default node pool will be created with the version specified by kubernetes_version. If both are unspecified, the latest recommended version will be used at provisioning time (but won't auto-upgrade). AKS does not require an exact patch version to be specified, minor version aliases such as 1.22 are also supported. - The minor version's latest GA patch is automatically chosen in that case. More details can be found in the documentation.\"", args=[d.arg(name='orchestratorVersion', type=d.T.string)]),
        withOrchestratorVersion(orchestratorVersion): { orchestratorVersion: orchestratorVersion },
        '#withOsDiskSizeGb':: d.fn(help='"The size of the OS Disk which should be used for each agent in the Node Pool. temporary_name_for_rotation must be specified when attempting a change."', args=[d.arg(name='osDiskSizeGb', type=d.T.number)]),
        withOsDiskSizeGb(osDiskSizeGb): { osDiskSizeGb: osDiskSizeGb },
        '#withOsDiskType':: d.fn(help='"The type of disk which should be used for the Operating System. Possible values are Ephemeral and Managed. Defaults to Managed. temporary_name_for_rotation must be specified when attempting a change."', args=[d.arg(name='osDiskType', type=d.T.string)]),
        withOsDiskType(osDiskType): { osDiskType: osDiskType },
        '#withOsSku':: d.fn(help='"Specifies the OS SKU used by the agent pool. Possible values are AzureLinux, AzureLinux3, Ubuntu, Ubuntu2204, Windows2019 and Windows2022. If not specified, the default is Ubuntu if OSType=Linux or Windows2019 if OSType=Windows. And the default Windows OSSKU will be changed to Windows2022 after Windows2019 is deprecated. Changing this from AzureLinux or Ubuntu to AzureLinux or Ubuntu will not replace the resource, otherwise temporary_name_for_rotation must be specified when attempting a change."', args=[d.arg(name='osSku', type=d.T.string)]),
        withOsSku(osSku): { osSku: osSku },
        '#withPodSubnetId':: d.fn(help='"The ID of the Subnet where the pods in the default Node Pool should exist."', args=[d.arg(name='podSubnetId', type=d.T.string)]),
        withPodSubnetId(podSubnetId): { podSubnetId: podSubnetId },
        '#withProximityPlacementGroupId':: d.fn(help='"The ID of the Proximity Placement Group. Changing this forces a new resource to be created."', args=[d.arg(name='proximityPlacementGroupId', type=d.T.string)]),
        withProximityPlacementGroupId(proximityPlacementGroupId): { proximityPlacementGroupId: proximityPlacementGroupId },
        '#withScaleDownMode':: d.fn(help='"Specifies the autoscaling behaviour of the Kubernetes Cluster. Allowed values are Delete and Deallocate. Defaults to Delete."', args=[d.arg(name='scaleDownMode', type=d.T.string)]),
        withScaleDownMode(scaleDownMode): { scaleDownMode: scaleDownMode },
        '#withSnapshotId':: d.fn(help='"The ID of the Snapshot which should be used to create this default Node Pool. temporary_name_for_rotation must be specified when changing this property."', args=[d.arg(name='snapshotId', type=d.T.string)]),
        withSnapshotId(snapshotId): { snapshotId: snapshotId },
        '#withTags':: d.fn(help='"A mapping of tags to assign to the Node Pool."', args=[d.arg(name='tags', type=d.T.object)]),
        withTags(tags): { tags: tags },
        '#withTagsMixin':: d.fn(help='"A mapping of tags to assign to the Node Pool."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tags', type=d.T.object)]),
        withTagsMixin(tags): { tags+: tags },
        '#withTemporaryNameForRotation':: d.fn(help='"Specifies the name of the temporary node pool used to cycle the default node pool for VM resizing."', args=[d.arg(name='temporaryNameForRotation', type=d.T.string)]),
        withTemporaryNameForRotation(temporaryNameForRotation): { temporaryNameForRotation: temporaryNameForRotation },
        '#withType':: d.fn(help='"The type of Node Pool which should be created. Possible values are VirtualMachineScaleSets. Defaults to VirtualMachineScaleSets. Changing this forces a new resource to be created."', args=[d.arg(name='type', type=d.T.string)]),
        withType(type): { type: type },
        '#withUltraSsdEnabled':: d.fn(help='"Used to specify whether the UltraSSD is enabled in the Default Node Pool. Defaults to false. See the documentation for more information. temporary_name_for_rotation must be specified when attempting a change."', args=[d.arg(name='ultraSsdEnabled', type=d.T.boolean)]),
        withUltraSsdEnabled(ultraSsdEnabled): { ultraSsdEnabled: ultraSsdEnabled },
        '#withUpgradeSettings':: d.fn(help='"A upgrade_settings block as documented below."', args=[d.arg(name='upgradeSettings', type=d.T.array)]),
        withUpgradeSettings(upgradeSettings): { upgradeSettings: if std.isArray(v=upgradeSettings) then upgradeSettings else [upgradeSettings] },
        '#withUpgradeSettingsMixin':: d.fn(help='"A upgrade_settings block as documented below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='upgradeSettings', type=d.T.array)]),
        withUpgradeSettingsMixin(upgradeSettings): { upgradeSettings+: if std.isArray(v=upgradeSettings) then upgradeSettings else [upgradeSettings] },
        '#withVmSize':: d.fn(help='"The size of the Virtual Machine, such as Standard_DS2_v2. temporary_name_for_rotation must be specified when attempting a resize."', args=[d.arg(name='vmSize', type=d.T.string)]),
        withVmSize(vmSize): { vmSize: vmSize },
        '#withVnetSubnetId':: d.fn(help='"The ID of a Subnet where the Kubernetes Node Pool should exist."', args=[d.arg(name='vnetSubnetId', type=d.T.string)]),
        withVnetSubnetId(vnetSubnetId): { vnetSubnetId: vnetSubnetId },
        '#withWorkloadRuntime':: d.fn(help='"Specifies the workload runtime used by the node pool. Possible value is OCIContainer."', args=[d.arg(name='workloadRuntime', type=d.T.string)]),
        withWorkloadRuntime(workloadRuntime): { workloadRuntime: workloadRuntime },
        '#withZones':: d.fn(help='"Specifies a list of Availability Zones in which this Kubernetes Cluster should be located. temporary_name_for_rotation must be specified when changing this property."', args=[d.arg(name='zones', type=d.T.array)]),
        withZones(zones): { zones: if std.isArray(v=zones) then zones else [zones] },
        '#withZonesMixin':: d.fn(help='"Specifies a list of Availability Zones in which this Kubernetes Cluster should be located. temporary_name_for_rotation must be specified when changing this property."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='zones', type=d.T.array)]),
        withZonesMixin(zones): { zones+: if std.isArray(v=zones) then zones else [zones] },
      },
      '#httpProxyConfig':: d.obj(help='"A http_proxy_config block as defined below."'),
      httpProxyConfig: {
        '#trustedCaSecretRef':: d.obj(help='"The base64 encoded alternative CA certificate content in PEM format."'),
        trustedCaSecretRef: {
          '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { trustedCaSecretRef+: { key: key } },
          '#withName':: d.fn(help='"Name of the secret."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { trustedCaSecretRef+: { name: name } },
          '#withNamespace':: d.fn(help='"Namespace of the secret."', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { trustedCaSecretRef+: { namespace: namespace } },
        },
        '#withHttpProxy':: d.fn(help='"The proxy address to be used when communicating over HTTP."', args=[d.arg(name='httpProxy', type=d.T.string)]),
        withHttpProxy(httpProxy): { httpProxy: httpProxy },
        '#withHttpsProxy':: d.fn(help='"The proxy address to be used when communicating over HTTPS."', args=[d.arg(name='httpsProxy', type=d.T.string)]),
        withHttpsProxy(httpsProxy): { httpsProxy: httpsProxy },
        '#withNoProxy':: d.fn(help='"The list of domains that will not use the proxy for communication."', args=[d.arg(name='noProxy', type=d.T.array)]),
        withNoProxy(noProxy): { noProxy: if std.isArray(v=noProxy) then noProxy else [noProxy] },
        '#withNoProxyMixin':: d.fn(help='"The list of domains that will not use the proxy for communication."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='noProxy', type=d.T.array)]),
        withNoProxyMixin(noProxy): { noProxy+: if std.isArray(v=noProxy) then noProxy else [noProxy] },
      },
      '#identity':: d.obj(help='"An identity block as defined below. One of either identity or service_principal must be specified."'),
      identity: {
        '#identityIdsRefs':: d.obj(help='"References to UserAssignedIdentity in managedidentity to populate identityIds."'),
        identityIdsRefs: {
          '#policy':: d.obj(help='"Policies for referencing."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { policy+: { resolution: resolution } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { policy+: { resolve: resolve } },
          },
          '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
        },
        '#identityIdsSelector':: d.obj(help='"Selector for a list of UserAssignedIdentity in managedidentity to populate identityIds."'),
        identityIdsSelector: {
          '#policy':: d.obj(help='"Policies for selection."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { identityIdsSelector+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { identityIdsSelector+: { policy+: { resolve: resolve } } },
          },
          '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference\\nas the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
          withMatchControllerRef(matchControllerRef): { identityIdsSelector+: { matchControllerRef: matchControllerRef } },
          '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabels(matchLabels): { identityIdsSelector+: { matchLabels: matchLabels } },
          '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabelsMixin(matchLabels): { identityIdsSelector+: { matchLabels+: matchLabels } },
        },
        '#withIdentityIds':: d.fn(help='"Specifies a list of User Assigned Managed Identity IDs to be assigned to this Kubernetes Cluster."', args=[d.arg(name='identityIds', type=d.T.array)]),
        withIdentityIds(identityIds): { identityIds: if std.isArray(v=identityIds) then identityIds else [identityIds] },
        '#withIdentityIdsMixin':: d.fn(help='"Specifies a list of User Assigned Managed Identity IDs to be assigned to this Kubernetes Cluster."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='identityIds', type=d.T.array)]),
        withIdentityIdsMixin(identityIds): { identityIds+: if std.isArray(v=identityIds) then identityIds else [identityIds] },
        '#withIdentityIdsRefs':: d.fn(help='"References to UserAssignedIdentity in managedidentity to populate identityIds."', args=[d.arg(name='identityIdsRefs', type=d.T.array)]),
        withIdentityIdsRefs(identityIdsRefs): { identityIdsRefs: if std.isArray(v=identityIdsRefs) then identityIdsRefs else [identityIdsRefs] },
        '#withIdentityIdsRefsMixin':: d.fn(help='"References to UserAssignedIdentity in managedidentity to populate identityIds."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='identityIdsRefs', type=d.T.array)]),
        withIdentityIdsRefsMixin(identityIdsRefs): { identityIdsRefs+: if std.isArray(v=identityIdsRefs) then identityIdsRefs else [identityIdsRefs] },
        '#withType':: d.fn(help='"Specifies the type of Managed Service Identity that should be configured on this Kubernetes Cluster. Possible values are SystemAssigned or UserAssigned."', args=[d.arg(name='type', type=d.T.string)]),
        withType(type): { type: type },
      },
      '#ingressApplicationGateway':: d.obj(help='"An ingress_application_gateway block as defined below."'),
      ingressApplicationGateway: {
        '#subnetIdRef':: d.obj(help='"Reference to a Subnet in network to populate subnetId."'),
        subnetIdRef: {
          '#policy':: d.obj(help='"Policies for referencing."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { subnetIdRef+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { subnetIdRef+: { policy+: { resolve: resolve } } },
          },
          '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { subnetIdRef+: { name: name } },
        },
        '#subnetIdSelector':: d.obj(help='"Selector for a Subnet in network to populate subnetId."'),
        subnetIdSelector: {
          '#policy':: d.obj(help='"Policies for selection."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { subnetIdSelector+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { subnetIdSelector+: { policy+: { resolve: resolve } } },
          },
          '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference\\nas the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
          withMatchControllerRef(matchControllerRef): { subnetIdSelector+: { matchControllerRef: matchControllerRef } },
          '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabels(matchLabels): { subnetIdSelector+: { matchLabels: matchLabels } },
          '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabelsMixin(matchLabels): { subnetIdSelector+: { matchLabels+: matchLabels } },
        },
        '#withGatewayId':: d.fn(help='"The ID of the Application Gateway to integrate with the ingress controller of this Kubernetes Cluster. See this page for further details."', args=[d.arg(name='gatewayId', type=d.T.string)]),
        withGatewayId(gatewayId): { gatewayId: gatewayId },
        '#withGatewayName':: d.fn(help='"The name of the Application Gateway to be used or created in the Nodepool Resource Group, which in turn will be integrated with the ingress controller of this Kubernetes Cluster. See this page for further details."', args=[d.arg(name='gatewayName', type=d.T.string)]),
        withGatewayName(gatewayName): { gatewayName: gatewayName },
        '#withSubnetCidr':: d.fn(help='"The subnet CIDR to be used to create an Application Gateway, which in turn will be integrated with the ingress controller of this Kubernetes Cluster. See this page for further details."', args=[d.arg(name='subnetCidr', type=d.T.string)]),
        withSubnetCidr(subnetCidr): { subnetCidr: subnetCidr },
        '#withSubnetId':: d.fn(help='"The ID of the subnet on which to create an Application Gateway, which in turn will be integrated with the ingress controller of this Kubernetes Cluster. See this page for further details."', args=[d.arg(name='subnetId', type=d.T.string)]),
        withSubnetId(subnetId): { subnetId: subnetId },
      },
      '#keyManagementService':: d.obj(help='"A key_management_service block as defined below. For more details, please visit Key Management Service (KMS) etcd encryption to an AKS cluster."'),
      keyManagementService: {
        '#withKeyVaultKeyId':: d.fn(help='"Identifier of Azure Key Vault key. See key identifier format for more details."', args=[d.arg(name='keyVaultKeyId', type=d.T.string)]),
        withKeyVaultKeyId(keyVaultKeyId): { keyVaultKeyId: keyVaultKeyId },
        '#withKeyVaultNetworkAccess':: d.fn(help='"Network access of the key vault Network access of key vault. The possible values are Public and Private. Public means the key vault allows public access from all networks. Private means the key vault disables public access and enables private link. Defaults to Public."', args=[d.arg(name='keyVaultNetworkAccess', type=d.T.string)]),
        withKeyVaultNetworkAccess(keyVaultNetworkAccess): { keyVaultNetworkAccess: keyVaultNetworkAccess },
      },
      '#keyVaultSecretsProvider':: d.obj(help='"A key_vault_secrets_provider block as defined below."'),
      keyVaultSecretsProvider: {
        '#withSecretRotationEnabled':: d.fn(help='"Should the secret store CSI driver on the AKS cluster be enabled?"', args=[d.arg(name='secretRotationEnabled', type=d.T.boolean)]),
        withSecretRotationEnabled(secretRotationEnabled): { secretRotationEnabled: secretRotationEnabled },
        '#withSecretRotationInterval':: d.fn(help='"The interval to poll for secret rotation. This attribute is only set when secret_rotation_enabled is true. Defaults to 2m."', args=[d.arg(name='secretRotationInterval', type=d.T.string)]),
        withSecretRotationInterval(secretRotationInterval): { secretRotationInterval: secretRotationInterval },
      },
      '#kubeletIdentity':: d.obj(help='"A kubelet_identity block as defined below."'),
      kubeletIdentity: {
        '#withClientId':: d.fn(help='"The Client ID of the user-defined Managed Identity to be assigned to the Kubelets. If not specified a Managed Identity is created automatically. Changing this forces a new resource to be created."', args=[d.arg(name='clientId', type=d.T.string)]),
        withClientId(clientId): { clientId: clientId },
        '#withObjectId':: d.fn(help='"The Object ID of the user-defined Managed Identity assigned to the Kubelets.If not specified a Managed Identity is created automatically. Changing this forces a new resource to be created."', args=[d.arg(name='objectId', type=d.T.string)]),
        withObjectId(objectId): { objectId: objectId },
        '#withUserAssignedIdentityId':: d.fn(help='"The ID of the User Assigned Identity assigned to the Kubelets. If not specified a Managed Identity is created automatically. Changing this forces a new resource to be created."', args=[d.arg(name='userAssignedIdentityId', type=d.T.string)]),
        withUserAssignedIdentityId(userAssignedIdentityId): { userAssignedIdentityId: userAssignedIdentityId },
      },
      '#linuxProfile':: d.obj(help='"A linux_profile block as defined below."'),
      linuxProfile: {
        '#sshKey':: d.obj(help='"An ssh_key block as defined below. Only one is currently allowed. Changing this will update the key on all node pools. More information can be found in the documentation."'),
        sshKey: {
          '#withKeyData':: d.fn(help='"The Public SSH Key used to access the cluster. Changing this forces a new resource to be created."', args=[d.arg(name='keyData', type=d.T.string)]),
          withKeyData(keyData): { keyData: keyData },
        },
        '#withAdminUsername':: d.fn(help='"The Admin Username for the Cluster. Changing this forces a new resource to be created."', args=[d.arg(name='adminUsername', type=d.T.string)]),
        withAdminUsername(adminUsername): { adminUsername: adminUsername },
        '#withSshKey':: d.fn(help='"An ssh_key block as defined below. Only one is currently allowed. Changing this will update the key on all node pools. More information can be found in the documentation."', args=[d.arg(name='sshKey', type=d.T.array)]),
        withSshKey(sshKey): { sshKey: if std.isArray(v=sshKey) then sshKey else [sshKey] },
        '#withSshKeyMixin':: d.fn(help='"An ssh_key block as defined below. Only one is currently allowed. Changing this will update the key on all node pools. More information can be found in the documentation."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sshKey', type=d.T.array)]),
        withSshKeyMixin(sshKey): { sshKey+: if std.isArray(v=sshKey) then sshKey else [sshKey] },
      },
      '#maintenanceWindow':: d.obj(help='"A maintenance_window block as defined below."'),
      maintenanceWindow: {
        '#allowed':: d.obj(help='"One or more allowed blocks as defined below."'),
        allowed: {
          '#withDay':: d.fn(help='"A day in a week. Possible values are Sunday, Monday, Tuesday, Wednesday, Thursday, Friday and Saturday."', args=[d.arg(name='day', type=d.T.string)]),
          withDay(day): { day: day },
          '#withHours':: d.fn(help='"An array of hour slots in a day. For example, specifying 1 will allow maintenance from 1:00am to 2:00am. Specifying 1, 2 will allow maintenance from 1:00am to 3:00m. Possible values are between 0 and 23."', args=[d.arg(name='hours', type=d.T.array)]),
          withHours(hours): { hours: if std.isArray(v=hours) then hours else [hours] },
          '#withHoursMixin':: d.fn(help='"An array of hour slots in a day. For example, specifying 1 will allow maintenance from 1:00am to 2:00am. Specifying 1, 2 will allow maintenance from 1:00am to 3:00m. Possible values are between 0 and 23."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='hours', type=d.T.array)]),
          withHoursMixin(hours): { hours+: if std.isArray(v=hours) then hours else [hours] },
        },
        '#notAllowed':: d.obj(help='"One or more not_allowed block as defined below."'),
        notAllowed: {
          '#withEnd':: d.fn(help='"The end of a time span, formatted as an RFC3339 string."', args=[d.arg(name='end', type=d.T.string)]),
          withEnd(end): { end: end },
          '#withStart':: d.fn(help='"The start of a time span, formatted as an RFC3339 string."', args=[d.arg(name='start', type=d.T.string)]),
          withStart(start): { start: start },
        },
        '#withAllowed':: d.fn(help='"One or more allowed blocks as defined below."', args=[d.arg(name='allowed', type=d.T.array)]),
        withAllowed(allowed): { allowed: if std.isArray(v=allowed) then allowed else [allowed] },
        '#withAllowedMixin':: d.fn(help='"One or more allowed blocks as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='allowed', type=d.T.array)]),
        withAllowedMixin(allowed): { allowed+: if std.isArray(v=allowed) then allowed else [allowed] },
        '#withNotAllowed':: d.fn(help='"One or more not_allowed block as defined below."', args=[d.arg(name='notAllowed', type=d.T.array)]),
        withNotAllowed(notAllowed): { notAllowed: if std.isArray(v=notAllowed) then notAllowed else [notAllowed] },
        '#withNotAllowedMixin':: d.fn(help='"One or more not_allowed block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='notAllowed', type=d.T.array)]),
        withNotAllowedMixin(notAllowed): { notAllowed+: if std.isArray(v=notAllowed) then notAllowed else [notAllowed] },
      },
      '#maintenanceWindowAutoUpgrade':: d.obj(help='"A maintenance_window_auto_upgrade block as defined below."'),
      maintenanceWindowAutoUpgrade: {
        '#notAllowed':: d.obj(help='"One or more not_allowed block as defined below."'),
        notAllowed: {
          '#withEnd':: d.fn(help='"The end of a time span, formatted as an RFC3339 string."', args=[d.arg(name='end', type=d.T.string)]),
          withEnd(end): { end: end },
          '#withStart':: d.fn(help='"The start of a time span, formatted as an RFC3339 string."', args=[d.arg(name='start', type=d.T.string)]),
          withStart(start): { start: start },
        },
        '#withDayOfMonth':: d.fn(help='"The day of the month for the maintenance run. Required in combination with AbsoluteMonthly frequency. Value between 0 and 31 (inclusive)."', args=[d.arg(name='dayOfMonth', type=d.T.number)]),
        withDayOfMonth(dayOfMonth): { dayOfMonth: dayOfMonth },
        '#withDayOfWeek':: d.fn(help='"The day of the week for the maintenance run. Required in combination with weekly frequency. Possible values are Friday, Monday, Saturday, Sunday, Thursday, Tuesday and Wednesday."', args=[d.arg(name='dayOfWeek', type=d.T.string)]),
        withDayOfWeek(dayOfWeek): { dayOfWeek: dayOfWeek },
        '#withDuration':: d.fn(help='"The duration of the window for maintenance to run in hours. Possible options are between 4 to 24."', args=[d.arg(name='duration', type=d.T.number)]),
        withDuration(duration): { duration: duration },
        '#withFrequency':: d.fn(help='"Frequency of maintenance. Possible options are Daily, Weekly, AbsoluteMonthly and RelativeMonthly."', args=[d.arg(name='frequency', type=d.T.string)]),
        withFrequency(frequency): { frequency: frequency },
        '#withInterval':: d.fn(help='"The interval for maintenance runs. Depending on the frequency this interval is week or month based."', args=[d.arg(name='interval', type=d.T.number)]),
        withInterval(interval): { interval: interval },
        '#withNotAllowed':: d.fn(help='"One or more not_allowed block as defined below."', args=[d.arg(name='notAllowed', type=d.T.array)]),
        withNotAllowed(notAllowed): { notAllowed: if std.isArray(v=notAllowed) then notAllowed else [notAllowed] },
        '#withNotAllowedMixin':: d.fn(help='"One or more not_allowed block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='notAllowed', type=d.T.array)]),
        withNotAllowedMixin(notAllowed): { notAllowed+: if std.isArray(v=notAllowed) then notAllowed else [notAllowed] },
        '#withStartDate':: d.fn(help='"The date on which the maintenance window begins to take effect."', args=[d.arg(name='startDate', type=d.T.string)]),
        withStartDate(startDate): { startDate: startDate },
        '#withStartTime':: d.fn(help='"The time for maintenance to begin, based on the timezone determined by utc_offset. Format is HH:mm."', args=[d.arg(name='startTime', type=d.T.string)]),
        withStartTime(startTime): { startTime: startTime },
        '#withUtcOffset':: d.fn(help='"Used to determine the timezone for cluster maintenance."', args=[d.arg(name='utcOffset', type=d.T.string)]),
        withUtcOffset(utcOffset): { utcOffset: utcOffset },
        '#withWeekIndex':: d.fn(help='"Specifies on which instance of the allowed days specified in day_of_week the maintenance occurs. Options are First, Second, Third, Fourth, and Last.\\nRequired in combination with relative monthly frequency."', args=[d.arg(name='weekIndex', type=d.T.string)]),
        withWeekIndex(weekIndex): { weekIndex: weekIndex },
      },
      '#maintenanceWindowNodeOs':: d.obj(help='"A maintenance_window_node_os block as defined below."'),
      maintenanceWindowNodeOs: {
        '#notAllowed':: d.obj(help='"One or more not_allowed block as defined below."'),
        notAllowed: {
          '#withEnd':: d.fn(help='"The end of a time span, formatted as an RFC3339 string."', args=[d.arg(name='end', type=d.T.string)]),
          withEnd(end): { end: end },
          '#withStart':: d.fn(help='"The start of a time span, formatted as an RFC3339 string."', args=[d.arg(name='start', type=d.T.string)]),
          withStart(start): { start: start },
        },
        '#withDayOfMonth':: d.fn(help='"The day of the month for the maintenance run. Required in combination with AbsoluteMonthly frequency. Value between 0 and 31 (inclusive)."', args=[d.arg(name='dayOfMonth', type=d.T.number)]),
        withDayOfMonth(dayOfMonth): { dayOfMonth: dayOfMonth },
        '#withDayOfWeek':: d.fn(help='"The day of the week for the maintenance run. Required in combination with weekly frequency. Possible values are Friday, Monday, Saturday, Sunday, Thursday, Tuesday and Wednesday."', args=[d.arg(name='dayOfWeek', type=d.T.string)]),
        withDayOfWeek(dayOfWeek): { dayOfWeek: dayOfWeek },
        '#withDuration':: d.fn(help='"The duration of the window for maintenance to run in hours. Possible options are between 4 to 24."', args=[d.arg(name='duration', type=d.T.number)]),
        withDuration(duration): { duration: duration },
        '#withFrequency':: d.fn(help='"Frequency of maintenance. Possible options are Daily, Weekly, AbsoluteMonthly and RelativeMonthly."', args=[d.arg(name='frequency', type=d.T.string)]),
        withFrequency(frequency): { frequency: frequency },
        '#withInterval':: d.fn(help='"The interval for maintenance runs. Depending on the frequency this interval is week or month based."', args=[d.arg(name='interval', type=d.T.number)]),
        withInterval(interval): { interval: interval },
        '#withNotAllowed':: d.fn(help='"One or more not_allowed block as defined below."', args=[d.arg(name='notAllowed', type=d.T.array)]),
        withNotAllowed(notAllowed): { notAllowed: if std.isArray(v=notAllowed) then notAllowed else [notAllowed] },
        '#withNotAllowedMixin':: d.fn(help='"One or more not_allowed block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='notAllowed', type=d.T.array)]),
        withNotAllowedMixin(notAllowed): { notAllowed+: if std.isArray(v=notAllowed) then notAllowed else [notAllowed] },
        '#withStartDate':: d.fn(help='"The date on which the maintenance window begins to take effect."', args=[d.arg(name='startDate', type=d.T.string)]),
        withStartDate(startDate): { startDate: startDate },
        '#withStartTime':: d.fn(help='"The time for maintenance to begin, based on the timezone determined by utc_offset. Format is HH:mm."', args=[d.arg(name='startTime', type=d.T.string)]),
        withStartTime(startTime): { startTime: startTime },
        '#withUtcOffset':: d.fn(help='"Used to determine the timezone for cluster maintenance."', args=[d.arg(name='utcOffset', type=d.T.string)]),
        withUtcOffset(utcOffset): { utcOffset: utcOffset },
        '#withWeekIndex':: d.fn(help='"The week in the month used for the maintenance run. Options are First, Second, Third, Fourth, and Last."', args=[d.arg(name='weekIndex', type=d.T.string)]),
        withWeekIndex(weekIndex): { weekIndex: weekIndex },
      },
      '#microsoftDefender':: d.obj(help='"A microsoft_defender block as defined below."'),
      microsoftDefender: {
        '#withLogAnalyticsWorkspaceId':: d.fn(help='"Specifies the ID of the Log Analytics Workspace where the audit logs collected by Microsoft Defender should be sent to."', args=[d.arg(name='logAnalyticsWorkspaceId', type=d.T.string)]),
        withLogAnalyticsWorkspaceId(logAnalyticsWorkspaceId): { logAnalyticsWorkspaceId: logAnalyticsWorkspaceId },
      },
      '#monitorMetrics':: d.obj(help='"Specifies a Prometheus add-on profile for the Kubernetes Cluster. A monitor_metrics block as defined below."'),
      monitorMetrics: {
        '#withAnnotationsAllowed':: d.fn(help="\"Specifies a comma-separated list of Kubernetes annotation keys that will be used in the resource's labels metric.\"", args=[d.arg(name='annotationsAllowed', type=d.T.string)]),
        withAnnotationsAllowed(annotationsAllowed): { annotationsAllowed: annotationsAllowed },
        '#withLabelsAllowed':: d.fn(help="\"Specifies a Comma-separated list of additional Kubernetes label keys that will be used in the resource's labels metric.\"", args=[d.arg(name='labelsAllowed', type=d.T.string)]),
        withLabelsAllowed(labelsAllowed): { labelsAllowed: labelsAllowed },
      },
      '#networkProfile':: d.obj(help='"A network_profile block as defined below."'),
      networkProfile: {
        '#advancedNetworking':: d.obj(help='"An advanced_networking block as defined below. This can only be specified when network_plugin is set to azure and network_data_plane is set to cilium."'),
        advancedNetworking: {
          '#withObservabilityEnabled':: d.fn(help='"Is observability enabled? Defaults to false."', args=[d.arg(name='observabilityEnabled', type=d.T.boolean)]),
          withObservabilityEnabled(observabilityEnabled): { observabilityEnabled: observabilityEnabled },
          '#withSecurityEnabled':: d.fn(help='"Is security enabled? Defaults to false."', args=[d.arg(name='securityEnabled', type=d.T.boolean)]),
          withSecurityEnabled(securityEnabled): { securityEnabled: securityEnabled },
        },
        '#loadBalancerProfile':: d.obj(help='"A load_balancer_profile block as defined below. This can only be specified when load_balancer_sku is set to standard. Changing this forces a new resource to be created."'),
        loadBalancerProfile: {
          '#withBackendPoolType':: d.fn(help='"The type of the managed inbound Load Balancer Backend Pool. Possible values are NodeIP and NodeIPConfiguration. Defaults to NodeIPConfiguration. See the documentation for more information."', args=[d.arg(name='backendPoolType', type=d.T.string)]),
          withBackendPoolType(backendPoolType): { backendPoolType: backendPoolType },
          '#withIdleTimeoutInMinutes':: d.fn(help='"Desired outbound flow idle timeout in minutes for the managed nat gateway. Must be between 4 and 120 inclusive. Defaults to 4."', args=[d.arg(name='idleTimeoutInMinutes', type=d.T.number)]),
          withIdleTimeoutInMinutes(idleTimeoutInMinutes): { idleTimeoutInMinutes: idleTimeoutInMinutes },
          '#withManagedOutboundIpCount':: d.fn(help='"Count of desired managed outbound IPs for the managed nat gateway. Must be between 1 and 16 inclusive."', args=[d.arg(name='managedOutboundIpCount', type=d.T.number)]),
          withManagedOutboundIpCount(managedOutboundIpCount): { managedOutboundIpCount: managedOutboundIpCount },
          '#withManagedOutboundIpv6Count':: d.fn(help='"The desired number of IPv6 outbound IPs created and managed by Azure for the cluster load balancer. Must be in the range of 1 to 100 (inclusive). The default value is 0 for single-stack and 1 for dual-stack."', args=[d.arg(name='managedOutboundIpv6Count', type=d.T.number)]),
          withManagedOutboundIpv6Count(managedOutboundIpv6Count): { managedOutboundIpv6Count: managedOutboundIpv6Count },
          '#withOutboundIpAddressIds':: d.fn(help='"The ID of the Public IP Addresses which should be used for outbound communication for the cluster load balancer."', args=[d.arg(name='outboundIpAddressIds', type=d.T.array)]),
          withOutboundIpAddressIds(outboundIpAddressIds): { outboundIpAddressIds: if std.isArray(v=outboundIpAddressIds) then outboundIpAddressIds else [outboundIpAddressIds] },
          '#withOutboundIpAddressIdsMixin':: d.fn(help='"The ID of the Public IP Addresses which should be used for outbound communication for the cluster load balancer."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='outboundIpAddressIds', type=d.T.array)]),
          withOutboundIpAddressIdsMixin(outboundIpAddressIds): { outboundIpAddressIds+: if std.isArray(v=outboundIpAddressIds) then outboundIpAddressIds else [outboundIpAddressIds] },
          '#withOutboundIpPrefixIds':: d.fn(help='"The ID of the outbound Public IP Address Prefixes which should be used for the cluster load balancer."', args=[d.arg(name='outboundIpPrefixIds', type=d.T.array)]),
          withOutboundIpPrefixIds(outboundIpPrefixIds): { outboundIpPrefixIds: if std.isArray(v=outboundIpPrefixIds) then outboundIpPrefixIds else [outboundIpPrefixIds] },
          '#withOutboundIpPrefixIdsMixin':: d.fn(help='"The ID of the outbound Public IP Address Prefixes which should be used for the cluster load balancer."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='outboundIpPrefixIds', type=d.T.array)]),
          withOutboundIpPrefixIdsMixin(outboundIpPrefixIds): { outboundIpPrefixIds+: if std.isArray(v=outboundIpPrefixIds) then outboundIpPrefixIds else [outboundIpPrefixIds] },
          '#withOutboundPortsAllocated':: d.fn(help='"Number of desired SNAT port for each VM in the clusters load balancer. Must be between 0 and 64000 inclusive. Defaults to 0."', args=[d.arg(name='outboundPortsAllocated', type=d.T.number)]),
          withOutboundPortsAllocated(outboundPortsAllocated): { outboundPortsAllocated: outboundPortsAllocated },
        },
        '#natGatewayProfile':: d.obj(help='"A nat_gateway_profile block as defined below. This can only be specified when load_balancer_sku is set to standard and outbound_type is set to managedNATGateway or userAssignedNATGateway. Changing this forces a new resource to be created."'),
        natGatewayProfile: {
          '#withIdleTimeoutInMinutes':: d.fn(help='"Desired outbound flow idle timeout in minutes for the managed nat gateway. Must be between 4 and 120 inclusive. Defaults to 4."', args=[d.arg(name='idleTimeoutInMinutes', type=d.T.number)]),
          withIdleTimeoutInMinutes(idleTimeoutInMinutes): { idleTimeoutInMinutes: idleTimeoutInMinutes },
          '#withManagedOutboundIpCount':: d.fn(help='"Count of desired managed outbound IPs for the managed nat gateway. Must be between 1 and 16 inclusive."', args=[d.arg(name='managedOutboundIpCount', type=d.T.number)]),
          withManagedOutboundIpCount(managedOutboundIpCount): { managedOutboundIpCount: managedOutboundIpCount },
        },
        '#withAdvancedNetworking':: d.fn(help='"An advanced_networking block as defined below. This can only be specified when network_plugin is set to azure and network_data_plane is set to cilium."', args=[d.arg(name='advancedNetworking', type=d.T.array)]),
        withAdvancedNetworking(advancedNetworking): { advancedNetworking: if std.isArray(v=advancedNetworking) then advancedNetworking else [advancedNetworking] },
        '#withAdvancedNetworkingMixin':: d.fn(help='"An advanced_networking block as defined below. This can only be specified when network_plugin is set to azure and network_data_plane is set to cilium."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='advancedNetworking', type=d.T.array)]),
        withAdvancedNetworkingMixin(advancedNetworking): { advancedNetworking+: if std.isArray(v=advancedNetworking) then advancedNetworking else [advancedNetworking] },
        '#withDnsServiceIp':: d.fn(help='"IP address within the Kubernetes service address range that will be used by cluster service discovery (kube-dns). Changing this forces a new resource to be created."', args=[d.arg(name='dnsServiceIp', type=d.T.string)]),
        withDnsServiceIp(dnsServiceIp): { dnsServiceIp: dnsServiceIp },
        '#withIpVersions':: d.fn(help='"Specifies a list of IP versions the Kubernetes Cluster will use to assign IP addresses to its nodes and pods. Possible values are IPv4 and/or IPv6. IPv4 must always be specified. Changing this forces a new resource to be created."', args=[d.arg(name='ipVersions', type=d.T.array)]),
        withIpVersions(ipVersions): { ipVersions: if std.isArray(v=ipVersions) then ipVersions else [ipVersions] },
        '#withIpVersionsMixin':: d.fn(help='"Specifies a list of IP versions the Kubernetes Cluster will use to assign IP addresses to its nodes and pods. Possible values are IPv4 and/or IPv6. IPv4 must always be specified. Changing this forces a new resource to be created."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ipVersions', type=d.T.array)]),
        withIpVersionsMixin(ipVersions): { ipVersions+: if std.isArray(v=ipVersions) then ipVersions else [ipVersions] },
        '#withLoadBalancerProfile':: d.fn(help='"A load_balancer_profile block as defined below. This can only be specified when load_balancer_sku is set to standard. Changing this forces a new resource to be created."', args=[d.arg(name='loadBalancerProfile', type=d.T.array)]),
        withLoadBalancerProfile(loadBalancerProfile): { loadBalancerProfile: if std.isArray(v=loadBalancerProfile) then loadBalancerProfile else [loadBalancerProfile] },
        '#withLoadBalancerProfileMixin':: d.fn(help='"A load_balancer_profile block as defined below. This can only be specified when load_balancer_sku is set to standard. Changing this forces a new resource to be created."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='loadBalancerProfile', type=d.T.array)]),
        withLoadBalancerProfileMixin(loadBalancerProfile): { loadBalancerProfile+: if std.isArray(v=loadBalancerProfile) then loadBalancerProfile else [loadBalancerProfile] },
        '#withLoadBalancerSku':: d.fn(help='"Specifies the SKU of the Load Balancer used for this Kubernetes Cluster. Possible values are basic and standard. Defaults to standard. Changing this forces a new resource to be created."', args=[d.arg(name='loadBalancerSku', type=d.T.string)]),
        withLoadBalancerSku(loadBalancerSku): { loadBalancerSku: loadBalancerSku },
        '#withNatGatewayProfile':: d.fn(help='"A nat_gateway_profile block as defined below. This can only be specified when load_balancer_sku is set to standard and outbound_type is set to managedNATGateway or userAssignedNATGateway. Changing this forces a new resource to be created."', args=[d.arg(name='natGatewayProfile', type=d.T.array)]),
        withNatGatewayProfile(natGatewayProfile): { natGatewayProfile: if std.isArray(v=natGatewayProfile) then natGatewayProfile else [natGatewayProfile] },
        '#withNatGatewayProfileMixin':: d.fn(help='"A nat_gateway_profile block as defined below. This can only be specified when load_balancer_sku is set to standard and outbound_type is set to managedNATGateway or userAssignedNATGateway. Changing this forces a new resource to be created."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='natGatewayProfile', type=d.T.array)]),
        withNatGatewayProfileMixin(natGatewayProfile): { natGatewayProfile+: if std.isArray(v=natGatewayProfile) then natGatewayProfile else [natGatewayProfile] },
        '#withNetworkDataPlane':: d.fn(help='"Specifies the data plane used for building the Kubernetes network. Possible values are azure and cilium. Defaults to azure. Disabling this forces a new resource to be created."', args=[d.arg(name='networkDataPlane', type=d.T.string)]),
        withNetworkDataPlane(networkDataPlane): { networkDataPlane: networkDataPlane },
        '#withNetworkMode':: d.fn(help='"Network mode to be used with Azure CNI. Possible values are bridge and transparent. Changing this forces a new resource to be created."', args=[d.arg(name='networkMode', type=d.T.string)]),
        withNetworkMode(networkMode): { networkMode: networkMode },
        '#withNetworkPlugin':: d.fn(help='"Network plugin to use for networking. Currently supported values are azure, kubenet and none. Changing this forces a new resource to be created."', args=[d.arg(name='networkPlugin', type=d.T.string)]),
        withNetworkPlugin(networkPlugin): { networkPlugin: networkPlugin },
        '#withNetworkPluginMode':: d.fn(help='"Specifies the network plugin mode used for building the Kubernetes network. Possible value is overlay."', args=[d.arg(name='networkPluginMode', type=d.T.string)]),
        withNetworkPluginMode(networkPluginMode): { networkPluginMode: networkPluginMode },
        '#withNetworkPolicy':: d.fn(help='"Sets up network policy to be used with Azure CNI. Network policy allows us to control the traffic flow between pods. Currently supported values are calico, azure and cilium."', args=[d.arg(name='networkPolicy', type=d.T.string)]),
        withNetworkPolicy(networkPolicy): { networkPolicy: networkPolicy },
        '#withOutboundType':: d.fn(help='"The outbound (egress) routing method which should be used for this Kubernetes Cluster. Possible values are loadBalancer, userDefinedRouting, managedNATGateway, userAssignedNATGateway and none. Defaults to loadBalancer."', args=[d.arg(name='outboundType', type=d.T.string)]),
        withOutboundType(outboundType): { outboundType: outboundType },
        '#withPodCidr':: d.fn(help='"The CIDR to use for pod IP addresses. This field can only be set when network_plugin is set to kubenet or network_plugin_mode is set to overlay. Changing this forces a new resource to be created."', args=[d.arg(name='podCidr', type=d.T.string)]),
        withPodCidr(podCidr): { podCidr: podCidr },
        '#withPodCidrs':: d.fn(help='"A list of CIDRs to use for pod IP addresses. For single-stack networking a single IPv4 CIDR is expected. For dual-stack networking an IPv4 and IPv6 CIDR are expected. Changing this forces a new resource to be created."', args=[d.arg(name='podCidrs', type=d.T.array)]),
        withPodCidrs(podCidrs): { podCidrs: if std.isArray(v=podCidrs) then podCidrs else [podCidrs] },
        '#withPodCidrsMixin':: d.fn(help='"A list of CIDRs to use for pod IP addresses. For single-stack networking a single IPv4 CIDR is expected. For dual-stack networking an IPv4 and IPv6 CIDR are expected. Changing this forces a new resource to be created."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='podCidrs', type=d.T.array)]),
        withPodCidrsMixin(podCidrs): { podCidrs+: if std.isArray(v=podCidrs) then podCidrs else [podCidrs] },
        '#withServiceCidr':: d.fn(help='"The Network Range used by the Kubernetes service. Changing this forces a new resource to be created."', args=[d.arg(name='serviceCidr', type=d.T.string)]),
        withServiceCidr(serviceCidr): { serviceCidr: serviceCidr },
        '#withServiceCidrs':: d.fn(help='"A list of CIDRs to use for Kubernetes services. For single-stack networking a single IPv4 CIDR is expected. For dual-stack networking an IPv4 and IPv6 CIDR are expected. Changing this forces a new resource to be created."', args=[d.arg(name='serviceCidrs', type=d.T.array)]),
        withServiceCidrs(serviceCidrs): { serviceCidrs: if std.isArray(v=serviceCidrs) then serviceCidrs else [serviceCidrs] },
        '#withServiceCidrsMixin':: d.fn(help='"A list of CIDRs to use for Kubernetes services. For single-stack networking a single IPv4 CIDR is expected. For dual-stack networking an IPv4 and IPv6 CIDR are expected. Changing this forces a new resource to be created."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='serviceCidrs', type=d.T.array)]),
        withServiceCidrsMixin(serviceCidrs): { serviceCidrs+: if std.isArray(v=serviceCidrs) then serviceCidrs else [serviceCidrs] },
      },
      '#omsAgent':: d.obj(help='"An oms_agent block as defined below."'),
      omsAgent: {
        '#withLogAnalyticsWorkspaceId':: d.fn(help='"The ID of the Log Analytics Workspace which the OMS Agent should send data to."', args=[d.arg(name='logAnalyticsWorkspaceId', type=d.T.string)]),
        withLogAnalyticsWorkspaceId(logAnalyticsWorkspaceId): { logAnalyticsWorkspaceId: logAnalyticsWorkspaceId },
        '#withMsiAuthForMonitoringEnabled':: d.fn(help='"Is managed identity authentication for monitoring enabled?"', args=[d.arg(name='msiAuthForMonitoringEnabled', type=d.T.boolean)]),
        withMsiAuthForMonitoringEnabled(msiAuthForMonitoringEnabled): { msiAuthForMonitoringEnabled: msiAuthForMonitoringEnabled },
      },
      '#privateDnsZoneIdRef':: d.obj(help='"Reference to a PrivateDNSZone in network to populate privateDnsZoneId."'),
      privateDnsZoneIdRef: {
        '#policy':: d.obj(help='"Policies for referencing."'),
        policy: {
          '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
          withResolution(resolution): { spec+: { initProvider+: { privateDnsZoneIdRef+: { policy+: { resolution: resolution } } } } },
          '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
          withResolve(resolve): { spec+: { initProvider+: { privateDnsZoneIdRef+: { policy+: { resolve: resolve } } } } },
        },
        '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { initProvider+: { privateDnsZoneIdRef+: { name: name } } } },
      },
      '#privateDnsZoneIdSelector':: d.obj(help='"Selector for a PrivateDNSZone in network to populate privateDnsZoneId."'),
      privateDnsZoneIdSelector: {
        '#policy':: d.obj(help='"Policies for selection."'),
        policy: {
          '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
          withResolution(resolution): { spec+: { initProvider+: { privateDnsZoneIdSelector+: { policy+: { resolution: resolution } } } } },
          '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
          withResolve(resolve): { spec+: { initProvider+: { privateDnsZoneIdSelector+: { policy+: { resolve: resolve } } } } },
        },
        '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference\\nas the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
        withMatchControllerRef(matchControllerRef): { spec+: { initProvider+: { privateDnsZoneIdSelector+: { matchControllerRef: matchControllerRef } } } },
        '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
        withMatchLabels(matchLabels): { spec+: { initProvider+: { privateDnsZoneIdSelector+: { matchLabels: matchLabels } } } },
        '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
        withMatchLabelsMixin(matchLabels): { spec+: { initProvider+: { privateDnsZoneIdSelector+: { matchLabels+: matchLabels } } } },
      },
      '#serviceMeshProfile':: d.obj(help='"A service_mesh_profile block as defined below."'),
      serviceMeshProfile: {
        '#certificateAuthority':: d.obj(help='"A certificate_authority block as defined below. When this property is specified, key_vault_secrets_provider is also required to be set. This configuration allows you to bring your own root certificate and keys for Istio CA in the Istio-based service mesh add-on for Azure Kubernetes Service."'),
        certificateAuthority: {
          '#withCertChainObjectName':: d.fn(help='"The certificate chain object name in Azure Key Vault."', args=[d.arg(name='certChainObjectName', type=d.T.string)]),
          withCertChainObjectName(certChainObjectName): { certChainObjectName: certChainObjectName },
          '#withCertObjectName':: d.fn(help='"The intermediate certificate object name in Azure Key Vault."', args=[d.arg(name='certObjectName', type=d.T.string)]),
          withCertObjectName(certObjectName): { certObjectName: certObjectName },
          '#withKeyObjectName':: d.fn(help='"The intermediate certificate private key object name in Azure Key Vault."', args=[d.arg(name='keyObjectName', type=d.T.string)]),
          withKeyObjectName(keyObjectName): { keyObjectName: keyObjectName },
          '#withKeyVaultId':: d.fn(help='"The resource ID of the Key Vault."', args=[d.arg(name='keyVaultId', type=d.T.string)]),
          withKeyVaultId(keyVaultId): { keyVaultId: keyVaultId },
          '#withRootCertObjectName':: d.fn(help='"The root certificate object name in Azure Key Vault."', args=[d.arg(name='rootCertObjectName', type=d.T.string)]),
          withRootCertObjectName(rootCertObjectName): { rootCertObjectName: rootCertObjectName },
        },
        '#withCertificateAuthority':: d.fn(help='"A certificate_authority block as defined below. When this property is specified, key_vault_secrets_provider is also required to be set. This configuration allows you to bring your own root certificate and keys for Istio CA in the Istio-based service mesh add-on for Azure Kubernetes Service."', args=[d.arg(name='certificateAuthority', type=d.T.array)]),
        withCertificateAuthority(certificateAuthority): { certificateAuthority: if std.isArray(v=certificateAuthority) then certificateAuthority else [certificateAuthority] },
        '#withCertificateAuthorityMixin':: d.fn(help='"A certificate_authority block as defined below. When this property is specified, key_vault_secrets_provider is also required to be set. This configuration allows you to bring your own root certificate and keys for Istio CA in the Istio-based service mesh add-on for Azure Kubernetes Service."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='certificateAuthority', type=d.T.array)]),
        withCertificateAuthorityMixin(certificateAuthority): { certificateAuthority+: if std.isArray(v=certificateAuthority) then certificateAuthority else [certificateAuthority] },
        '#withExternalIngressGatewayEnabled':: d.fn(help='"Is Istio External Ingress Gateway enabled?"', args=[d.arg(name='externalIngressGatewayEnabled', type=d.T.boolean)]),
        withExternalIngressGatewayEnabled(externalIngressGatewayEnabled): { externalIngressGatewayEnabled: externalIngressGatewayEnabled },
        '#withInternalIngressGatewayEnabled':: d.fn(help='"Is Istio Internal Ingress Gateway enabled?"', args=[d.arg(name='internalIngressGatewayEnabled', type=d.T.boolean)]),
        withInternalIngressGatewayEnabled(internalIngressGatewayEnabled): { internalIngressGatewayEnabled: internalIngressGatewayEnabled },
        '#withMode':: d.fn(help='"The mode of the service mesh. Possible value is Istio."', args=[d.arg(name='mode', type=d.T.string)]),
        withMode(mode): { mode: mode },
        '#withRevisions':: d.fn(help='"Specify 1 or 2 Istio control plane revisions for managing minor upgrades using the canary upgrade process. For example, create the resource with revisions set to [\\"asm-1-25\\"], or leave it empty (the revisions will only be known after apply). To start the canary upgrade, change revisions to [\\"asm-1-25\\", \\"asm-1-26\\"]. To roll back the canary upgrade, revert to [\\"asm-1-25\\"]. To confirm the upgrade, change to [\\"asm-1-26\\"]."', args=[d.arg(name='revisions', type=d.T.array)]),
        withRevisions(revisions): { revisions: if std.isArray(v=revisions) then revisions else [revisions] },
        '#withRevisionsMixin':: d.fn(help='"Specify 1 or 2 Istio control plane revisions for managing minor upgrades using the canary upgrade process. For example, create the resource with revisions set to [\\"asm-1-25\\"], or leave it empty (the revisions will only be known after apply). To start the canary upgrade, change revisions to [\\"asm-1-25\\", \\"asm-1-26\\"]. To roll back the canary upgrade, revert to [\\"asm-1-25\\"]. To confirm the upgrade, change to [\\"asm-1-26\\"]."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='revisions', type=d.T.array)]),
        withRevisionsMixin(revisions): { revisions+: if std.isArray(v=revisions) then revisions else [revisions] },
      },
      '#servicePrincipal':: d.obj(help='"A service_principal block as documented below. One of either identity or service_principal must be specified."'),
      servicePrincipal: {
        '#clientSecretSecretRef':: d.obj(help='"The Client Secret for the Service Principal."'),
        clientSecretSecretRef: {
          '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { clientSecretSecretRef+: { key: key } },
          '#withName':: d.fn(help='"Name of the secret."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { clientSecretSecretRef+: { name: name } },
          '#withNamespace':: d.fn(help='"Namespace of the secret."', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { clientSecretSecretRef+: { namespace: namespace } },
        },
        '#withClientId':: d.fn(help='"The Client ID for the Service Principal."', args=[d.arg(name='clientId', type=d.T.string)]),
        withClientId(clientId): { clientId: clientId },
      },
      '#storageProfile':: d.obj(help='"A storage_profile block as defined below."'),
      storageProfile: {
        '#withBlobDriverEnabled':: d.fn(help='"Is the Blob CSI driver enabled? Defaults to false."', args=[d.arg(name='blobDriverEnabled', type=d.T.boolean)]),
        withBlobDriverEnabled(blobDriverEnabled): { blobDriverEnabled: blobDriverEnabled },
        '#withDiskDriverEnabled':: d.fn(help='"Is the Disk CSI driver enabled? Defaults to true."', args=[d.arg(name='diskDriverEnabled', type=d.T.boolean)]),
        withDiskDriverEnabled(diskDriverEnabled): { diskDriverEnabled: diskDriverEnabled },
        '#withFileDriverEnabled':: d.fn(help='"Is the File CSI driver enabled? Defaults to true."', args=[d.arg(name='fileDriverEnabled', type=d.T.boolean)]),
        withFileDriverEnabled(fileDriverEnabled): { fileDriverEnabled: fileDriverEnabled },
        '#withSnapshotControllerEnabled':: d.fn(help='"Is the Snapshot Controller enabled? Defaults to true."', args=[d.arg(name='snapshotControllerEnabled', type=d.T.boolean)]),
        withSnapshotControllerEnabled(snapshotControllerEnabled): { snapshotControllerEnabled: snapshotControllerEnabled },
      },
      '#upgradeOverride':: d.obj(help='"A upgrade_override block as defined below."'),
      upgradeOverride: {
        '#withEffectiveUntil':: d.fn(help='"Specifies the duration, in RFC 3339 format (e.g., 2025-10-01T13:00:00Z), the upgrade_override values are effective. This field must be set for the upgrade_override values to take effect. The date-time must be within the next 30 days."', args=[d.arg(name='effectiveUntil', type=d.T.string)]),
        withEffectiveUntil(effectiveUntil): { effectiveUntil: effectiveUntil },
        '#withForceUpgradeEnabled':: d.fn(help='"Whether to force upgrade the cluster. Possible values are true or false."', args=[d.arg(name='forceUpgradeEnabled', type=d.T.boolean)]),
        withForceUpgradeEnabled(forceUpgradeEnabled): { forceUpgradeEnabled: forceUpgradeEnabled },
      },
      '#webAppRouting':: d.obj(help='"A web_app_routing block as defined below."'),
      webAppRouting: {
        '#withDefaultNginxController':: d.fn(help='"Specifies the ingress type for the default NginxIngressController custom resource. The allowed values are None, Internal, External and AnnotationControlled. Defaults to AnnotationControlled."', args=[d.arg(name='defaultNginxController', type=d.T.string)]),
        withDefaultNginxController(defaultNginxController): { defaultNginxController: defaultNginxController },
        '#withDnsZoneIds':: d.fn(help='"Specifies the list of the DNS Zone IDs in which DNS entries are created for applications deployed to the cluster when Web App Routing is enabled. If not using Bring-Your-Own DNS zones this property should be set to an empty list."', args=[d.arg(name='dnsZoneIds', type=d.T.array)]),
        withDnsZoneIds(dnsZoneIds): { dnsZoneIds: if std.isArray(v=dnsZoneIds) then dnsZoneIds else [dnsZoneIds] },
        '#withDnsZoneIdsMixin':: d.fn(help='"Specifies the list of the DNS Zone IDs in which DNS entries are created for applications deployed to the cluster when Web App Routing is enabled. If not using Bring-Your-Own DNS zones this property should be set to an empty list."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='dnsZoneIds', type=d.T.array)]),
        withDnsZoneIdsMixin(dnsZoneIds): { dnsZoneIds+: if std.isArray(v=dnsZoneIds) then dnsZoneIds else [dnsZoneIds] },
      },
      '#windowsProfile':: d.obj(help='"A windows_profile block as defined below."'),
      windowsProfile: {
        '#adminPasswordSecretRef':: d.obj(help='"The Admin Password for Windows VMs. Length must be between 14 and 123 characters."'),
        adminPasswordSecretRef: {
          '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { adminPasswordSecretRef+: { key: key } },
          '#withName':: d.fn(help='"Name of the secret."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { adminPasswordSecretRef+: { name: name } },
          '#withNamespace':: d.fn(help='"Namespace of the secret."', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { adminPasswordSecretRef+: { namespace: namespace } },
        },
        '#gmsa':: d.obj(help='"A gmsa block as defined below."'),
        gmsa: {
          '#withDnsServer':: d.fn(help='"Specifies the DNS server for Windows gMSA. Set this to an empty string if you have configured the DNS server in the VNet which was used to create the managed cluster."', args=[d.arg(name='dnsServer', type=d.T.string)]),
          withDnsServer(dnsServer): { dnsServer: dnsServer },
          '#withRootDomain':: d.fn(help='"Specifies the root domain name for Windows gMSA. Set this to an empty string if you have configured the DNS server in the VNet which was used to create the managed cluster."', args=[d.arg(name='rootDomain', type=d.T.string)]),
          withRootDomain(rootDomain): { rootDomain: rootDomain },
        },
        '#withAdminUsername':: d.fn(help='"The Admin Username for Windows VMs. Changing this forces a new resource to be created."', args=[d.arg(name='adminUsername', type=d.T.string)]),
        withAdminUsername(adminUsername): { adminUsername: adminUsername },
        '#withGmsa':: d.fn(help='"A gmsa block as defined below."', args=[d.arg(name='gmsa', type=d.T.array)]),
        withGmsa(gmsa): { gmsa: if std.isArray(v=gmsa) then gmsa else [gmsa] },
        '#withGmsaMixin':: d.fn(help='"A gmsa block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='gmsa', type=d.T.array)]),
        withGmsaMixin(gmsa): { gmsa+: if std.isArray(v=gmsa) then gmsa else [gmsa] },
        '#withLicense':: d.fn(help='"Specifies the type of on-premise license which should be used for Node Pool Windows Virtual Machine. At this time the only possible value is Windows_Server."', args=[d.arg(name='license', type=d.T.string)]),
        withLicense(license): { license: license },
      },
      '#withAciConnectorLinux':: d.fn(help='"A aci_connector_linux block as defined below. For more details, please visit Create and configure an AKS cluster to use virtual nodes."', args=[d.arg(name='aciConnectorLinux', type=d.T.array)]),
      withAciConnectorLinux(aciConnectorLinux): { spec+: { initProvider+: { aciConnectorLinux: if std.isArray(v=aciConnectorLinux) then aciConnectorLinux else [aciConnectorLinux] } } },
      '#withAciConnectorLinuxMixin':: d.fn(help='"A aci_connector_linux block as defined below. For more details, please visit Create and configure an AKS cluster to use virtual nodes."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='aciConnectorLinux', type=d.T.array)]),
      withAciConnectorLinuxMixin(aciConnectorLinux): { spec+: { initProvider+: { aciConnectorLinux+: if std.isArray(v=aciConnectorLinux) then aciConnectorLinux else [aciConnectorLinux] } } },
      '#withAiToolchainOperatorEnabled':: d.fn(help='"Specifies whether the AI Toolchain Operator should be enabled for the Cluster. Defaults to false."', args=[d.arg(name='aiToolchainOperatorEnabled', type=d.T.boolean)]),
      withAiToolchainOperatorEnabled(aiToolchainOperatorEnabled): { spec+: { initProvider+: { aiToolchainOperatorEnabled: aiToolchainOperatorEnabled } } },
      '#withApiServerAccessProfile':: d.fn(help='"An api_server_access_profile block as defined below."', args=[d.arg(name='apiServerAccessProfile', type=d.T.array)]),
      withApiServerAccessProfile(apiServerAccessProfile): { spec+: { initProvider+: { apiServerAccessProfile: if std.isArray(v=apiServerAccessProfile) then apiServerAccessProfile else [apiServerAccessProfile] } } },
      '#withApiServerAccessProfileMixin':: d.fn(help='"An api_server_access_profile block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='apiServerAccessProfile', type=d.T.array)]),
      withApiServerAccessProfileMixin(apiServerAccessProfile): { spec+: { initProvider+: { apiServerAccessProfile+: if std.isArray(v=apiServerAccessProfile) then apiServerAccessProfile else [apiServerAccessProfile] } } },
      '#withAutoScalerProfile':: d.fn(help='"A auto_scaler_profile block as defined below."', args=[d.arg(name='autoScalerProfile', type=d.T.array)]),
      withAutoScalerProfile(autoScalerProfile): { spec+: { initProvider+: { autoScalerProfile: if std.isArray(v=autoScalerProfile) then autoScalerProfile else [autoScalerProfile] } } },
      '#withAutoScalerProfileMixin':: d.fn(help='"A auto_scaler_profile block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='autoScalerProfile', type=d.T.array)]),
      withAutoScalerProfileMixin(autoScalerProfile): { spec+: { initProvider+: { autoScalerProfile+: if std.isArray(v=autoScalerProfile) then autoScalerProfile else [autoScalerProfile] } } },
      '#withAutomaticUpgradeChannel':: d.fn(help='"The upgrade channel for this Kubernetes Cluster. Possible values are patch, rapid, node-image and stable. Omitting this field sets this value to none."', args=[d.arg(name='automaticUpgradeChannel', type=d.T.string)]),
      withAutomaticUpgradeChannel(automaticUpgradeChannel): { spec+: { initProvider+: { automaticUpgradeChannel: automaticUpgradeChannel } } },
      '#withAzureActiveDirectoryRoleBasedAccessControl':: d.fn(help='"A azure_active_directory_role_based_access_control block as defined below."', args=[d.arg(name='azureActiveDirectoryRoleBasedAccessControl', type=d.T.array)]),
      withAzureActiveDirectoryRoleBasedAccessControl(azureActiveDirectoryRoleBasedAccessControl): { spec+: { initProvider+: { azureActiveDirectoryRoleBasedAccessControl: if std.isArray(v=azureActiveDirectoryRoleBasedAccessControl) then azureActiveDirectoryRoleBasedAccessControl else [azureActiveDirectoryRoleBasedAccessControl] } } },
      '#withAzureActiveDirectoryRoleBasedAccessControlMixin':: d.fn(help='"A azure_active_directory_role_based_access_control block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='azureActiveDirectoryRoleBasedAccessControl', type=d.T.array)]),
      withAzureActiveDirectoryRoleBasedAccessControlMixin(azureActiveDirectoryRoleBasedAccessControl): { spec+: { initProvider+: { azureActiveDirectoryRoleBasedAccessControl+: if std.isArray(v=azureActiveDirectoryRoleBasedAccessControl) then azureActiveDirectoryRoleBasedAccessControl else [azureActiveDirectoryRoleBasedAccessControl] } } },
      '#withAzurePolicyEnabled':: d.fn(help='"Should the Azure Policy Add-On be enabled? For more details please visit Understand Azure Policy for Azure Kubernetes Service"', args=[d.arg(name='azurePolicyEnabled', type=d.T.boolean)]),
      withAzurePolicyEnabled(azurePolicyEnabled): { spec+: { initProvider+: { azurePolicyEnabled: azurePolicyEnabled } } },
      '#withBootstrapProfile':: d.fn(help='"A bootstrap_profile block as defined below."', args=[d.arg(name='bootstrapProfile', type=d.T.array)]),
      withBootstrapProfile(bootstrapProfile): { spec+: { initProvider+: { bootstrapProfile: if std.isArray(v=bootstrapProfile) then bootstrapProfile else [bootstrapProfile] } } },
      '#withBootstrapProfileMixin':: d.fn(help='"A bootstrap_profile block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='bootstrapProfile', type=d.T.array)]),
      withBootstrapProfileMixin(bootstrapProfile): { spec+: { initProvider+: { bootstrapProfile+: if std.isArray(v=bootstrapProfile) then bootstrapProfile else [bootstrapProfile] } } },
      '#withConfidentialComputing':: d.fn(help='"A confidential_computing block as defined below. For more details please the documentation"', args=[d.arg(name='confidentialComputing', type=d.T.array)]),
      withConfidentialComputing(confidentialComputing): { spec+: { initProvider+: { confidentialComputing: if std.isArray(v=confidentialComputing) then confidentialComputing else [confidentialComputing] } } },
      '#withConfidentialComputingMixin':: d.fn(help='"A confidential_computing block as defined below. For more details please the documentation"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='confidentialComputing', type=d.T.array)]),
      withConfidentialComputingMixin(confidentialComputing): { spec+: { initProvider+: { confidentialComputing+: if std.isArray(v=confidentialComputing) then confidentialComputing else [confidentialComputing] } } },
      '#withCostAnalysisEnabled':: d.fn(help='"Should cost analysis be enabled for this Kubernetes Cluster? Defaults to false. The sku_tier must be set to Standard or Premium to enable this feature. Enabling this will add Kubernetes Namespace and Deployment details to the Cost Analysis views in the Azure portal."', args=[d.arg(name='costAnalysisEnabled', type=d.T.boolean)]),
      withCostAnalysisEnabled(costAnalysisEnabled): { spec+: { initProvider+: { costAnalysisEnabled: costAnalysisEnabled } } },
      '#withCustomCaTrustCertificatesBase64':: d.fn(help='"A list of up to 10 base64 encoded CA certificates that will be added to the trust store on nodes."', args=[d.arg(name='customCaTrustCertificatesBase64', type=d.T.array)]),
      withCustomCaTrustCertificatesBase64(customCaTrustCertificatesBase64): { spec+: { initProvider+: { customCaTrustCertificatesBase64: if std.isArray(v=customCaTrustCertificatesBase64) then customCaTrustCertificatesBase64 else [customCaTrustCertificatesBase64] } } },
      '#withCustomCaTrustCertificatesBase64Mixin':: d.fn(help='"A list of up to 10 base64 encoded CA certificates that will be added to the trust store on nodes."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='customCaTrustCertificatesBase64', type=d.T.array)]),
      withCustomCaTrustCertificatesBase64Mixin(customCaTrustCertificatesBase64): { spec+: { initProvider+: { customCaTrustCertificatesBase64+: if std.isArray(v=customCaTrustCertificatesBase64) then customCaTrustCertificatesBase64 else [customCaTrustCertificatesBase64] } } },
      '#withDefaultNodePool':: d.fn(help='"Specifies configuration for \\"System\\" mode node pool. A default_node_pool block as defined below."', args=[d.arg(name='defaultNodePool', type=d.T.array)]),
      withDefaultNodePool(defaultNodePool): { spec+: { initProvider+: { defaultNodePool: if std.isArray(v=defaultNodePool) then defaultNodePool else [defaultNodePool] } } },
      '#withDefaultNodePoolMixin':: d.fn(help='"Specifies configuration for \\"System\\" mode node pool. A default_node_pool block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='defaultNodePool', type=d.T.array)]),
      withDefaultNodePoolMixin(defaultNodePool): { spec+: { initProvider+: { defaultNodePool+: if std.isArray(v=defaultNodePool) then defaultNodePool else [defaultNodePool] } } },
      '#withDiskEncryptionSetId':: d.fn(help='"The ID of the Disk Encryption Set which should be used for the Nodes and Volumes. More information can be found in the documentation. Changing this forces a new resource to be created."', args=[d.arg(name='diskEncryptionSetId', type=d.T.string)]),
      withDiskEncryptionSetId(diskEncryptionSetId): { spec+: { initProvider+: { diskEncryptionSetId: diskEncryptionSetId } } },
      '#withDnsPrefix':: d.fn(help='"DNS prefix specified when creating the managed cluster. Possible values must begin and end with a letter or number, contain only letters, numbers, and hyphens and be between 1 and 54 characters in length. Changing this forces a new resource to be created."', args=[d.arg(name='dnsPrefix', type=d.T.string)]),
      withDnsPrefix(dnsPrefix): { spec+: { initProvider+: { dnsPrefix: dnsPrefix } } },
      '#withDnsPrefixPrivateCluster':: d.fn(help='"Specifies the DNS prefix to use with private clusters. Changing this forces a new resource to be created."', args=[d.arg(name='dnsPrefixPrivateCluster', type=d.T.string)]),
      withDnsPrefixPrivateCluster(dnsPrefixPrivateCluster): { spec+: { initProvider+: { dnsPrefixPrivateCluster: dnsPrefixPrivateCluster } } },
      '#withEdgeZone':: d.fn(help='"Specifies the Extended Zone (formerly called Edge Zone) within the Azure Region where this Managed Kubernetes Cluster should exist. Changing this forces a new resource to be created."', args=[d.arg(name='edgeZone', type=d.T.string)]),
      withEdgeZone(edgeZone): { spec+: { initProvider+: { edgeZone: edgeZone } } },
      '#withHttpApplicationRoutingEnabled':: d.fn(help='"Should HTTP Application Routing be enabled?"', args=[d.arg(name='httpApplicationRoutingEnabled', type=d.T.boolean)]),
      withHttpApplicationRoutingEnabled(httpApplicationRoutingEnabled): { spec+: { initProvider+: { httpApplicationRoutingEnabled: httpApplicationRoutingEnabled } } },
      '#withHttpProxyConfig':: d.fn(help='"A http_proxy_config block as defined below."', args=[d.arg(name='httpProxyConfig', type=d.T.array)]),
      withHttpProxyConfig(httpProxyConfig): { spec+: { initProvider+: { httpProxyConfig: if std.isArray(v=httpProxyConfig) then httpProxyConfig else [httpProxyConfig] } } },
      '#withHttpProxyConfigMixin':: d.fn(help='"A http_proxy_config block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpProxyConfig', type=d.T.array)]),
      withHttpProxyConfigMixin(httpProxyConfig): { spec+: { initProvider+: { httpProxyConfig+: if std.isArray(v=httpProxyConfig) then httpProxyConfig else [httpProxyConfig] } } },
      '#withIdentity':: d.fn(help='"An identity block as defined below. One of either identity or service_principal must be specified."', args=[d.arg(name='identity', type=d.T.array)]),
      withIdentity(identity): { spec+: { initProvider+: { identity: if std.isArray(v=identity) then identity else [identity] } } },
      '#withIdentityMixin':: d.fn(help='"An identity block as defined below. One of either identity or service_principal must be specified."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='identity', type=d.T.array)]),
      withIdentityMixin(identity): { spec+: { initProvider+: { identity+: if std.isArray(v=identity) then identity else [identity] } } },
      '#withImageCleanerEnabled':: d.fn(help='"Specifies whether Image Cleaner is enabled."', args=[d.arg(name='imageCleanerEnabled', type=d.T.boolean)]),
      withImageCleanerEnabled(imageCleanerEnabled): { spec+: { initProvider+: { imageCleanerEnabled: imageCleanerEnabled } } },
      '#withImageCleanerIntervalHours':: d.fn(help='"Specifies the interval in hours when images should be cleaned up."', args=[d.arg(name='imageCleanerIntervalHours', type=d.T.number)]),
      withImageCleanerIntervalHours(imageCleanerIntervalHours): { spec+: { initProvider+: { imageCleanerIntervalHours: imageCleanerIntervalHours } } },
      '#withIngressApplicationGateway':: d.fn(help='"An ingress_application_gateway block as defined below."', args=[d.arg(name='ingressApplicationGateway', type=d.T.array)]),
      withIngressApplicationGateway(ingressApplicationGateway): { spec+: { initProvider+: { ingressApplicationGateway: if std.isArray(v=ingressApplicationGateway) then ingressApplicationGateway else [ingressApplicationGateway] } } },
      '#withIngressApplicationGatewayMixin':: d.fn(help='"An ingress_application_gateway block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ingressApplicationGateway', type=d.T.array)]),
      withIngressApplicationGatewayMixin(ingressApplicationGateway): { spec+: { initProvider+: { ingressApplicationGateway+: if std.isArray(v=ingressApplicationGateway) then ingressApplicationGateway else [ingressApplicationGateway] } } },
      '#withKeyManagementService':: d.fn(help='"A key_management_service block as defined below. For more details, please visit Key Management Service (KMS) etcd encryption to an AKS cluster."', args=[d.arg(name='keyManagementService', type=d.T.array)]),
      withKeyManagementService(keyManagementService): { spec+: { initProvider+: { keyManagementService: if std.isArray(v=keyManagementService) then keyManagementService else [keyManagementService] } } },
      '#withKeyManagementServiceMixin':: d.fn(help='"A key_management_service block as defined below. For more details, please visit Key Management Service (KMS) etcd encryption to an AKS cluster."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='keyManagementService', type=d.T.array)]),
      withKeyManagementServiceMixin(keyManagementService): { spec+: { initProvider+: { keyManagementService+: if std.isArray(v=keyManagementService) then keyManagementService else [keyManagementService] } } },
      '#withKeyVaultSecretsProvider':: d.fn(help='"A key_vault_secrets_provider block as defined below."', args=[d.arg(name='keyVaultSecretsProvider', type=d.T.array)]),
      withKeyVaultSecretsProvider(keyVaultSecretsProvider): { spec+: { initProvider+: { keyVaultSecretsProvider: if std.isArray(v=keyVaultSecretsProvider) then keyVaultSecretsProvider else [keyVaultSecretsProvider] } } },
      '#withKeyVaultSecretsProviderMixin':: d.fn(help='"A key_vault_secrets_provider block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='keyVaultSecretsProvider', type=d.T.array)]),
      withKeyVaultSecretsProviderMixin(keyVaultSecretsProvider): { spec+: { initProvider+: { keyVaultSecretsProvider+: if std.isArray(v=keyVaultSecretsProvider) then keyVaultSecretsProvider else [keyVaultSecretsProvider] } } },
      '#withKubeletIdentity':: d.fn(help='"A kubelet_identity block as defined below."', args=[d.arg(name='kubeletIdentity', type=d.T.array)]),
      withKubeletIdentity(kubeletIdentity): { spec+: { initProvider+: { kubeletIdentity: if std.isArray(v=kubeletIdentity) then kubeletIdentity else [kubeletIdentity] } } },
      '#withKubeletIdentityMixin':: d.fn(help='"A kubelet_identity block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='kubeletIdentity', type=d.T.array)]),
      withKubeletIdentityMixin(kubeletIdentity): { spec+: { initProvider+: { kubeletIdentity+: if std.isArray(v=kubeletIdentity) then kubeletIdentity else [kubeletIdentity] } } },
      '#withKubernetesVersion':: d.fn(help="\"Version of Kubernetes specified when creating the AKS managed cluster. If not specified, the latest recommended version will be used at provisioning time (but won't auto-upgrade). AKS does not require an exact patch version to be specified, minor version aliases such as 1.22 are also supported. - The minor version's latest GA patch is automatically chosen in that case. More details can be found in the documentation.\"", args=[d.arg(name='kubernetesVersion', type=d.T.string)]),
      withKubernetesVersion(kubernetesVersion): { spec+: { initProvider+: { kubernetesVersion: kubernetesVersion } } },
      '#withLinuxProfile':: d.fn(help='"A linux_profile block as defined below."', args=[d.arg(name='linuxProfile', type=d.T.array)]),
      withLinuxProfile(linuxProfile): { spec+: { initProvider+: { linuxProfile: if std.isArray(v=linuxProfile) then linuxProfile else [linuxProfile] } } },
      '#withLinuxProfileMixin':: d.fn(help='"A linux_profile block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='linuxProfile', type=d.T.array)]),
      withLinuxProfileMixin(linuxProfile): { spec+: { initProvider+: { linuxProfile+: if std.isArray(v=linuxProfile) then linuxProfile else [linuxProfile] } } },
      '#withLocalAccountDisabled':: d.fn(help='"If true local accounts will be disabled. See the documentation for more information."', args=[d.arg(name='localAccountDisabled', type=d.T.boolean)]),
      withLocalAccountDisabled(localAccountDisabled): { spec+: { initProvider+: { localAccountDisabled: localAccountDisabled } } },
      '#withLocation':: d.fn(help='"The location where the Managed Kubernetes Cluster should be created. Changing this forces a new resource to be created."', args=[d.arg(name='location', type=d.T.string)]),
      withLocation(location): { spec+: { initProvider+: { location: location } } },
      '#withMaintenanceWindow':: d.fn(help='"A maintenance_window block as defined below."', args=[d.arg(name='maintenanceWindow', type=d.T.array)]),
      withMaintenanceWindow(maintenanceWindow): { spec+: { initProvider+: { maintenanceWindow: if std.isArray(v=maintenanceWindow) then maintenanceWindow else [maintenanceWindow] } } },
      '#withMaintenanceWindowAutoUpgrade':: d.fn(help='"A maintenance_window_auto_upgrade block as defined below."', args=[d.arg(name='maintenanceWindowAutoUpgrade', type=d.T.array)]),
      withMaintenanceWindowAutoUpgrade(maintenanceWindowAutoUpgrade): { spec+: { initProvider+: { maintenanceWindowAutoUpgrade: if std.isArray(v=maintenanceWindowAutoUpgrade) then maintenanceWindowAutoUpgrade else [maintenanceWindowAutoUpgrade] } } },
      '#withMaintenanceWindowAutoUpgradeMixin':: d.fn(help='"A maintenance_window_auto_upgrade block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='maintenanceWindowAutoUpgrade', type=d.T.array)]),
      withMaintenanceWindowAutoUpgradeMixin(maintenanceWindowAutoUpgrade): { spec+: { initProvider+: { maintenanceWindowAutoUpgrade+: if std.isArray(v=maintenanceWindowAutoUpgrade) then maintenanceWindowAutoUpgrade else [maintenanceWindowAutoUpgrade] } } },
      '#withMaintenanceWindowMixin':: d.fn(help='"A maintenance_window block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='maintenanceWindow', type=d.T.array)]),
      withMaintenanceWindowMixin(maintenanceWindow): { spec+: { initProvider+: { maintenanceWindow+: if std.isArray(v=maintenanceWindow) then maintenanceWindow else [maintenanceWindow] } } },
      '#withMaintenanceWindowNodeOs':: d.fn(help='"A maintenance_window_node_os block as defined below."', args=[d.arg(name='maintenanceWindowNodeOs', type=d.T.array)]),
      withMaintenanceWindowNodeOs(maintenanceWindowNodeOs): { spec+: { initProvider+: { maintenanceWindowNodeOs: if std.isArray(v=maintenanceWindowNodeOs) then maintenanceWindowNodeOs else [maintenanceWindowNodeOs] } } },
      '#withMaintenanceWindowNodeOsMixin':: d.fn(help='"A maintenance_window_node_os block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='maintenanceWindowNodeOs', type=d.T.array)]),
      withMaintenanceWindowNodeOsMixin(maintenanceWindowNodeOs): { spec+: { initProvider+: { maintenanceWindowNodeOs+: if std.isArray(v=maintenanceWindowNodeOs) then maintenanceWindowNodeOs else [maintenanceWindowNodeOs] } } },
      '#withMicrosoftDefender':: d.fn(help='"A microsoft_defender block as defined below."', args=[d.arg(name='microsoftDefender', type=d.T.array)]),
      withMicrosoftDefender(microsoftDefender): { spec+: { initProvider+: { microsoftDefender: if std.isArray(v=microsoftDefender) then microsoftDefender else [microsoftDefender] } } },
      '#withMicrosoftDefenderMixin':: d.fn(help='"A microsoft_defender block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='microsoftDefender', type=d.T.array)]),
      withMicrosoftDefenderMixin(microsoftDefender): { spec+: { initProvider+: { microsoftDefender+: if std.isArray(v=microsoftDefender) then microsoftDefender else [microsoftDefender] } } },
      '#withMonitorMetrics':: d.fn(help='"Specifies a Prometheus add-on profile for the Kubernetes Cluster. A monitor_metrics block as defined below."', args=[d.arg(name='monitorMetrics', type=d.T.array)]),
      withMonitorMetrics(monitorMetrics): { spec+: { initProvider+: { monitorMetrics: if std.isArray(v=monitorMetrics) then monitorMetrics else [monitorMetrics] } } },
      '#withMonitorMetricsMixin':: d.fn(help='"Specifies a Prometheus add-on profile for the Kubernetes Cluster. A monitor_metrics block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='monitorMetrics', type=d.T.array)]),
      withMonitorMetricsMixin(monitorMetrics): { spec+: { initProvider+: { monitorMetrics+: if std.isArray(v=monitorMetrics) then monitorMetrics else [monitorMetrics] } } },
      '#withNetworkProfile':: d.fn(help='"A network_profile block as defined below."', args=[d.arg(name='networkProfile', type=d.T.array)]),
      withNetworkProfile(networkProfile): { spec+: { initProvider+: { networkProfile: if std.isArray(v=networkProfile) then networkProfile else [networkProfile] } } },
      '#withNetworkProfileMixin':: d.fn(help='"A network_profile block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='networkProfile', type=d.T.array)]),
      withNetworkProfileMixin(networkProfile): { spec+: { initProvider+: { networkProfile+: if std.isArray(v=networkProfile) then networkProfile else [networkProfile] } } },
      '#withNodeOsUpgradeChannel':: d.fn(help="\"The upgrade channel for this Kubernetes Cluster Nodes' OS Image. Possible values are Unmanaged, SecurityPatch, NodeImage and None. Defaults to NodeImage.\"", args=[d.arg(name='nodeOsUpgradeChannel', type=d.T.string)]),
      withNodeOsUpgradeChannel(nodeOsUpgradeChannel): { spec+: { initProvider+: { nodeOsUpgradeChannel: nodeOsUpgradeChannel } } },
      '#withNodeResourceGroup':: d.fn(help='"The auto-generated Resource Group which contains the resources for this Managed Kubernetes Cluster."', args=[d.arg(name='nodeResourceGroup', type=d.T.string)]),
      withNodeResourceGroup(nodeResourceGroup): { spec+: { initProvider+: { nodeResourceGroup: nodeResourceGroup } } },
      '#withOidcIssuerEnabled':: d.fn(help='"Enable or Disable the OIDC issuer URL"', args=[d.arg(name='oidcIssuerEnabled', type=d.T.boolean)]),
      withOidcIssuerEnabled(oidcIssuerEnabled): { spec+: { initProvider+: { oidcIssuerEnabled: oidcIssuerEnabled } } },
      '#withOmsAgent':: d.fn(help='"An oms_agent block as defined below."', args=[d.arg(name='omsAgent', type=d.T.array)]),
      withOmsAgent(omsAgent): { spec+: { initProvider+: { omsAgent: if std.isArray(v=omsAgent) then omsAgent else [omsAgent] } } },
      '#withOmsAgentMixin':: d.fn(help='"An oms_agent block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='omsAgent', type=d.T.array)]),
      withOmsAgentMixin(omsAgent): { spec+: { initProvider+: { omsAgent+: if std.isArray(v=omsAgent) then omsAgent else [omsAgent] } } },
      '#withOpenServiceMeshEnabled':: d.fn(help='"Is Open Service Mesh enabled? For more details, please visit Open Service Mesh for AKS."', args=[d.arg(name='openServiceMeshEnabled', type=d.T.boolean)]),
      withOpenServiceMeshEnabled(openServiceMeshEnabled): { spec+: { initProvider+: { openServiceMeshEnabled: openServiceMeshEnabled } } },
      '#withPrivateClusterEnabled':: d.fn(help='"Should this Kubernetes Cluster have its API server only exposed on internal IP addresses? This provides a Private IP Address for the Kubernetes API on the Virtual Network where the Kubernetes Cluster is located. Defaults to false. Changing this forces a new resource to be created."', args=[d.arg(name='privateClusterEnabled', type=d.T.boolean)]),
      withPrivateClusterEnabled(privateClusterEnabled): { spec+: { initProvider+: { privateClusterEnabled: privateClusterEnabled } } },
      '#withPrivateClusterPublicFqdnEnabled':: d.fn(help='"Specifies whether a Public FQDN for this Private Cluster should be added. Defaults to false."', args=[d.arg(name='privateClusterPublicFqdnEnabled', type=d.T.boolean)]),
      withPrivateClusterPublicFqdnEnabled(privateClusterPublicFqdnEnabled): { spec+: { initProvider+: { privateClusterPublicFqdnEnabled: privateClusterPublicFqdnEnabled } } },
      '#withPrivateDnsZoneId':: d.fn(help='"Either the ID of Private DNS Zone which should be delegated to this Cluster, System to have AKS manage this or None. In case of None you will need to bring your own DNS server and set up resolving, otherwise, the cluster will have issues after provisioning. Changing this forces a new resource to be created."', args=[d.arg(name='privateDnsZoneId', type=d.T.string)]),
      withPrivateDnsZoneId(privateDnsZoneId): { spec+: { initProvider+: { privateDnsZoneId: privateDnsZoneId } } },
      '#withRoleBasedAccessControlEnabled':: d.fn(help='"Whether Role Based Access Control for the Kubernetes Cluster should be enabled. Defaults to true. Changing this forces a new resource to be created."', args=[d.arg(name='roleBasedAccessControlEnabled', type=d.T.boolean)]),
      withRoleBasedAccessControlEnabled(roleBasedAccessControlEnabled): { spec+: { initProvider+: { roleBasedAccessControlEnabled: roleBasedAccessControlEnabled } } },
      '#withRunCommandEnabled':: d.fn(help='"Whether to enable run command for the cluster or not. Defaults to true."', args=[d.arg(name='runCommandEnabled', type=d.T.boolean)]),
      withRunCommandEnabled(runCommandEnabled): { spec+: { initProvider+: { runCommandEnabled: runCommandEnabled } } },
      '#withServiceMeshProfile':: d.fn(help='"A service_mesh_profile block as defined below."', args=[d.arg(name='serviceMeshProfile', type=d.T.array)]),
      withServiceMeshProfile(serviceMeshProfile): { spec+: { initProvider+: { serviceMeshProfile: if std.isArray(v=serviceMeshProfile) then serviceMeshProfile else [serviceMeshProfile] } } },
      '#withServiceMeshProfileMixin':: d.fn(help='"A service_mesh_profile block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='serviceMeshProfile', type=d.T.array)]),
      withServiceMeshProfileMixin(serviceMeshProfile): { spec+: { initProvider+: { serviceMeshProfile+: if std.isArray(v=serviceMeshProfile) then serviceMeshProfile else [serviceMeshProfile] } } },
      '#withServicePrincipal':: d.fn(help='"A service_principal block as documented below. One of either identity or service_principal must be specified."', args=[d.arg(name='servicePrincipal', type=d.T.array)]),
      withServicePrincipal(servicePrincipal): { spec+: { initProvider+: { servicePrincipal: if std.isArray(v=servicePrincipal) then servicePrincipal else [servicePrincipal] } } },
      '#withServicePrincipalMixin':: d.fn(help='"A service_principal block as documented below. One of either identity or service_principal must be specified."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='servicePrincipal', type=d.T.array)]),
      withServicePrincipalMixin(servicePrincipal): { spec+: { initProvider+: { servicePrincipal+: if std.isArray(v=servicePrincipal) then servicePrincipal else [servicePrincipal] } } },
      '#withSkuTier':: d.fn(help='"The SKU Tier that should be used for this Kubernetes Cluster. Possible values are Free, Standard (which includes the Uptime SLA) and Premium. Defaults to Free."', args=[d.arg(name='skuTier', type=d.T.string)]),
      withSkuTier(skuTier): { spec+: { initProvider+: { skuTier: skuTier } } },
      '#withStorageProfile':: d.fn(help='"A storage_profile block as defined below."', args=[d.arg(name='storageProfile', type=d.T.array)]),
      withStorageProfile(storageProfile): { spec+: { initProvider+: { storageProfile: if std.isArray(v=storageProfile) then storageProfile else [storageProfile] } } },
      '#withStorageProfileMixin':: d.fn(help='"A storage_profile block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='storageProfile', type=d.T.array)]),
      withStorageProfileMixin(storageProfile): { spec+: { initProvider+: { storageProfile+: if std.isArray(v=storageProfile) then storageProfile else [storageProfile] } } },
      '#withSupportPlan':: d.fn(help='"Specifies the support plan which should be used for this Kubernetes Cluster. Possible values are KubernetesOfficial and AKSLongTermSupport. Defaults to KubernetesOfficial."', args=[d.arg(name='supportPlan', type=d.T.string)]),
      withSupportPlan(supportPlan): { spec+: { initProvider+: { supportPlan: supportPlan } } },
      '#withTags':: d.fn(help='"A mapping of tags to assign to the resource."', args=[d.arg(name='tags', type=d.T.object)]),
      withTags(tags): { spec+: { initProvider+: { tags: tags } } },
      '#withTagsMixin':: d.fn(help='"A mapping of tags to assign to the resource."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tags', type=d.T.object)]),
      withTagsMixin(tags): { spec+: { initProvider+: { tags+: tags } } },
      '#withUpgradeOverride':: d.fn(help='"A upgrade_override block as defined below."', args=[d.arg(name='upgradeOverride', type=d.T.array)]),
      withUpgradeOverride(upgradeOverride): { spec+: { initProvider+: { upgradeOverride: if std.isArray(v=upgradeOverride) then upgradeOverride else [upgradeOverride] } } },
      '#withUpgradeOverrideMixin':: d.fn(help='"A upgrade_override block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='upgradeOverride', type=d.T.array)]),
      withUpgradeOverrideMixin(upgradeOverride): { spec+: { initProvider+: { upgradeOverride+: if std.isArray(v=upgradeOverride) then upgradeOverride else [upgradeOverride] } } },
      '#withWebAppRouting':: d.fn(help='"A web_app_routing block as defined below."', args=[d.arg(name='webAppRouting', type=d.T.array)]),
      withWebAppRouting(webAppRouting): { spec+: { initProvider+: { webAppRouting: if std.isArray(v=webAppRouting) then webAppRouting else [webAppRouting] } } },
      '#withWebAppRoutingMixin':: d.fn(help='"A web_app_routing block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='webAppRouting', type=d.T.array)]),
      withWebAppRoutingMixin(webAppRouting): { spec+: { initProvider+: { webAppRouting+: if std.isArray(v=webAppRouting) then webAppRouting else [webAppRouting] } } },
      '#withWindowsProfile':: d.fn(help='"A windows_profile block as defined below."', args=[d.arg(name='windowsProfile', type=d.T.array)]),
      withWindowsProfile(windowsProfile): { spec+: { initProvider+: { windowsProfile: if std.isArray(v=windowsProfile) then windowsProfile else [windowsProfile] } } },
      '#withWindowsProfileMixin':: d.fn(help='"A windows_profile block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='windowsProfile', type=d.T.array)]),
      withWindowsProfileMixin(windowsProfile): { spec+: { initProvider+: { windowsProfile+: if std.isArray(v=windowsProfile) then windowsProfile else [windowsProfile] } } },
      '#withWorkloadAutoscalerProfile':: d.fn(help='"A workload_autoscaler_profile block defined below."', args=[d.arg(name='workloadAutoscalerProfile', type=d.T.array)]),
      withWorkloadAutoscalerProfile(workloadAutoscalerProfile): { spec+: { initProvider+: { workloadAutoscalerProfile: if std.isArray(v=workloadAutoscalerProfile) then workloadAutoscalerProfile else [workloadAutoscalerProfile] } } },
      '#withWorkloadAutoscalerProfileMixin':: d.fn(help='"A workload_autoscaler_profile block defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='workloadAutoscalerProfile', type=d.T.array)]),
      withWorkloadAutoscalerProfileMixin(workloadAutoscalerProfile): { spec+: { initProvider+: { workloadAutoscalerProfile+: if std.isArray(v=workloadAutoscalerProfile) then workloadAutoscalerProfile else [workloadAutoscalerProfile] } } },
      '#withWorkloadIdentityEnabled':: d.fn(help='"Specifies whether Azure AD Workload Identity should be enabled for the Cluster. Defaults to false."', args=[d.arg(name='workloadIdentityEnabled', type=d.T.boolean)]),
      withWorkloadIdentityEnabled(workloadIdentityEnabled): { spec+: { initProvider+: { workloadIdentityEnabled: workloadIdentityEnabled } } },
      '#workloadAutoscalerProfile':: d.obj(help='"A workload_autoscaler_profile block defined below."'),
      workloadAutoscalerProfile: {
        '#withKedaEnabled':: d.fn(help='"Specifies whether KEDA Autoscaler can be used for workloads."', args=[d.arg(name='kedaEnabled', type=d.T.boolean)]),
        withKedaEnabled(kedaEnabled): { kedaEnabled: kedaEnabled },
        '#withVerticalPodAutoscalerEnabled':: d.fn(help='"Specifies whether Vertical Pod Autoscaler should be enabled."', args=[d.arg(name='verticalPodAutoscalerEnabled', type=d.T.boolean)]),
        withVerticalPodAutoscalerEnabled(verticalPodAutoscalerEnabled): { verticalPodAutoscalerEnabled: verticalPodAutoscalerEnabled },
      },
    },
    '#providerConfigRef':: d.obj(help='"ProviderConfigReference specifies how the provider that will be used to\\ncreate, observe, update, and delete this managed resource should be\\nconfigured."'),
    providerConfigRef: {
      '#policy':: d.obj(help='"Policies for referencing."'),
      policy: {
        '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required.\\nThe default is 'Required', which means the reconcile will fail if the\\nreference cannot be resolved. 'Optional' means this reference will be\\na no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
        withResolution(resolution): { spec+: { providerConfigRef+: { policy+: { resolution: resolution } } } },
        '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default\\nis 'IfNotPresent', which will attempt to resolve the reference only when\\nthe corresponding field is not present. Use 'Always' to resolve the\\nreference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
        withResolve(resolve): { spec+: { providerConfigRef+: { policy+: { resolve: resolve } } } },
      },
      '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { providerConfigRef+: { name: name } } },
    },
    '#withDeletionPolicy':: d.fn(help='"DeletionPolicy specifies what will happen to the underlying external\\nwhen this managed resource is deleted - either \\"Delete\\" or \\"Orphan\\" the\\nexternal resource.\\nThis field is planned to be deprecated in favor of the ManagementPolicies\\nfield in a future release. Currently, both could be set independently and\\nnon-default values would be honored if the feature flag is enabled.\\nSee the design doc for more information: https://github.com/crossplane/crossplane/blob/499895a25d1a1a0ba1604944ef98ac7a1a71f197/design/design-doc-observe-only-resources.md?plain=1#L223"', args=[d.arg(name='deletionPolicy', type=d.T.string)]),
    withDeletionPolicy(deletionPolicy): { spec+: { deletionPolicy: deletionPolicy } },
    '#withManagementPolicies':: d.fn(help='"THIS IS A BETA FIELD. It is on by default but can be opted out\\nthrough a Crossplane feature flag.\\nManagementPolicies specify the array of actions Crossplane is allowed to\\ntake on the managed and external resources.\\nThis field is planned to replace the DeletionPolicy field in a future\\nrelease. Currently, both could be set independently and non-default\\nvalues would be honored if the feature flag is enabled. If both are\\ncustom, the DeletionPolicy field will be ignored.\\nSee the design doc for more information: https://github.com/crossplane/crossplane/blob/499895a25d1a1a0ba1604944ef98ac7a1a71f197/design/design-doc-observe-only-resources.md?plain=1#L223\\nand this one: https://github.com/crossplane/crossplane/blob/444267e84783136daa93568b364a5f01228cacbe/design/one-pager-ignore-changes.md"', args=[d.arg(name='managementPolicies', type=d.T.array)]),
    withManagementPolicies(managementPolicies): { spec+: { managementPolicies: if std.isArray(v=managementPolicies) then managementPolicies else [managementPolicies] } },
    '#withManagementPoliciesMixin':: d.fn(help='"THIS IS A BETA FIELD. It is on by default but can be opted out\\nthrough a Crossplane feature flag.\\nManagementPolicies specify the array of actions Crossplane is allowed to\\ntake on the managed and external resources.\\nThis field is planned to replace the DeletionPolicy field in a future\\nrelease. Currently, both could be set independently and non-default\\nvalues would be honored if the feature flag is enabled. If both are\\ncustom, the DeletionPolicy field will be ignored.\\nSee the design doc for more information: https://github.com/crossplane/crossplane/blob/499895a25d1a1a0ba1604944ef98ac7a1a71f197/design/design-doc-observe-only-resources.md?plain=1#L223\\nand this one: https://github.com/crossplane/crossplane/blob/444267e84783136daa93568b364a5f01228cacbe/design/one-pager-ignore-changes.md"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='managementPolicies', type=d.T.array)]),
    withManagementPoliciesMixin(managementPolicies): { spec+: { managementPolicies+: if std.isArray(v=managementPolicies) then managementPolicies else [managementPolicies] } },
    '#writeConnectionSecretToRef':: d.obj(help='"WriteConnectionSecretToReference specifies the namespace and name of a\\nSecret to which any connection details for this managed resource should\\nbe written. Connection details frequently include the endpoint, username,\\nand password required to connect to the managed resource."'),
    writeConnectionSecretToRef: {
      '#withName':: d.fn(help='"Name of the secret."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { writeConnectionSecretToRef+: { name: name } } },
      '#withNamespace':: d.fn(help='"Namespace of the secret."', args=[d.arg(name='namespace', type=d.T.string)]),
      withNamespace(namespace): { spec+: { writeConnectionSecretToRef+: { namespace: namespace } } },
    },
  },
  '#mixin': 'ignore',
  mixin: self,
}
